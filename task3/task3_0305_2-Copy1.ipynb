{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score, recall_score, \\\n",
    "    accuracy_score, precision_score, r2_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"data/sample.csv\")\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feats_dict(df_train):\n",
    "    fv = df_train['Sequence'].values\n",
    "    \n",
    "\n",
    "    fv_1plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,4):\n",
    "            fv_1plex_list.append(fv[i][j:j+1])\n",
    "    feats1 = list(set(fv_1plex_list))\n",
    "    #print(i)\n",
    "    #print(j)\n",
    "    #print(len(feats1))\n",
    "    \n",
    "    feats_dict = {}\n",
    "    \n",
    "    feats_dict['1plex_pos0']=feats1\n",
    "    feats_dict['1plex_pos1']=feats1\n",
    "    feats_dict['1plex_pos2']=feats1\n",
    "    feats_dict['1plex_pos3']=feats1\n",
    "        \n",
    "    return(feats_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_occ(df,feats_dict):\n",
    "    \n",
    "    fv = df['Sequence'].values\n",
    "    \n",
    "    occ = {}\n",
    "    \n",
    "    fv_1plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,4):\n",
    "            fv_1plex_list.append(fv[i][j:j+1])\n",
    "    #1-plex\n",
    "    for i in range(len(feats_dict['1plex'])):\n",
    "        feat = feats_dict['1plex'][i]\n",
    "        count = fv_1plex_list.count(feat)\n",
    "        occ[feat] = count\n",
    "        print(\"%s: %d\"%(feat,count))\n",
    "    \n",
    "    return(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_X(df,feats_dict):\n",
    "    n = df.shape[0]\n",
    "    d = 0\n",
    "    for feat_type in list(feats_dict):\n",
    "        d+=len(feats_dict[feat_type])\n",
    "    X = np.zeros((n,d))\n",
    "    print(np.shape(X))\n",
    "    \n",
    "    seqs = df[\"Sequence\"].values\n",
    "    i=0\n",
    "    for feat_type in list(feats_dict):\n",
    "        pos = int(feat_type[-1])\n",
    "        plex = int(feat_type[0])\n",
    "        for j in range(len(feats_dict[feat_type])):\n",
    "\n",
    "            for k in range(len(seqs)):\n",
    "                if feats_dict[feat_type][j] == seqs[k][pos:pos+plex]:\n",
    "                    X[k][i] = 1\n",
    "\n",
    "            if i%10==0:\n",
    "                print(i)\n",
    "            i+=1\n",
    "\n",
    "    return(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111999\n",
      "3\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "feats_dict = gen_feats_dict(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 80)\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "(48000, 80)\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "X_train_raw = gen_X(df_train,feats_dict)\n",
    "X_test_raw = gen_X(df_test,feats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 80)\n",
      "(112000,)\n",
      "(48000, 80)\n",
      "(112000, 80)\n",
      "(112000,)\n",
      "(48000, 80)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "holdout=False\n",
    "feat_sel1=False\n",
    "feat_sel2=False\n",
    "\n",
    "if holdout:\n",
    "    #make hold out\n",
    "    X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "        X_train_raw,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "    print(np.shape(X_train))\n",
    "    print(np.shape(X_hold))\n",
    "    print(np.sum(y_train))\n",
    "    print(np.sum(y_hold))\n",
    "    print(\"\\n\")\n",
    "else:\n",
    "    X_train = X_train_raw.copy()\n",
    "    \n",
    "X_test = X_test_raw.copy()\n",
    "    \n",
    "y_train = df_train['Active'].values\n",
    "n = float(np.shape(y_train)[0])    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "if feat_sel1:\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    X_train = model.transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    \n",
    "if feat_sel2:\n",
    "    #feature selection by conditional probability threshold\n",
    "    a = np.sum(X_train,axis=0)\n",
    "    b = np.sum(np.transpose(X_train)*y_train,axis=1)\n",
    "    print(np.shape(a))\n",
    "    print(np.shape(b))\n",
    "    c = b/a\n",
    "    d = np.argwhere(c>0.2).flatten()\n",
    "    \n",
    "    X_train = X_train[:,d]\n",
    "    X_test = X_test[:,d]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.065 GB of training data: 0.447 s\n",
      "Binning 0.007 GB of validation data: 0.008 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 90 leaves, max depth = 22, train loss: 0.09865, val loss: 0.10212, in 0.090s\n",
      "[2/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.07511, val loss: 0.07881, in 0.115s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.06237, val loss: 0.06578, in 0.090s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.05293, val loss: 0.05651, in 0.103s\n",
      "[5/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.04882, val loss: 0.05252, in 0.087s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.04393, val loss: 0.04753, in 0.088s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.04022, val loss: 0.04424, in 0.087s\n",
      "[8/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.03698, val loss: 0.04088, in 0.112s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03494, val loss: 0.03902, in 0.089s\n",
      "[10/200] 1 tree, 120 leaves, max depth = 25, train loss: 0.03307, val loss: 0.03704, in 0.082s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.03149, val loss: 0.03552, in 0.090s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.03033, val loss: 0.03428, in 0.111s\n",
      "[13/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.02922, val loss: 0.03315, in 0.084s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.02832, val loss: 0.03235, in 0.087s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.02746, val loss: 0.03164, in 0.086s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.02674, val loss: 0.03103, in 0.090s\n",
      "[17/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.02607, val loss: 0.03057, in 0.235s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02528, val loss: 0.02982, in 0.082s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02474, val loss: 0.02949, in 0.083s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02414, val loss: 0.02898, in 0.084s\n",
      "[21/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.02350, val loss: 0.02838, in 0.107s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02303, val loss: 0.02814, in 0.084s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02255, val loss: 0.02789, in 0.087s\n",
      "[24/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.02218, val loss: 0.02755, in 0.085s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02177, val loss: 0.02722, in 0.118s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02139, val loss: 0.02705, in 0.080s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02100, val loss: 0.02664, in 0.081s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02062, val loss: 0.02628, in 0.084s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02027, val loss: 0.02610, in 0.087s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 38, train loss: 0.01992, val loss: 0.02574, in 0.112s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01954, val loss: 0.02550, in 0.081s\n",
      "[32/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01923, val loss: 0.02530, in 0.088s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01891, val loss: 0.02482, in 0.090s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01862, val loss: 0.02461, in 0.108s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01834, val loss: 0.02445, in 0.085s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01806, val loss: 0.02418, in 0.086s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01781, val loss: 0.02401, in 0.092s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01756, val loss: 0.02379, in 0.109s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01734, val loss: 0.02367, in 0.082s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01711, val loss: 0.02353, in 0.087s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01686, val loss: 0.02325, in 0.093s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01663, val loss: 0.02313, in 0.110s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01640, val loss: 0.02297, in 0.081s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01616, val loss: 0.02282, in 0.095s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01596, val loss: 0.02270, in 0.087s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01574, val loss: 0.02260, in 0.087s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01554, val loss: 0.02245, in 0.115s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01534, val loss: 0.02242, in 0.088s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01517, val loss: 0.02240, in 0.087s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.01496, val loss: 0.02225, in 0.091s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01480, val loss: 0.02223, in 0.118s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01463, val loss: 0.02214, in 0.088s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01445, val loss: 0.02205, in 0.083s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01429, val loss: 0.02193, in 0.081s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.01415, val loss: 0.02182, in 0.103s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01396, val loss: 0.02176, in 0.085s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01382, val loss: 0.02163, in 0.083s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01367, val loss: 0.02144, in 0.083s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 21, train loss: 0.01352, val loss: 0.02142, in 0.104s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01339, val loss: 0.02142, in 0.082s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01326, val loss: 0.02127, in 0.082s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 37, train loss: 0.01314, val loss: 0.02128, in 0.082s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.01302, val loss: 0.02127, in 0.112s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01289, val loss: 0.02115, in 0.214s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01276, val loss: 0.02103, in 0.077s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01265, val loss: 0.02092, in 0.076s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01254, val loss: 0.02081, in 0.079s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01241, val loss: 0.02083, in 0.100s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01231, val loss: 0.02075, in 0.077s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01219, val loss: 0.02061, in 0.076s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01207, val loss: 0.02065, in 0.081s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.01195, val loss: 0.02056, in 0.102s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.01185, val loss: 0.02045, in 0.075s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01174, val loss: 0.02045, in 0.076s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01164, val loss: 0.02044, in 0.081s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01153, val loss: 0.02047, in 0.104s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01145, val loss: 0.02044, in 0.074s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 49, train loss: 0.01133, val loss: 0.02036, in 0.082s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01123, val loss: 0.02030, in 0.083s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.01113, val loss: 0.02027, in 0.084s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01103, val loss: 0.02028, in 0.104s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01095, val loss: 0.02027, in 0.079s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01085, val loss: 0.02028, in 0.079s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01076, val loss: 0.02021, in 0.083s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01067, val loss: 0.02015, in 0.100s\n",
      "[86/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01057, val loss: 0.02011, in 0.077s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01049, val loss: 0.02007, in 0.081s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01041, val loss: 0.02007, in 0.085s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01032, val loss: 0.01998, in 0.100s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01023, val loss: 0.01992, in 0.077s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01016, val loss: 0.01998, in 0.084s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01007, val loss: 0.01997, in 0.084s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01000, val loss: 0.01993, in 0.105s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00992, val loss: 0.01998, in 0.078s\n",
      "[95/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00984, val loss: 0.01991, in 0.083s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00977, val loss: 0.01989, in 0.081s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00968, val loss: 0.01988, in 0.081s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00961, val loss: 0.01983, in 0.108s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00953, val loss: 0.01984, in 0.081s\n",
      "[100/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00945, val loss: 0.01986, in 0.083s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.00938, val loss: 0.01975, in 0.087s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00931, val loss: 0.01977, in 0.104s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00925, val loss: 0.01966, in 0.082s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00918, val loss: 0.01963, in 0.086s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.00911, val loss: 0.01959, in 0.084s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00906, val loss: 0.01957, in 0.104s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00899, val loss: 0.01956, in 0.085s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00894, val loss: 0.01955, in 0.084s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00887, val loss: 0.01955, in 0.082s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00881, val loss: 0.01949, in 0.108s\n",
      "[111/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00875, val loss: 0.01945, in 0.216s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00870, val loss: 0.01947, in 0.080s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00865, val loss: 0.01948, in 0.077s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00859, val loss: 0.01945, in 0.077s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00852, val loss: 0.01939, in 0.100s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00847, val loss: 0.01935, in 0.076s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00841, val loss: 0.01932, in 0.076s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00835, val loss: 0.01937, in 0.081s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00828, val loss: 0.01935, in 0.103s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00823, val loss: 0.01929, in 0.076s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00817, val loss: 0.01927, in 0.078s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00813, val loss: 0.01925, in 0.083s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00808, val loss: 0.01923, in 0.102s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 46, train loss: 0.00802, val loss: 0.01917, in 0.077s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00796, val loss: 0.01916, in 0.082s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00791, val loss: 0.01912, in 0.085s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00787, val loss: 0.01917, in 0.094s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00781, val loss: 0.01914, in 0.108s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00777, val loss: 0.01909, in 0.078s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00772, val loss: 0.01910, in 0.084s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00767, val loss: 0.01912, in 0.084s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00762, val loss: 0.01906, in 0.101s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00757, val loss: 0.01905, in 0.082s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00753, val loss: 0.01903, in 0.087s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00748, val loss: 0.01906, in 0.083s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00744, val loss: 0.01906, in 0.103s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00739, val loss: 0.01909, in 0.083s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00735, val loss: 0.01908, in 0.084s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00730, val loss: 0.01900, in 0.086s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00726, val loss: 0.01901, in 0.107s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00723, val loss: 0.01901, in 0.082s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00718, val loss: 0.01903, in 0.083s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00713, val loss: 0.01902, in 0.083s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00710, val loss: 0.01902, in 0.109s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00705, val loss: 0.01899, in 0.078s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00702, val loss: 0.01897, in 0.082s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00698, val loss: 0.01896, in 0.086s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00694, val loss: 0.01896, in 0.085s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00690, val loss: 0.01897, in 0.114s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00686, val loss: 0.01896, in 0.084s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00682, val loss: 0.01894, in 0.083s\n",
      "[152/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00679, val loss: 0.01896, in 0.081s\n",
      "[153/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00676, val loss: 0.01896, in 0.106s\n",
      "[154/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00671, val loss: 0.01907, in 0.082s\n",
      "[155/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00668, val loss: 0.01900, in 0.082s\n",
      "[156/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00665, val loss: 0.01898, in 0.081s\n",
      "[157/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00661, val loss: 0.01896, in 0.107s\n",
      "[158/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00657, val loss: 0.01896, in 0.221s\n",
      "[159/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00654, val loss: 0.01895, in 0.080s\n",
      "[160/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00650, val loss: 0.01899, in 0.079s\n",
      "[161/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00646, val loss: 0.01899, in 0.077s\n",
      "Fit 161 trees in 15.386 s, (20403 total leaves)\n",
      "Time spent computing histograms: 8.422s\n",
      "Time spent finding best splits:  0.956s\n",
      "Time spent applying splits:      3.027s\n",
      "Time spent predicting:           0.055s\n",
      "Binning 0.052 GB of training data: 0.293 s\n",
      "Binning 0.006 GB of validation data: 0.010 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 91 leaves, max depth = 22, train loss: 0.09597, val loss: 0.10010, in 0.088s\n",
      "[2/200] 1 tree, 113 leaves, max depth = 33, train loss: 0.07591, val loss: 0.08070, in 0.064s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.06342, val loss: 0.06835, in 0.078s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.05500, val loss: 0.06144, in 0.071s\n",
      "[5/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.04829, val loss: 0.05398, in 0.102s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.04487, val loss: 0.05087, in 0.099s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.04163, val loss: 0.04813, in 0.070s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.03805, val loss: 0.04504, in 0.070s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.03561, val loss: 0.04258, in 0.072s\n",
      "[10/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.03371, val loss: 0.04079, in 0.098s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.03260, val loss: 0.04023, in 0.070s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03119, val loss: 0.03893, in 0.071s\n",
      "[13/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02989, val loss: 0.03776, in 0.075s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.02902, val loss: 0.03731, in 0.092s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02803, val loss: 0.03660, in 0.067s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.02710, val loss: 0.03555, in 0.073s\n",
      "[17/200] 1 tree, 122 leaves, max depth = 22, train loss: 0.02612, val loss: 0.03475, in 0.074s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02545, val loss: 0.03451, in 0.095s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.02482, val loss: 0.03401, in 0.067s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02428, val loss: 0.03365, in 0.076s\n",
      "[21/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02368, val loss: 0.03320, in 0.074s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02320, val loss: 0.03293, in 0.096s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.02275, val loss: 0.03261, in 0.068s\n",
      "[24/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02226, val loss: 0.03215, in 0.079s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02182, val loss: 0.03191, in 0.071s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.02143, val loss: 0.03167, in 0.071s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02101, val loss: 0.03128, in 0.097s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.02063, val loss: 0.03101, in 0.072s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02029, val loss: 0.03058, in 0.073s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01995, val loss: 0.03046, in 0.075s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01963, val loss: 0.03018, in 0.098s\n",
      "[32/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01935, val loss: 0.03012, in 0.075s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01902, val loss: 0.02997, in 0.074s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01869, val loss: 0.02962, in 0.071s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01842, val loss: 0.02958, in 0.103s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01817, val loss: 0.02935, in 0.076s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01786, val loss: 0.02909, in 0.073s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01764, val loss: 0.02911, in 0.076s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01741, val loss: 0.02892, in 0.098s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01719, val loss: 0.02874, in 0.071s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01694, val loss: 0.02858, in 0.072s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01673, val loss: 0.02852, in 0.077s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01649, val loss: 0.02834, in 0.075s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01628, val loss: 0.02812, in 0.226s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01610, val loss: 0.02794, in 0.070s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01588, val loss: 0.02773, in 0.068s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01569, val loss: 0.02759, in 0.071s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01554, val loss: 0.02748, in 0.092s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01533, val loss: 0.02738, in 0.068s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01516, val loss: 0.02727, in 0.067s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01499, val loss: 0.02730, in 0.078s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01483, val loss: 0.02726, in 0.096s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01466, val loss: 0.02712, in 0.066s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01450, val loss: 0.02705, in 0.071s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01435, val loss: 0.02689, in 0.072s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01419, val loss: 0.02668, in 0.078s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01405, val loss: 0.02665, in 0.087s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.01387, val loss: 0.02651, in 0.073s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01373, val loss: 0.02645, in 0.074s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01360, val loss: 0.02630, in 0.073s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01346, val loss: 0.02635, in 0.098s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01332, val loss: 0.02628, in 0.070s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01319, val loss: 0.02637, in 0.072s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01304, val loss: 0.02630, in 0.073s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01291, val loss: 0.02619, in 0.095s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01279, val loss: 0.02613, in 0.067s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01267, val loss: 0.02613, in 0.075s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01254, val loss: 0.02600, in 0.083s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 37, train loss: 0.01243, val loss: 0.02596, in 0.100s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01231, val loss: 0.02597, in 0.068s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01220, val loss: 0.02593, in 0.074s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01209, val loss: 0.02583, in 0.074s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01198, val loss: 0.02576, in 0.100s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01187, val loss: 0.02566, in 0.065s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01178, val loss: 0.02555, in 0.072s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01169, val loss: 0.02557, in 0.077s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01157, val loss: 0.02554, in 0.073s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01147, val loss: 0.02558, in 0.098s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01135, val loss: 0.02549, in 0.072s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01126, val loss: 0.02534, in 0.076s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01117, val loss: 0.02536, in 0.072s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01107, val loss: 0.02527, in 0.095s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01098, val loss: 0.02525, in 0.081s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01090, val loss: 0.02515, in 0.072s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01081, val loss: 0.02520, in 0.073s\n",
      "[86/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01072, val loss: 0.02512, in 0.099s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01063, val loss: 0.02506, in 0.072s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01054, val loss: 0.02509, in 0.072s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01046, val loss: 0.02503, in 0.073s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01038, val loss: 0.02491, in 0.101s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01031, val loss: 0.02490, in 0.210s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01021, val loss: 0.02483, in 0.074s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01014, val loss: 0.02486, in 0.068s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01007, val loss: 0.02490, in 0.071s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95/200] 1 tree, 127 leaves, max depth = 38, train loss: 0.00999, val loss: 0.02497, in 0.094s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00991, val loss: 0.02492, in 0.071s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00984, val loss: 0.02491, in 0.067s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00976, val loss: 0.02483, in 0.069s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00969, val loss: 0.02476, in 0.095s\n",
      "[100/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00961, val loss: 0.02477, in 0.067s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00954, val loss: 0.02476, in 0.070s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00947, val loss: 0.02468, in 0.070s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00940, val loss: 0.02458, in 0.099s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00934, val loss: 0.02467, in 0.066s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00927, val loss: 0.02463, in 0.070s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00920, val loss: 0.02462, in 0.071s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00914, val loss: 0.02461, in 0.078s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00908, val loss: 0.02458, in 0.098s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00902, val loss: 0.02454, in 0.073s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00896, val loss: 0.02453, in 0.076s\n",
      "[111/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00890, val loss: 0.02454, in 0.071s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00884, val loss: 0.02448, in 0.091s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00877, val loss: 0.02442, in 0.069s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00871, val loss: 0.02435, in 0.079s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 49, train loss: 0.00863, val loss: 0.02426, in 0.074s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00857, val loss: 0.02427, in 0.094s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00851, val loss: 0.02425, in 0.095s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00846, val loss: 0.02416, in 0.074s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00841, val loss: 0.02415, in 0.070s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00835, val loss: 0.02409, in 0.098s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00830, val loss: 0.02415, in 0.070s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00825, val loss: 0.02408, in 0.078s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00819, val loss: 0.02410, in 0.073s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00813, val loss: 0.02410, in 0.075s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00808, val loss: 0.02404, in 0.100s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00803, val loss: 0.02399, in 0.077s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 42, train loss: 0.00797, val loss: 0.02392, in 0.074s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00793, val loss: 0.02391, in 0.076s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00787, val loss: 0.02383, in 0.098s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00782, val loss: 0.02381, in 0.071s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00777, val loss: 0.02380, in 0.076s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00772, val loss: 0.02373, in 0.072s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00766, val loss: 0.02368, in 0.097s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00762, val loss: 0.02371, in 0.073s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00756, val loss: 0.02365, in 0.075s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00751, val loss: 0.02364, in 0.073s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00748, val loss: 0.02363, in 0.099s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00743, val loss: 0.02361, in 0.206s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00738, val loss: 0.02361, in 0.069s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00734, val loss: 0.02358, in 0.074s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00730, val loss: 0.02365, in 0.068s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00726, val loss: 0.02358, in 0.093s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 41, train loss: 0.00721, val loss: 0.02353, in 0.070s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00717, val loss: 0.02362, in 0.072s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00713, val loss: 0.02359, in 0.070s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00709, val loss: 0.02366, in 0.095s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.00704, val loss: 0.02359, in 0.075s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00700, val loss: 0.02360, in 0.070s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00696, val loss: 0.02354, in 0.072s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00692, val loss: 0.02355, in 0.094s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00688, val loss: 0.02352, in 0.070s\n",
      "[152/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00684, val loss: 0.02358, in 0.076s\n",
      "[153/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00680, val loss: 0.02362, in 0.079s\n",
      "[154/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00676, val loss: 0.02359, in 0.108s\n",
      "[155/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00672, val loss: 0.02357, in 0.074s\n",
      "[156/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.00668, val loss: 0.02349, in 0.076s\n",
      "[157/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00663, val loss: 0.02353, in 0.079s\n",
      "[158/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00660, val loss: 0.02352, in 0.080s\n",
      "[159/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00657, val loss: 0.02354, in 0.105s\n",
      "[160/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00654, val loss: 0.02347, in 0.080s\n",
      "[161/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00650, val loss: 0.02345, in 0.080s\n",
      "[162/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00646, val loss: 0.02348, in 0.080s\n",
      "[163/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00643, val loss: 0.02344, in 0.103s\n",
      "[164/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00640, val loss: 0.02340, in 0.078s\n",
      "[165/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00636, val loss: 0.02340, in 0.074s\n",
      "[166/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00633, val loss: 0.02341, in 0.071s\n",
      "[167/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.00629, val loss: 0.02334, in 0.094s\n",
      "[168/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00625, val loss: 0.02342, in 0.077s\n",
      "[169/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00622, val loss: 0.02343, in 0.076s\n",
      "[170/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00619, val loss: 0.02342, in 0.073s\n",
      "[171/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00616, val loss: 0.02337, in 0.098s\n",
      "[172/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.00612, val loss: 0.02337, in 0.069s\n",
      "[173/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00609, val loss: 0.02343, in 0.079s\n",
      "[174/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00605, val loss: 0.02341, in 0.073s\n",
      "[175/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00602, val loss: 0.02338, in 0.077s\n",
      "[176/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00598, val loss: 0.02337, in 0.102s\n",
      "[177/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00595, val loss: 0.02338, in 0.075s\n",
      "Fit 177 trees in 14.783 s, (22424 total leaves)\n",
      "Time spent computing histograms: 8.289s\n",
      "Time spent finding best splits:  0.983s\n",
      "Time spent applying splits:      2.805s\n",
      "Time spent predicting:           0.049s\n",
      "Binning 0.052 GB of training data: 0.285 s\n",
      "Binning 0.006 GB of validation data: 0.011 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 92 leaves, max depth = 22, train loss: 0.09513, val loss: 0.09936, in 0.068s\n",
      "[2/200] 1 tree, 107 leaves, max depth = 32, train loss: 0.07475, val loss: 0.07933, in 0.066s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.06232, val loss: 0.06710, in 0.096s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.05455, val loss: 0.06015, in 0.071s\n",
      "[5/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.04852, val loss: 0.05374, in 0.075s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.04520, val loss: 0.05078, in 0.072s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.04064, val loss: 0.04708, in 0.071s\n",
      "[8/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.03804, val loss: 0.04482, in 0.234s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.03649, val loss: 0.04350, in 0.071s\n",
      "[10/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.03410, val loss: 0.04106, in 0.069s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.03248, val loss: 0.03961, in 0.068s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.03092, val loss: 0.03832, in 0.089s\n",
      "[13/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.03000, val loss: 0.03776, in 0.069s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02877, val loss: 0.03644, in 0.072s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02764, val loss: 0.03538, in 0.073s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.02677, val loss: 0.03480, in 0.094s\n",
      "[17/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02614, val loss: 0.03435, in 0.068s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02549, val loss: 0.03395, in 0.073s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.02479, val loss: 0.03309, in 0.070s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 46, train loss: 0.02415, val loss: 0.03238, in 0.075s\n",
      "[21/200] 1 tree, 116 leaves, max depth = 23, train loss: 0.02351, val loss: 0.03192, in 0.095s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02301, val loss: 0.03184, in 0.072s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02253, val loss: 0.03157, in 0.069s\n",
      "[24/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.02202, val loss: 0.03100, in 0.074s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02162, val loss: 0.03100, in 0.096s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02109, val loss: 0.03062, in 0.070s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02069, val loss: 0.03019, in 0.073s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.02031, val loss: 0.02984, in 0.073s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01996, val loss: 0.02979, in 0.102s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01960, val loss: 0.02958, in 0.071s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01925, val loss: 0.02930, in 0.075s\n",
      "[32/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01896, val loss: 0.02907, in 0.078s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01866, val loss: 0.02888, in 0.098s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01827, val loss: 0.02863, in 0.068s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01798, val loss: 0.02850, in 0.077s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01770, val loss: 0.02823, in 0.077s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.01745, val loss: 0.02809, in 0.074s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01719, val loss: 0.02801, in 0.098s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01696, val loss: 0.02795, in 0.078s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01668, val loss: 0.02758, in 0.075s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.01647, val loss: 0.02761, in 0.075s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01620, val loss: 0.02734, in 0.104s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01598, val loss: 0.02718, in 0.077s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01575, val loss: 0.02693, in 0.077s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 37, train loss: 0.01555, val loss: 0.02681, in 0.077s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01536, val loss: 0.02666, in 0.104s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01517, val loss: 0.02650, in 0.075s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01498, val loss: 0.02640, in 0.077s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01481, val loss: 0.02631, in 0.077s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01462, val loss: 0.02624, in 0.101s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01444, val loss: 0.02614, in 0.076s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 37, train loss: 0.01429, val loss: 0.02604, in 0.077s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01414, val loss: 0.02590, in 0.078s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01398, val loss: 0.02588, in 0.076s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01381, val loss: 0.02583, in 0.236s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01366, val loss: 0.02576, in 0.072s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01352, val loss: 0.02570, in 0.072s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01339, val loss: 0.02561, in 0.075s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01327, val loss: 0.02556, in 0.094s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01312, val loss: 0.02540, in 0.072s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01301, val loss: 0.02541, in 0.111s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01288, val loss: 0.02542, in 0.146s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01274, val loss: 0.02538, in 0.175s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01262, val loss: 0.02537, in 0.121s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01249, val loss: 0.02532, in 0.140s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 48, train loss: 0.01236, val loss: 0.02519, in 0.178s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01223, val loss: 0.02510, in 0.140s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01212, val loss: 0.02507, in 0.104s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01202, val loss: 0.02512, in 0.118s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01191, val loss: 0.02519, in 0.103s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01181, val loss: 0.02520, in 0.099s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 37, train loss: 0.01168, val loss: 0.02518, in 0.105s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01156, val loss: 0.02499, in 0.086s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01146, val loss: 0.02495, in 0.096s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.01134, val loss: 0.02482, in 0.086s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01124, val loss: 0.02481, in 0.105s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01113, val loss: 0.02473, in 0.085s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01105, val loss: 0.02462, in 0.102s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01095, val loss: 0.02450, in 0.079s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01087, val loss: 0.02453, in 0.097s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01077, val loss: 0.02450, in 0.121s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.01067, val loss: 0.02440, in 0.081s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01058, val loss: 0.02433, in 0.079s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01047, val loss: 0.02424, in 0.113s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01038, val loss: 0.02435, in 0.079s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01029, val loss: 0.02429, in 0.092s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 48, train loss: 0.01020, val loss: 0.02421, in 0.118s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01012, val loss: 0.02411, in 0.076s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01005, val loss: 0.02413, in 0.114s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00997, val loss: 0.02405, in 0.239s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00989, val loss: 0.02406, in 0.188s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00981, val loss: 0.02403, in 0.177s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00974, val loss: 0.02404, in 0.237s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00966, val loss: 0.02404, in 0.221s\n",
      "[95/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.00957, val loss: 0.02399, in 0.189s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00950, val loss: 0.02402, in 0.174s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00944, val loss: 0.02400, in 0.214s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00936, val loss: 0.02388, in 0.172s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00929, val loss: 0.02393, in 0.213s\n",
      "[100/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00922, val loss: 0.02388, in 0.193s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00916, val loss: 0.02385, in 0.228s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00909, val loss: 0.02380, in 0.367s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00902, val loss: 0.02379, in 0.146s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00896, val loss: 0.02381, in 0.097s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00889, val loss: 0.02370, in 0.092s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.00882, val loss: 0.02371, in 0.146s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00875, val loss: 0.02376, in 0.087s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00868, val loss: 0.02370, in 0.080s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00861, val loss: 0.02368, in 0.075s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00855, val loss: 0.02364, in 0.122s\n",
      "[111/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00850, val loss: 0.02374, in 0.089s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00844, val loss: 0.02373, in 0.092s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00838, val loss: 0.02374, in 0.118s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00832, val loss: 0.02375, in 0.166s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00826, val loss: 0.02373, in 0.078s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00821, val loss: 0.02366, in 0.083s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00816, val loss: 0.02368, in 0.105s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00811, val loss: 0.02365, in 0.179s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00806, val loss: 0.02360, in 0.204s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00801, val loss: 0.02359, in 0.189s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00796, val loss: 0.02359, in 0.083s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00791, val loss: 0.02361, in 0.080s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00785, val loss: 0.02356, in 0.104s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00780, val loss: 0.02355, in 0.108s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00775, val loss: 0.02354, in 0.081s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00771, val loss: 0.02348, in 0.117s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00765, val loss: 0.02350, in 0.114s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00760, val loss: 0.02341, in 0.118s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00755, val loss: 0.02341, in 0.078s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00750, val loss: 0.02339, in 0.076s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00746, val loss: 0.02336, in 0.105s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00741, val loss: 0.02336, in 0.082s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00736, val loss: 0.02327, in 0.098s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00732, val loss: 0.02320, in 0.087s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00727, val loss: 0.02315, in 0.082s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00723, val loss: 0.02308, in 0.106s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00719, val loss: 0.02312, in 0.099s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00714, val loss: 0.02317, in 0.093s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00710, val loss: 0.02313, in 0.079s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00705, val loss: 0.02312, in 0.097s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00701, val loss: 0.02311, in 0.102s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00696, val loss: 0.02308, in 0.116s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00692, val loss: 0.02309, in 0.080s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00688, val loss: 0.02303, in 0.118s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 38, train loss: 0.00684, val loss: 0.02302, in 0.192s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00680, val loss: 0.02302, in 0.156s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00676, val loss: 0.02311, in 0.205s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00672, val loss: 0.02313, in 0.223s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00668, val loss: 0.02308, in 0.292s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00664, val loss: 0.02310, in 0.165s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00661, val loss: 0.02305, in 0.116s\n",
      "[152/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00657, val loss: 0.02304, in 0.105s\n",
      "[153/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00653, val loss: 0.02302, in 0.126s\n",
      "[154/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00649, val loss: 0.02304, in 0.104s\n",
      "[155/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00645, val loss: 0.02306, in 0.134s\n",
      "[156/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00642, val loss: 0.02308, in 0.106s\n",
      "Fit 156 trees in 17.748 s, (19746 total leaves)\n",
      "Time spent computing histograms: 9.348s\n",
      "Time spent finding best splits:  2.021s\n",
      "Time spent applying splits:      3.755s\n",
      "Time spent predicting:           0.050s\n",
      "Binning 0.052 GB of training data: 0.351 s\n",
      "Binning 0.006 GB of validation data: 0.008 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 90 leaves, max depth = 21, train loss: 0.09582, val loss: 0.10298, in 0.115s\n",
      "[2/200] 1 tree, 108 leaves, max depth = 31, train loss: 0.07655, val loss: 0.08159, in 0.089s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.06426, val loss: 0.06875, in 0.101s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.05554, val loss: 0.06018, in 0.106s\n",
      "[5/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.04841, val loss: 0.05359, in 0.104s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.04515, val loss: 0.05035, in 0.133s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.04145, val loss: 0.04690, in 0.102s\n",
      "[8/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.03875, val loss: 0.04447, in 0.101s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.03585, val loss: 0.04162, in 0.101s\n",
      "[10/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.03440, val loss: 0.04025, in 0.130s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03295, val loss: 0.03918, in 0.102s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.03144, val loss: 0.03757, in 0.109s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/200] 1 tree, 122 leaves, max depth = 25, train loss: 0.03014, val loss: 0.03666, in 0.103s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.02909, val loss: 0.03568, in 0.135s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02797, val loss: 0.03464, in 0.122s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02718, val loss: 0.03403, in 0.075s\n",
      "[17/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.02645, val loss: 0.03340, in 0.083s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02567, val loss: 0.03286, in 0.078s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.02494, val loss: 0.03194, in 0.104s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02434, val loss: 0.03142, in 0.077s\n",
      "[21/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02372, val loss: 0.03112, in 0.082s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02319, val loss: 0.03052, in 0.079s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02265, val loss: 0.03018, in 0.102s\n",
      "[24/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02214, val loss: 0.02992, in 0.081s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02175, val loss: 0.02974, in 0.080s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02129, val loss: 0.02938, in 0.077s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.02088, val loss: 0.02891, in 0.105s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02048, val loss: 0.02876, in 0.078s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02017, val loss: 0.02850, in 0.078s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01981, val loss: 0.02834, in 0.078s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01946, val loss: 0.02797, in 0.106s\n",
      "[32/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01912, val loss: 0.02773, in 0.076s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01882, val loss: 0.02763, in 0.079s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.01855, val loss: 0.02749, in 0.078s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01830, val loss: 0.02737, in 0.078s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01802, val loss: 0.02732, in 0.105s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01779, val loss: 0.02702, in 0.077s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01754, val loss: 0.02674, in 0.081s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01725, val loss: 0.02659, in 0.079s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01701, val loss: 0.02650, in 0.235s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01678, val loss: 0.02633, in 0.073s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01657, val loss: 0.02625, in 0.072s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01636, val loss: 0.02615, in 0.076s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01615, val loss: 0.02608, in 0.099s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01593, val loss: 0.02597, in 0.074s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01572, val loss: 0.02588, in 0.081s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01554, val loss: 0.02583, in 0.077s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01534, val loss: 0.02565, in 0.078s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.01514, val loss: 0.02559, in 0.093s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01497, val loss: 0.02551, in 0.076s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01478, val loss: 0.02535, in 0.075s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.01461, val loss: 0.02533, in 0.079s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 40, train loss: 0.01445, val loss: 0.02512, in 0.101s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01430, val loss: 0.02512, in 0.070s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01414, val loss: 0.02506, in 0.074s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01397, val loss: 0.02490, in 0.105s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01382, val loss: 0.02471, in 0.109s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01368, val loss: 0.02463, in 0.087s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01355, val loss: 0.02458, in 0.084s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01340, val loss: 0.02457, in 0.093s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 46, train loss: 0.01326, val loss: 0.02452, in 0.130s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01312, val loss: 0.02448, in 0.079s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01299, val loss: 0.02439, in 0.083s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01286, val loss: 0.02443, in 0.088s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01274, val loss: 0.02434, in 0.113s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01260, val loss: 0.02422, in 0.103s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01247, val loss: 0.02420, in 0.084s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01235, val loss: 0.02411, in 0.092s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01224, val loss: 0.02410, in 0.095s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01212, val loss: 0.02393, in 0.106s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01202, val loss: 0.02392, in 0.081s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01192, val loss: 0.02386, in 0.085s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01180, val loss: 0.02383, in 0.092s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01169, val loss: 0.02378, in 0.110s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01158, val loss: 0.02382, in 0.090s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01148, val loss: 0.02379, in 0.092s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01137, val loss: 0.02376, in 0.092s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01127, val loss: 0.02376, in 0.115s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01118, val loss: 0.02370, in 0.097s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01107, val loss: 0.02365, in 0.095s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01098, val loss: 0.02366, in 0.078s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01088, val loss: 0.02363, in 0.101s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01080, val loss: 0.02358, in 0.074s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01070, val loss: 0.02354, in 0.078s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.01062, val loss: 0.02346, in 0.076s\n",
      "[86/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01053, val loss: 0.02344, in 0.078s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01043, val loss: 0.02338, in 0.307s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01035, val loss: 0.02342, in 0.124s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01027, val loss: 0.02335, in 0.108s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01018, val loss: 0.02330, in 0.157s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01010, val loss: 0.02331, in 0.227s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01003, val loss: 0.02332, in 0.129s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00996, val loss: 0.02324, in 0.095s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00988, val loss: 0.02322, in 0.101s\n",
      "[95/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00981, val loss: 0.02320, in 0.113s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00973, val loss: 0.02318, in 0.094s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 21, train loss: 0.00966, val loss: 0.02320, in 0.092s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00958, val loss: 0.02317, in 0.159s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00952, val loss: 0.02315, in 0.165s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00945, val loss: 0.02308, in 0.137s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00938, val loss: 0.02311, in 0.088s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00931, val loss: 0.02305, in 0.102s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00925, val loss: 0.02309, in 0.096s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00918, val loss: 0.02304, in 0.099s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00911, val loss: 0.02307, in 0.083s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00905, val loss: 0.02302, in 0.184s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00899, val loss: 0.02296, in 0.147s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00892, val loss: 0.02298, in 0.129s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00886, val loss: 0.02294, in 0.169s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00879, val loss: 0.02282, in 0.160s\n",
      "[111/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00873, val loss: 0.02290, in 0.187s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 21, train loss: 0.00866, val loss: 0.02284, in 0.214s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00861, val loss: 0.02286, in 0.186s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00854, val loss: 0.02282, in 0.126s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00849, val loss: 0.02293, in 0.113s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00844, val loss: 0.02298, in 0.126s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00838, val loss: 0.02294, in 0.173s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00832, val loss: 0.02286, in 0.131s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00827, val loss: 0.02280, in 0.115s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00822, val loss: 0.02284, in 0.117s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00817, val loss: 0.02276, in 0.152s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00812, val loss: 0.02277, in 0.165s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00806, val loss: 0.02280, in 0.171s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00801, val loss: 0.02283, in 0.174s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00794, val loss: 0.02281, in 0.144s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00789, val loss: 0.02285, in 0.102s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 48, train loss: 0.00783, val loss: 0.02275, in 0.112s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00779, val loss: 0.02270, in 0.105s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00773, val loss: 0.02264, in 0.135s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00768, val loss: 0.02271, in 0.105s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00763, val loss: 0.02264, in 0.105s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00758, val loss: 0.02264, in 0.117s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00753, val loss: 0.02260, in 0.132s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00748, val loss: 0.02262, in 0.246s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00744, val loss: 0.02259, in 0.098s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00739, val loss: 0.02258, in 0.102s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00735, val loss: 0.02252, in 0.099s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00730, val loss: 0.02255, in 0.123s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 39, train loss: 0.00726, val loss: 0.02251, in 0.099s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00721, val loss: 0.02247, in 0.096s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00716, val loss: 0.02246, in 0.103s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00712, val loss: 0.02253, in 0.126s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00708, val loss: 0.02251, in 0.095s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00703, val loss: 0.02250, in 0.101s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00699, val loss: 0.02255, in 0.098s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00695, val loss: 0.02250, in 0.135s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00692, val loss: 0.02252, in 0.094s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00688, val loss: 0.02254, in 0.100s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00684, val loss: 0.02249, in 0.103s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00680, val loss: 0.02248, in 0.108s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00676, val loss: 0.02246, in 0.130s\n",
      "Fit 151 trees in 17.000 s, (19116 total leaves)\n",
      "Time spent computing histograms: 8.951s\n",
      "Time spent finding best splits:  2.042s\n",
      "Time spent applying splits:      3.376s\n",
      "Time spent predicting:           0.049s\n",
      "Binning 0.052 GB of training data: 0.358 s\n",
      "Binning 0.006 GB of validation data: 0.005 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 93 leaves, max depth = 21, train loss: 0.09557, val loss: 0.10146, in 0.078s\n",
      "[2/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.07469, val loss: 0.08054, in 0.104s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.06293, val loss: 0.06917, in 0.102s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.05536, val loss: 0.06212, in 0.133s\n",
      "[5/200] 1 tree, 126 leaves, max depth = 32, train loss: 0.04888, val loss: 0.05495, in 0.110s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.04398, val loss: 0.04955, in 0.094s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.04134, val loss: 0.04712, in 0.108s\n",
      "[8/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.03828, val loss: 0.04382, in 0.190s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.03623, val loss: 0.04188, in 0.098s\n",
      "[10/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.03426, val loss: 0.03984, in 0.102s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.03269, val loss: 0.03821, in 0.138s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.03167, val loss: 0.03736, in 0.161s\n",
      "[13/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03044, val loss: 0.03629, in 0.168s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 42, train loss: 0.02937, val loss: 0.03522, in 0.120s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.02823, val loss: 0.03445, in 0.149s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.02726, val loss: 0.03362, in 0.130s\n",
      "[17/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02650, val loss: 0.03277, in 0.190s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02571, val loss: 0.03233, in 0.164s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02497, val loss: 0.03189, in 0.116s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02431, val loss: 0.03153, in 0.148s\n",
      "[21/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02384, val loss: 0.03101, in 0.143s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.02328, val loss: 0.03059, in 0.116s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02275, val loss: 0.03028, in 0.098s\n",
      "[24/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02229, val loss: 0.03002, in 0.083s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02184, val loss: 0.02967, in 0.107s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02145, val loss: 0.02937, in 0.087s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.02105, val loss: 0.02919, in 0.088s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.02066, val loss: 0.02885, in 0.121s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02025, val loss: 0.02856, in 0.099s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01988, val loss: 0.02821, in 0.330s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01952, val loss: 0.02794, in 0.120s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01918, val loss: 0.02776, in 0.097s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01891, val loss: 0.02745, in 0.122s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01863, val loss: 0.02733, in 0.167s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01838, val loss: 0.02742, in 0.109s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 40, train loss: 0.01805, val loss: 0.02725, in 0.166s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01780, val loss: 0.02713, in 0.190s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01748, val loss: 0.02701, in 0.140s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01726, val loss: 0.02694, in 0.178s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01702, val loss: 0.02675, in 0.165s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01679, val loss: 0.02642, in 0.111s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.01659, val loss: 0.02637, in 0.110s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01639, val loss: 0.02638, in 0.130s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01615, val loss: 0.02609, in 0.077s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01595, val loss: 0.02599, in 0.074s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01576, val loss: 0.02588, in 0.078s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01558, val loss: 0.02586, in 0.119s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01536, val loss: 0.02568, in 0.159s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01520, val loss: 0.02555, in 0.110s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01501, val loss: 0.02559, in 0.106s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01482, val loss: 0.02547, in 0.146s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01466, val loss: 0.02525, in 0.160s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01450, val loss: 0.02518, in 0.119s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01434, val loss: 0.02515, in 0.111s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01418, val loss: 0.02505, in 0.132s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 43, train loss: 0.01400, val loss: 0.02486, in 0.106s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01385, val loss: 0.02484, in 0.134s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.01370, val loss: 0.02468, in 0.152s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01354, val loss: 0.02462, in 0.113s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01341, val loss: 0.02452, in 0.161s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01326, val loss: 0.02453, in 0.141s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01311, val loss: 0.02442, in 0.112s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01298, val loss: 0.02448, in 0.173s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01284, val loss: 0.02438, in 0.223s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01270, val loss: 0.02446, in 0.190s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.01258, val loss: 0.02440, in 0.114s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01245, val loss: 0.02434, in 0.142s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01234, val loss: 0.02440, in 0.139s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 44, train loss: 0.01219, val loss: 0.02430, in 0.126s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01206, val loss: 0.02409, in 0.087s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.01192, val loss: 0.02400, in 0.086s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01181, val loss: 0.02406, in 0.183s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01170, val loss: 0.02392, in 0.178s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01160, val loss: 0.02381, in 0.179s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01149, val loss: 0.02373, in 0.181s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01139, val loss: 0.02377, in 0.212s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01128, val loss: 0.02375, in 0.250s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01116, val loss: 0.02370, in 0.121s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01107, val loss: 0.02356, in 0.197s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01097, val loss: 0.02361, in 0.188s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01087, val loss: 0.02361, in 0.130s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 41, train loss: 0.01077, val loss: 0.02345, in 0.107s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01067, val loss: 0.02340, in 0.151s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01058, val loss: 0.02334, in 0.145s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01048, val loss: 0.02334, in 0.143s\n",
      "[86/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01039, val loss: 0.02338, in 0.101s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01030, val loss: 0.02333, in 0.108s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01022, val loss: 0.02337, in 0.187s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01015, val loss: 0.02332, in 0.215s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01007, val loss: 0.02327, in 0.144s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00999, val loss: 0.02319, in 0.107s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00990, val loss: 0.02312, in 0.109s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00982, val loss: 0.02316, in 0.147s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00974, val loss: 0.02315, in 0.146s\n",
      "[95/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00967, val loss: 0.02317, in 0.099s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00960, val loss: 0.02316, in 0.112s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00954, val loss: 0.02324, in 0.157s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00947, val loss: 0.02319, in 0.172s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00939, val loss: 0.02312, in 0.161s\n",
      "[100/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00932, val loss: 0.02320, in 0.113s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00924, val loss: 0.02309, in 0.115s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00918, val loss: 0.02305, in 0.166s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00910, val loss: 0.02297, in 0.146s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00903, val loss: 0.02299, in 0.109s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00897, val loss: 0.02297, in 0.150s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00890, val loss: 0.02295, in 0.170s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 36, train loss: 0.00883, val loss: 0.02297, in 0.104s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00878, val loss: 0.02291, in 0.127s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00871, val loss: 0.02280, in 0.128s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00865, val loss: 0.02276, in 0.114s\n",
      "[111/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00859, val loss: 0.02275, in 0.137s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00853, val loss: 0.02284, in 0.084s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00847, val loss: 0.02283, in 0.083s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00842, val loss: 0.02280, in 0.090s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00836, val loss: 0.02277, in 0.150s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00830, val loss: 0.02276, in 0.177s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00824, val loss: 0.02274, in 0.122s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00818, val loss: 0.02274, in 0.108s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00813, val loss: 0.02274, in 0.136s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 52, train loss: 0.00806, val loss: 0.02269, in 0.118s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00801, val loss: 0.02273, in 0.165s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00794, val loss: 0.02272, in 0.124s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00789, val loss: 0.02276, in 0.140s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00784, val loss: 0.02275, in 0.295s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00779, val loss: 0.02269, in 0.104s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00774, val loss: 0.02266, in 0.083s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00770, val loss: 0.02270, in 0.076s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00765, val loss: 0.02267, in 0.111s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00760, val loss: 0.02266, in 0.072s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00756, val loss: 0.02269, in 0.086s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00752, val loss: 0.02271, in 0.180s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00746, val loss: 0.02264, in 0.134s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00741, val loss: 0.02267, in 0.121s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00736, val loss: 0.02262, in 0.149s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00731, val loss: 0.02258, in 0.133s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00727, val loss: 0.02253, in 0.208s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00722, val loss: 0.02254, in 0.114s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00718, val loss: 0.02254, in 0.155s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00714, val loss: 0.02257, in 0.113s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00710, val loss: 0.02257, in 0.080s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.00705, val loss: 0.02246, in 0.099s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00701, val loss: 0.02255, in 0.152s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00697, val loss: 0.02252, in 0.117s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00693, val loss: 0.02253, in 0.116s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00689, val loss: 0.02250, in 0.162s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00685, val loss: 0.02253, in 0.131s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00681, val loss: 0.02247, in 0.128s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00677, val loss: 0.02248, in 0.106s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00674, val loss: 0.02242, in 0.173s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00671, val loss: 0.02240, in 0.097s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00666, val loss: 0.02246, in 0.085s\n",
      "[152/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00663, val loss: 0.02248, in 0.091s\n",
      "[153/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00659, val loss: 0.02248, in 0.116s\n",
      "[154/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00655, val loss: 0.02246, in 0.091s\n",
      "[155/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00651, val loss: 0.02245, in 0.088s\n",
      "[156/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00648, val loss: 0.02244, in 0.087s\n",
      "[157/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00644, val loss: 0.02238, in 0.083s\n",
      "[158/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00641, val loss: 0.02236, in 0.130s\n",
      "[159/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00637, val loss: 0.02237, in 0.105s\n",
      "[160/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00634, val loss: 0.02229, in 0.079s\n",
      "[161/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00631, val loss: 0.02230, in 0.079s\n",
      "[162/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00627, val loss: 0.02228, in 0.141s\n",
      "[163/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00624, val loss: 0.02227, in 0.158s\n",
      "[164/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00620, val loss: 0.02224, in 0.131s\n",
      "[165/200] 1 tree, 127 leaves, max depth = 39, train loss: 0.00617, val loss: 0.02216, in 0.095s\n",
      "[166/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00613, val loss: 0.02217, in 0.121s\n",
      "[167/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00610, val loss: 0.02213, in 0.166s\n",
      "[168/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00607, val loss: 0.02213, in 0.131s\n",
      "[169/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00604, val loss: 0.02214, in 0.091s\n",
      "[170/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00601, val loss: 0.02213, in 0.113s\n",
      "[171/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00598, val loss: 0.02216, in 0.218s\n",
      "[172/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00595, val loss: 0.02219, in 0.092s\n",
      "[173/200] 1 tree, 127 leaves, max depth = 42, train loss: 0.00591, val loss: 0.02217, in 0.116s\n",
      "[174/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00589, val loss: 0.02218, in 0.084s\n",
      "[175/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00585, val loss: 0.02219, in 0.101s\n",
      "[176/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00582, val loss: 0.02216, in 0.087s\n",
      "[177/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00579, val loss: 0.02215, in 0.100s\n",
      "Fit 177 trees in 23.642 s, (22444 total leaves)\n",
      "Time spent computing histograms: 12.072s\n",
      "Time spent finding best splits:  3.316s\n",
      "Time spent applying splits:      5.116s\n",
      "Time spent predicting:           0.063s\n",
      "Binning 0.052 GB of training data: 0.293 s\n",
      "Binning 0.006 GB of validation data: 0.008 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 92 leaves, max depth = 22, train loss: 0.09497, val loss: 0.09584, in 0.078s\n",
      "[2/200] 1 tree, 124 leaves, max depth = 34, train loss: 0.07557, val loss: 0.07633, in 0.089s\n",
      "[3/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.06425, val loss: 0.06685, in 0.098s\n",
      "[4/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.05592, val loss: 0.05947, in 0.075s\n",
      "[5/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.04854, val loss: 0.05202, in 0.078s\n",
      "[6/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.04525, val loss: 0.04940, in 0.079s\n",
      "[7/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.04148, val loss: 0.04605, in 0.108s\n",
      "[8/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03932, val loss: 0.04448, in 0.076s\n",
      "[9/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.03683, val loss: 0.04209, in 0.079s\n",
      "[10/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.03492, val loss: 0.04038, in 0.078s\n",
      "[11/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.03316, val loss: 0.03866, in 0.101s\n",
      "[12/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.03156, val loss: 0.03710, in 0.073s\n",
      "[13/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.03064, val loss: 0.03627, in 0.079s\n",
      "[14/200] 1 tree, 127 leaves, max depth = 47, train loss: 0.02944, val loss: 0.03518, in 0.081s\n",
      "[15/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.02847, val loss: 0.03423, in 0.103s\n",
      "[16/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.02764, val loss: 0.03351, in 0.076s\n",
      "[17/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.02675, val loss: 0.03275, in 0.081s\n",
      "[18/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.02596, val loss: 0.03213, in 0.081s\n",
      "[19/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02512, val loss: 0.03130, in 0.124s\n",
      "[20/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02459, val loss: 0.03092, in 0.098s\n",
      "[21/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02390, val loss: 0.03031, in 0.102s\n",
      "[22/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.02334, val loss: 0.02997, in 0.083s\n",
      "[23/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.02282, val loss: 0.02973, in 0.097s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02237, val loss: 0.02941, in 0.126s\n",
      "[25/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02181, val loss: 0.02894, in 0.093s\n",
      "[26/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.02140, val loss: 0.02877, in 0.097s\n",
      "[27/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.02104, val loss: 0.02833, in 0.094s\n",
      "[28/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02059, val loss: 0.02792, in 0.121s\n",
      "[29/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.02019, val loss: 0.02752, in 0.100s\n",
      "[30/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01986, val loss: 0.02733, in 0.098s\n",
      "[31/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01954, val loss: 0.02729, in 0.100s\n",
      "[32/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01922, val loss: 0.02693, in 0.127s\n",
      "[33/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01884, val loss: 0.02659, in 0.097s\n",
      "[34/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01856, val loss: 0.02639, in 0.098s\n",
      "[35/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01830, val loss: 0.02626, in 0.098s\n",
      "[36/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01802, val loss: 0.02609, in 0.147s\n",
      "[37/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01772, val loss: 0.02584, in 0.097s\n",
      "[38/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01748, val loss: 0.02579, in 0.100s\n",
      "[39/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01724, val loss: 0.02560, in 0.101s\n",
      "[40/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01701, val loss: 0.02545, in 0.101s\n",
      "[41/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01674, val loss: 0.02525, in 0.297s\n",
      "[42/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01656, val loss: 0.02514, in 0.099s\n",
      "[43/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01635, val loss: 0.02501, in 0.137s\n",
      "[44/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01610, val loss: 0.02485, in 0.094s\n",
      "[45/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01587, val loss: 0.02478, in 0.120s\n",
      "[46/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01567, val loss: 0.02463, in 0.093s\n",
      "[47/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01546, val loss: 0.02452, in 0.089s\n",
      "[48/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01528, val loss: 0.02438, in 0.098s\n",
      "[49/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01512, val loss: 0.02439, in 0.122s\n",
      "[50/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01492, val loss: 0.02420, in 0.089s\n",
      "[51/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01472, val loss: 0.02405, in 0.096s\n",
      "[52/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01455, val loss: 0.02392, in 0.090s\n",
      "[53/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01438, val loss: 0.02382, in 0.099s\n",
      "[54/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01421, val loss: 0.02370, in 0.122s\n",
      "[55/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.01407, val loss: 0.02362, in 0.091s\n",
      "[56/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.01392, val loss: 0.02358, in 0.091s\n",
      "[57/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01376, val loss: 0.02350, in 0.092s\n",
      "[58/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.01362, val loss: 0.02342, in 0.120s\n",
      "[59/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.01349, val loss: 0.02337, in 0.102s\n",
      "[60/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01336, val loss: 0.02324, in 0.185s\n",
      "[61/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01321, val loss: 0.02316, in 0.102s\n",
      "[62/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01307, val loss: 0.02312, in 0.164s\n",
      "[63/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01292, val loss: 0.02310, in 0.100s\n",
      "[64/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01280, val loss: 0.02310, in 0.101s\n",
      "[65/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.01266, val loss: 0.02296, in 0.101s\n",
      "[66/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01253, val loss: 0.02287, in 0.132s\n",
      "[67/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01240, val loss: 0.02284, in 0.091s\n",
      "[68/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.01228, val loss: 0.02279, in 0.122s\n",
      "[69/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01216, val loss: 0.02275, in 0.108s\n",
      "[70/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01204, val loss: 0.02270, in 0.098s\n",
      "[71/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01194, val loss: 0.02255, in 0.132s\n",
      "[72/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01182, val loss: 0.02251, in 0.100s\n",
      "[73/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.01172, val loss: 0.02244, in 0.098s\n",
      "[74/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01160, val loss: 0.02239, in 0.100s\n",
      "[75/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01151, val loss: 0.02238, in 0.136s\n",
      "[76/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.01140, val loss: 0.02232, in 0.102s\n",
      "[77/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01130, val loss: 0.02222, in 0.099s\n",
      "[78/200] 1 tree, 127 leaves, max depth = 45, train loss: 0.01118, val loss: 0.02215, in 0.105s\n",
      "[79/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01108, val loss: 0.02213, in 0.123s\n",
      "[80/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01100, val loss: 0.02210, in 0.099s\n",
      "[81/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.01089, val loss: 0.02208, in 0.103s\n",
      "[82/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01080, val loss: 0.02207, in 0.099s\n",
      "[83/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01072, val loss: 0.02198, in 0.126s\n",
      "[84/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01062, val loss: 0.02197, in 0.100s\n",
      "[85/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01053, val loss: 0.02199, in 0.099s\n",
      "[86/200] 1 tree, 127 leaves, max depth = 51, train loss: 0.01043, val loss: 0.02186, in 0.112s\n",
      "[87/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.01034, val loss: 0.02181, in 0.131s\n",
      "[88/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.01024, val loss: 0.02168, in 0.247s\n",
      "[89/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01016, val loss: 0.02155, in 0.093s\n",
      "[90/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.01009, val loss: 0.02157, in 0.093s\n",
      "[91/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.01001, val loss: 0.02157, in 0.098s\n",
      "[92/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00993, val loss: 0.02155, in 0.121s\n",
      "[93/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00986, val loss: 0.02161, in 0.094s\n",
      "[94/200] 1 tree, 127 leaves, max depth = 42, train loss: 0.00977, val loss: 0.02156, in 0.098s\n",
      "[95/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00970, val loss: 0.02166, in 0.094s\n",
      "[96/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00961, val loss: 0.02161, in 0.128s\n",
      "[97/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00954, val loss: 0.02159, in 0.099s\n",
      "[98/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00947, val loss: 0.02150, in 0.094s\n",
      "[99/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00940, val loss: 0.02140, in 0.098s\n",
      "[100/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00933, val loss: 0.02139, in 0.122s\n",
      "[101/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00925, val loss: 0.02134, in 0.090s\n",
      "[102/200] 1 tree, 127 leaves, max depth = 41, train loss: 0.00919, val loss: 0.02124, in 0.094s\n",
      "[103/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00912, val loss: 0.02123, in 0.094s\n",
      "[104/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00905, val loss: 0.02120, in 0.095s\n",
      "[105/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00899, val loss: 0.02116, in 0.131s\n",
      "[106/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00892, val loss: 0.02117, in 0.103s\n",
      "[107/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00886, val loss: 0.02116, in 0.146s\n",
      "[108/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00879, val loss: 0.02115, in 0.132s\n",
      "[109/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00873, val loss: 0.02108, in 0.151s\n",
      "[110/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00867, val loss: 0.02103, in 0.096s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00861, val loss: 0.02105, in 0.102s\n",
      "[112/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00856, val loss: 0.02103, in 0.090s\n",
      "[113/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00849, val loss: 0.02102, in 0.125s\n",
      "[114/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00843, val loss: 0.02100, in 0.100s\n",
      "[115/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00837, val loss: 0.02092, in 0.095s\n",
      "[116/200] 1 tree, 127 leaves, max depth = 24, train loss: 0.00831, val loss: 0.02095, in 0.102s\n",
      "[117/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00826, val loss: 0.02092, in 0.118s\n",
      "[118/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00821, val loss: 0.02088, in 0.073s\n",
      "[119/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00816, val loss: 0.02084, in 0.156s\n",
      "[120/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00810, val loss: 0.02084, in 0.138s\n",
      "[121/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00805, val loss: 0.02082, in 0.173s\n",
      "[122/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00800, val loss: 0.02085, in 0.161s\n",
      "[123/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00794, val loss: 0.02084, in 0.166s\n",
      "[124/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00789, val loss: 0.02082, in 0.177s\n",
      "[125/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00783, val loss: 0.02076, in 0.147s\n",
      "[126/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00778, val loss: 0.02074, in 0.198s\n",
      "[127/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00772, val loss: 0.02073, in 0.188s\n",
      "[128/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00767, val loss: 0.02075, in 0.195s\n",
      "[129/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00763, val loss: 0.02076, in 0.142s\n",
      "[130/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00758, val loss: 0.02075, in 0.156s\n",
      "[131/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00753, val loss: 0.02072, in 0.170s\n",
      "[132/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00749, val loss: 0.02069, in 0.106s\n",
      "[133/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00745, val loss: 0.02065, in 0.164s\n",
      "[134/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00740, val loss: 0.02061, in 0.117s\n",
      "[135/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00735, val loss: 0.02061, in 0.230s\n",
      "[136/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00731, val loss: 0.02054, in 0.096s\n",
      "[137/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00726, val loss: 0.02058, in 0.082s\n",
      "[138/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00723, val loss: 0.02060, in 0.080s\n",
      "[139/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00718, val loss: 0.02062, in 0.132s\n",
      "[140/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00714, val loss: 0.02057, in 0.127s\n",
      "[141/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00709, val loss: 0.02060, in 0.133s\n",
      "[142/200] 1 tree, 127 leaves, max depth = 47, train loss: 0.00704, val loss: 0.02052, in 0.104s\n",
      "[143/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.00699, val loss: 0.02048, in 0.123s\n",
      "[144/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.00696, val loss: 0.02051, in 0.094s\n",
      "[145/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00692, val loss: 0.02046, in 0.133s\n",
      "[146/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00688, val loss: 0.02048, in 0.098s\n",
      "[147/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00683, val loss: 0.02041, in 0.116s\n",
      "[148/200] 1 tree, 127 leaves, max depth = 35, train loss: 0.00679, val loss: 0.02041, in 0.093s\n",
      "[149/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00675, val loss: 0.02043, in 0.100s\n",
      "[150/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00672, val loss: 0.02041, in 0.086s\n",
      "[151/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00668, val loss: 0.02042, in 0.080s\n",
      "[152/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00665, val loss: 0.02045, in 0.115s\n",
      "[153/200] 1 tree, 127 leaves, max depth = 22, train loss: 0.00661, val loss: 0.02046, in 0.099s\n",
      "[154/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00658, val loss: 0.02049, in 0.100s\n",
      "[155/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00654, val loss: 0.02043, in 0.099s\n",
      "[156/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00650, val loss: 0.02040, in 0.109s\n",
      "[157/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00647, val loss: 0.02041, in 0.082s\n",
      "[158/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00644, val loss: 0.02041, in 0.086s\n",
      "[159/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00640, val loss: 0.02042, in 0.079s\n",
      "[160/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00636, val loss: 0.02042, in 0.112s\n",
      "[161/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00633, val loss: 0.02044, in 0.105s\n",
      "[162/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00629, val loss: 0.02041, in 0.086s\n",
      "[163/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00626, val loss: 0.02043, in 0.083s\n",
      "[164/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00622, val loss: 0.02040, in 0.105s\n",
      "[165/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00619, val loss: 0.02038, in 0.079s\n",
      "[166/200] 1 tree, 127 leaves, max depth = 33, train loss: 0.00616, val loss: 0.02037, in 0.079s\n",
      "[167/200] 1 tree, 127 leaves, max depth = 34, train loss: 0.00612, val loss: 0.02040, in 0.082s\n",
      "[168/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00608, val loss: 0.02037, in 0.107s\n",
      "[169/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00605, val loss: 0.02032, in 0.074s\n",
      "[170/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00602, val loss: 0.02030, in 0.080s\n",
      "[171/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00599, val loss: 0.02027, in 0.083s\n",
      "[172/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00596, val loss: 0.02023, in 0.079s\n",
      "[173/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00592, val loss: 0.02020, in 0.113s\n",
      "[174/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00590, val loss: 0.02023, in 0.081s\n",
      "[175/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00587, val loss: 0.02018, in 0.080s\n",
      "[176/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00584, val loss: 0.02019, in 0.079s\n",
      "[177/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00581, val loss: 0.02015, in 0.106s\n",
      "[178/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00578, val loss: 0.02018, in 0.079s\n",
      "[179/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00575, val loss: 0.02020, in 0.079s\n",
      "[180/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00572, val loss: 0.02012, in 0.081s\n",
      "[181/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00569, val loss: 0.02014, in 0.105s\n",
      "[182/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00566, val loss: 0.02011, in 0.219s\n",
      "[183/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00563, val loss: 0.02010, in 0.074s\n",
      "[184/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00561, val loss: 0.02009, in 0.073s\n",
      "[185/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00559, val loss: 0.02012, in 0.076s\n",
      "[186/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00556, val loss: 0.02013, in 0.100s\n",
      "[187/200] 1 tree, 127 leaves, max depth = 27, train loss: 0.00553, val loss: 0.02014, in 0.074s\n",
      "[188/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00551, val loss: 0.02012, in 0.075s\n",
      "[189/200] 1 tree, 127 leaves, max depth = 26, train loss: 0.00548, val loss: 0.02011, in 0.081s\n",
      "[190/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00545, val loss: 0.02006, in 0.099s\n",
      "[191/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00543, val loss: 0.02006, in 0.074s\n",
      "[192/200] 1 tree, 127 leaves, max depth = 25, train loss: 0.00540, val loss: 0.02011, in 0.080s\n",
      "[193/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00538, val loss: 0.02009, in 0.081s\n",
      "[194/200] 1 tree, 127 leaves, max depth = 28, train loss: 0.00535, val loss: 0.02005, in 0.102s\n",
      "[195/200] 1 tree, 127 leaves, max depth = 32, train loss: 0.00533, val loss: 0.02006, in 0.073s\n",
      "[196/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00530, val loss: 0.02007, in 0.081s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197/200] 1 tree, 127 leaves, max depth = 29, train loss: 0.00528, val loss: 0.02006, in 0.078s\n",
      "[198/200] 1 tree, 127 leaves, max depth = 23, train loss: 0.00526, val loss: 0.02007, in 0.104s\n",
      "[199/200] 1 tree, 127 leaves, max depth = 30, train loss: 0.00523, val loss: 0.02006, in 0.078s\n",
      "[200/200] 1 tree, 127 leaves, max depth = 31, train loss: 0.00520, val loss: 0.02007, in 0.076s\n",
      "Fit 200 trees in 21.833 s, (25362 total leaves)\n",
      "Time spent computing histograms: 11.824s\n",
      "Time spent finding best splits:  2.355s\n",
      "Time spent applying splits:      4.346s\n",
      "Time spent predicting:           0.065s\n",
      "train score= 0.998875\n",
      "cv roc auc= 0.997894\n",
      "cv acc= 0.992223\n",
      "cv rec= 0.863520\n",
      "cv prec= 0.924794\n",
      "y train:\n",
      "n pos 4213.000000\n",
      "frac pos 0.037616\n",
      "y train pred:\n",
      "n pos 4155.000000\n",
      "frac pos 0.037098\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hp_x = np.array([0.56])\n",
    "hp_metrics = [\n",
    "           'test_accuracy',\n",
    "           'test_recall',\n",
    "           'test_precision'\n",
    "          ]\n",
    "hp_y = np.zeros((hp_x.shape[0],len(hp_metrics)))\n",
    "\n",
    "for j in range(0,hp_x.shape[0]):\n",
    "\n",
    "    \"\"\"\n",
    "    clf_init = GaussianNB()\n",
    "    \n",
    "    clf_init = LinearSVC(\n",
    "        penalty='l1',\n",
    "        C=hp_x[j],\n",
    "        dual=False,\n",
    "        random_state=42,tol=1e-5)\n",
    "        \n",
    "    clf_init = LinearSVC(\n",
    "        C=hp_x[j],\n",
    "        class_weight='balanced',\n",
    "        random_state=42,tol=1e-5)\n",
    "        \n",
    "    clf_init = LinearSVC(\n",
    "        C=0.56,\n",
    "        class_weight={0:0.52,1:13.3*hp_x[j]},\n",
    "        random_state=42,tol=1e-5)\n",
    "    #tuning class weights didn't do too much\n",
    "        \n",
    "    HistGradientBoostingClassifier(random_state=42)\n",
    "    clf_init = HistGradientBoostingClassifier(verbose=10,random_state=42)\n",
    "    #too slow\n",
    "    \n",
    "    clf_init = BernoulliNB(class_prior=[1-hp_x[j],hp_x[j]])\n",
    "    #performance not as good\n",
    "    \n",
    "    clf_init = LinearSVC(\n",
    "        C=hp_x[j],\n",
    "        random_state=42,tol=1e-5)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    clf_init = HistGradientBoostingClassifier(\n",
    "        learning_rate = hp_x[j],\n",
    "        max_iter=200,\n",
    "        max_leaf_nodes=127,\n",
    "        min_samples_leaf=20,\n",
    "        l2_regularization=32.0,\n",
    "        verbose=10,\n",
    "        random_state=42)\n",
    "    \n",
    "    clf = clf_init.fit(X_train,y_train)\n",
    "    score = clf.score(X_train,y_train)\n",
    "\n",
    "    cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "            scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "    print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "    hp_y[j][0] = np.mean(cv_results['test_accuracy'])\n",
    "    \n",
    "    print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "    hp_y[j][1] = np.mean(cv_results['test_recall'])\n",
    "    \n",
    "    print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "    hp_y[j][2] = np.mean(cv_results['test_precision'])\n",
    "\n",
    "    #print(sigmoid(clf.decision_function(X_train)))\n",
    "    #p_train=clf.predict(X_train)\n",
    "\n",
    "    print(\"y train:\")\n",
    "    print(\"n pos %f\"%np.sum(y_train))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "    print(\"y train pred:\")\n",
    "    y_train_pred=clf.predict(X_train)\n",
    "    print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "    #p_train=clf.predict_proba(X_train)\n",
    "    #print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "    #print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "    #print(p_train)\n",
    "\n",
    "    #print(\"y test:\")\n",
    "    #p_test=clf.predict_proba(X_test)\n",
    "    #print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "    #print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "    if holdout:\n",
    "        #print(\"holdout metrics:\")\n",
    "        #holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "        #print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "        #holdout_aucs[i] = holdout_auc\n",
    "\n",
    "        y_hold_pred = clf.predict(X_hold)\n",
    "        holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout acc= %f\"%holdout_acc)\n",
    "        holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout rec= %f\"%holdout_rec)\n",
    "        holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout prec= %f\"%holdout_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train=clf.predict_proba(X_train)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n/(2*np.bincount(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y test pred:\n",
      "n pos 1700.000000\n",
      "frac pos 0.015179\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"y test pred:\")\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(\"n pos %f\"%np.sum(y_test_pred))\n",
    "print(\"frac pos %f\"%(np.sum(y_test_pred)/n) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = \"\"\n",
    "for i in range(len(y_test_pred)):\n",
    "    result_str+=str(y_test_pred[i])\n",
    "    result_str+=\"\\n\"\n",
    "\n",
    "submission = open(\"sub.csv\",\"w\")\n",
    "submission.write(result_str)\n",
    "submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56]\n",
      "[[0.99222321 0.86352045 0.92479429]]\n"
     ]
    }
   ],
   "source": [
    "#HIST GBDT l2, stepsize experiment, 200 trees/iter\n",
    "\n",
    "print(hp_x)\n",
    "print(hp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "for k in range(0,len(hp_metrics)):\n",
    "    ax1.plot(np.log10(hp_x),hp_y[:,k],label=hp_metrics[k])\n",
    "    \n",
    "f1 = 2*hp_y[:,1]*hp_y[:,2]/(hp_y[:,1]+hp_y[:,2])\n",
    "ax1.plot(np.log10(hp_x),f1,label=\"f1\")\n",
    "    \n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89310765])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_init = HistGradientBoostingClassifier(random_state=42)\n",
    "clf = fit_model1(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "score = clf.score(X_train,y_train)\n",
    "\n",
    "cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "        scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "print(\"train score= %f\"%score)\n",
    "print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "\n",
    "#print(sigmoid(clf.decision_function(X_train)))\n",
    "#p_train=clf.predict(X_train)\n",
    "\n",
    "print(\"y train:\")\n",
    "print(\"n pos %f\"%np.sum(y_train))\n",
    "print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "print(\"y train pred:\")\n",
    "y_train_pred=clf.predict(X_train)\n",
    "print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "p_train=clf.predict_proba(X_train)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "#print(p_train)\n",
    "\n",
    "print(\"y test:\")\n",
    "p_test=clf.predict_proba(X_test)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "if holdout:\n",
    "    print(\"holdout metrics:\")\n",
    "    holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "    print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "    holdout_aucs[i] = holdout_auc\n",
    "\n",
    "    y_hold_pred = clf.predict(X_hold)\n",
    "    holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout acc= %f\"%holdout_acc)\n",
    "    holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout rec= %f\"%holdout_rec)\n",
    "    holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout prec= %f\"%holdout_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = df_train[df_train['Active']==1]\n",
    "asv = active['Sequence'].values\n",
    "asv_str = ''.join(list(asv))\n",
    "asv_1plex = asv_str\n",
    "\n",
    "chars = ''.join(set(asv_str))\n",
    "feats1 = chars\n",
    "\n",
    "occ = {}\n",
    "\n",
    "#1-plex\n",
    "for i in range(len(chars)):\n",
    "    count = asv_str.count(chars[i])\n",
    "    occ[chars[i]] = count\n",
    "    print(\"%s: %d\"%(chars[i],count))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_2plex_list = []\n",
    "for i in range(len(asv)):\n",
    "    for j in range(0,3):\n",
    "        asv_2plex_list.append(asv[i][j:j+2])\n",
    "\n",
    "feats2 = list(set(asv_2plex_list))\n",
    "print(len(feats2))\n",
    "\n",
    "occ = {}\n",
    "#2-plex\n",
    "for i in range(len(feats2)):\n",
    "    count = asv_2plex_list.count(feats2[i])\n",
    "    occ[feats2[i]] = count\n",
    "    print(\"%s: %d\"%(feats2[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_3plex_list = []\n",
    "for i in range(len(asv)):\n",
    "    for j in range(0,2):\n",
    "        asv_3plex_list.append(asv[i][j:j+3])\n",
    "\n",
    "feats3 = list(set(asv_3plex_list))\n",
    "print(len(feats3))\n",
    "\n",
    "occ = {}\n",
    "#3-plex\n",
    "for i in range(len(feats3)):\n",
    "    count = asv_3plex_list.count(feats3[i])\n",
    "    occ[feats3[i]] = count\n",
    "    print(\"%s: %d\"%(feats3[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_2plex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2 = list(set(asv_2plex_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = df_train[df_train['Active']!=2]\n",
    "asv = active['Sequence'].values\n",
    "asv_str = ''.join(list(asv))\n",
    "chars = ''.join(set(asv_str))\n",
    "occ = {}\n",
    "for i in range(len(chars)):\n",
    "    count = asv_str.count(chars[i])\n",
    "    occ[chars[i]] = count\n",
    "    print(\"%s: %d\"%(chars[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train,X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return(X_train,X_test)\n",
    "    \n",
    "\n",
    "def impute(X_train,X_test):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_mean.fit(X_train)\n",
    "    \n",
    "    X_train = imp_mean.transform(X_train)\n",
    "    X_test = imp_mean.transform(X_test)\n",
    "\n",
    "    #print(X_train_imp)\n",
    "    return(X_train,X_test)\n",
    "\n",
    "def forest_fi(X_train,y_train,X_test):\n",
    "\n",
    "    forest = ExtraTreesClassifier(n_estimators=20,\n",
    "                                  random_state=0)\n",
    "\n",
    "    forest.fit(X_train,y_train)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    X_train = X_train[:,indices[:50]]\n",
    "    X_test = X_test[:,indices[:50]]\n",
    "    return(X_train,X_test)\n",
    "\n",
    "\n",
    "def nystroem(X_train,X_test):\n",
    "    gamma=1.0\n",
    "    n_components=100\n",
    "    print(\"nystroem gamma=%f\"%(gamma))\n",
    "    print(\"nystroem q=%d\"%(n_components))\n",
    "    feature_map_nystroem = Nystroem(gamma=gamma,\n",
    "                                    random_state=42,\n",
    "                                    n_components=n_components)\n",
    "    feature_map_nystroem.fit(X_train)\n",
    "    Q_train = feature_map_nystroem.transform(X_train)\n",
    "    sqrt_k_inv_train = np.linalg.inv(feature_map_nystroem.normalization_)\n",
    "    B_train = np.dot(Q_train,sqrt_k_inv_train)\n",
    "    K_train = np.dot(B_train,np.transpose(B_train))\n",
    "\n",
    "    Q_test = feature_map_nystroem.transform(X_test)\n",
    "    sqrt_k_inv_test = np.linalg.inv(feature_map_nystroem.normalization_)\n",
    "    B_test = np.dot(Q_test,sqrt_k_inv_test)\n",
    "    K_test = np.dot(B_test,np.transpose(B_train))\n",
    "    return(K_train,K_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1+np.exp(-x)))\n",
    "\n",
    "def fit_model1_1(X_train,y_train):\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
    "                                     max_depth=3, random_state=42).fit(X_train,y_train)\n",
    "    #clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "    #                                 max_depth=5, random_state=42).fit(X_train_imp,y_train)\n",
    "\n",
    "    return(clf)\n",
    "\n",
    "def fit_model1_2(X_train,y_train):\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=10,\n",
    "                  class_weight=\"balanced\",\n",
    "                  decision_function_shape='ovo').fit(X_train,y_train)\n",
    "    return(clf)\n",
    "\n",
    "def fit_model1(X_train,y_train,clf_init,sw_dict={}):\n",
    "    n = np.shape(y_train)[0]\n",
    "    w0 = n/(n-np.sum(y_train))\n",
    "    w1 = n/np.sum(y_train)\n",
    "    \n",
    "    sample_weight = np.zeros(len(y_train))\n",
    "    if not(sw_dict):\n",
    "        print(\"using default sample weights\")\n",
    "        sample_weight[y_train == 0] = w0\n",
    "        sample_weight[y_train == 1] = w1\n",
    "    else:\n",
    "        print(\"using custom sample weights\")\n",
    "        sample_weight[y_train == 0] = sw_dict[0]\n",
    "        sample_weight[y_train == 1] = sw_dict[1]\n",
    "    \n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = clf_init\n",
    "    #clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
    "    #                                 max_depth=3, random_state=42)\n",
    "    clf.fit(X_train,y_train,sample_weight=sample_weight)\n",
    "    #clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "    #                                 max_depth=5, random_state=42).fit(X_train_imp,y_train)\n",
    "\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2_1(X_train,y_train,hps):\n",
    "    C = hps[\"C\"]\n",
    "    #class_weight={1:16.5}\n",
    "    class_weight={1:hps[\"w1\"]}\n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=hps[\"C\"],\n",
    "                  kernel=\"rbf\",\n",
    "                  gamma=hps[\"gamma\"],\n",
    "                  class_weight=class_weight,\n",
    "                  decision_function_shape='ovo',\n",
    "                  verbose=True).fit(X_train,y_train)\n",
    "    print(\"C: %f\"%hps[\"C\"])\n",
    "    print(\"gamma: %f\"%hps[\"gamma\"])\n",
    "    print(\"Computed class weight: %s\"%(str(clf.class_weight_)))\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2_2(K_train,y_train):\n",
    "    C = 1.0\n",
    "    class_weight={1:17.5}\n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=C,\n",
    "                  kernel=\"precomputed\",\n",
    "                  class_weight=\"balanced\",\n",
    "                  decision_function_shape='ovo',\n",
    "                  verbose=True).fit(K_train,y_train)\n",
    "    print(\"C: %f\"%C)\n",
    "    print(\"Computed class weight: %s\"%(str(clf.class_weight_)))\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2(X_train,y_train,clf_init,sw_dict={}):\n",
    "    n = np.shape(y_train)[0]\n",
    "    w0 = n/(n-np.sum(y_train))\n",
    "    w1 = n/np.sum(y_train)\n",
    "    \n",
    "    sample_weight = np.zeros(len(y_train))\n",
    "    if not(sw_dict):\n",
    "        print(\"using default sample weights\")\n",
    "        sample_weight[y_train == 0] = w0\n",
    "        sample_weight[y_train == 1] = w1\n",
    "    else:\n",
    "        print(\"using custom sample weights\")\n",
    "        sample_weight[y_train == 0] = sw_dict[0]\n",
    "        sample_weight[y_train == 1] = sw_dict[1]\n",
    "    \n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = clf_init\n",
    "    clf.fit(X_train,y_train,sample_weight=sample_weight)\n",
    "    return(clf)\n",
    "\n",
    "def fit_model3(X_train,y_train):\n",
    "    #print(np.shape(y_train))\n",
    "    #print(np.sum(y_train))\n",
    "    reg = HistGradientBoostingRegressor(random_state=42).fit(X_train,y_train)\n",
    "    #reg = GradientBoostingRegressor(random_state=42).fit(X_train,y_train)\n",
    "    return(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pids = pd.unique(df_test_feats['pid'])\n",
    "\n",
    "df_test_labels = pd.DataFrame(columns=df_labels_cols)\n",
    "df_test_labels['pid'] = test_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_raw = feats_2_X1(df_train_feats,active_feats)\n",
    "X_test1_raw = feats_2_X1(df_test_feats,active_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train1_raw))\n",
    "print(np.shape(X_test1_raw))\n",
    "X_train_imp,X_test = impute(X_train1_raw,X_test1_raw)\n",
    "print(np.shape(X_train_imp))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "holdout_aucs = np.zeros(len(subtask1_labels))\n",
    "\n",
    "for i in range(0,len(subtask1_labels)):\n",
    "#for i in range(0,1):\n",
    "    print(\"i=%d\"%i)\n",
    "    y_train=df_train_labels[subtask1_labels[i]].values\n",
    "    n = float(np.shape(y_train)[0])\n",
    "\n",
    "    if holdout:\n",
    "        #make hold out\n",
    "        X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "            X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "        print(np.shape(X_train))\n",
    "        print(np.shape(X_hold))\n",
    "        print(np.sum(y_train))\n",
    "        print(np.sum(y_hold))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        X_train = X_train_imp\n",
    "\n",
    "    #sample weight\n",
    "    use_custom_sw = True\n",
    "    if use_custom_sw:\n",
    "        #sample weight\n",
    "        n = float(np.shape(y_train)[0])\n",
    "        w1_boost = 0.17\n",
    "\n",
    "        w0 = n/(n-np.sum(y_train))\n",
    "        w1 = (n/np.sum(y_train))*w1_boost\n",
    "        geo_mean = np.sqrt(w0*w1)\n",
    "        w0 /= geo_mean\n",
    "        w1 /= geo_mean\n",
    "    else:\n",
    "        w0=1.0\n",
    "        w1=1.0\n",
    "    \n",
    "    clf_init = HistGradientBoostingClassifier(random_state=42)\n",
    "    clf = fit_model1(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "    score = clf.score(X_train,y_train)\n",
    "    \n",
    "    cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "            scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "    \n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "    print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "    print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "    print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "    \n",
    "    #print(sigmoid(clf.decision_function(X_train)))\n",
    "    #p_train=clf.predict(X_train)\n",
    "    \n",
    "    print(\"y train:\")\n",
    "    print(\"n pos %f\"%np.sum(y_train))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "    \n",
    "    print(\"y train pred:\")\n",
    "    y_train_pred=clf.predict(X_train)\n",
    "    print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "    \n",
    "    p_train=clf.predict_proba(X_train)\n",
    "    print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "    print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "    \n",
    "    #print(p_train)\n",
    "    \n",
    "    print(\"y test:\")\n",
    "    p_test=clf.predict_proba(X_test)\n",
    "    print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "    print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "    \n",
    "    if holdout:\n",
    "        print(\"holdout metrics:\")\n",
    "        holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "        print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "        holdout_aucs[i] = holdout_auc\n",
    "\n",
    "        y_hold_pred = clf.predict(X_hold)\n",
    "        holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout acc= %f\"%holdout_acc)\n",
    "        holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout rec= %f\"%holdout_rec)\n",
    "        holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout prec= %f\"%holdout_prec)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    #y_test[:,1+i] = p_test[:,1]\n",
    "    \n",
    "    df_test_labels[subtask1_labels[i]] = p_test[:,1]\n",
    "    \n",
    "print(\"Hold out aucs and mean\")\n",
    "print(holdout_aucs)\n",
    "print(np.mean(holdout_aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_raw = feats_2_X2(df_train_feats,active_feats)\n",
    "X_test2_raw = feats_2_X2(df_test_feats,active_feats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train2_raw))\n",
    "print(np.shape(X_test2_raw))\n",
    "\n",
    "X_train_imp,X_test = impute(X_train2_raw,X_test2_raw)\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "#X_train,X_test = standardize(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "\n",
    "#X_train,X_test = nystroem(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "hp_x = np.array([0.05])\n",
    "hp_metrics = ['hold_roc_auc',\n",
    "           'hold_accuracy',\n",
    "           'hold_recall',\n",
    "           'hold_precision'\n",
    "          ]\n",
    "hp_y = np.zeros((hp_x.shape[0],len(hp_metrics)))\n",
    "\n",
    "for j in range(0,hp_x.shape[0]):\n",
    "    for i in range(0,len(subtask2_labels)):\n",
    "    #for i in range(0,1):\n",
    "        print(\"i=%d\"%i)\n",
    "        y_train=df_train_labels[subtask2_labels[i]].values\n",
    "        n = float(np.shape(y_train)[0])\n",
    "\n",
    "        if holdout:\n",
    "            #make hold out\n",
    "            X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "                X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "            print(np.shape(X_train))\n",
    "            print(np.shape(X_hold))\n",
    "            print(np.sum(y_train))\n",
    "            print(np.sum(y_hold))\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            X_train = X_train_imp\n",
    "\n",
    "        #sample weight\n",
    "        use_custom_sw = True\n",
    "        if use_custom_sw:\n",
    "            #sample weight\n",
    "            n = float(np.shape(y_train)[0])\n",
    "            w1_boost = 0.17\n",
    "\n",
    "            w0 = n/(n-np.sum(y_train))\n",
    "            w1 = (n/np.sum(y_train))*w1_boost\n",
    "            geo_mean = np.sqrt(w0*w1)\n",
    "            w0 /= geo_mean\n",
    "            w1 /= geo_mean\n",
    "        else:\n",
    "            w0=1.0\n",
    "            w1=1.0\n",
    "            \n",
    "        print(\"class weights: %f,%f\"%(w0,w1))\n",
    "\n",
    "        clf_init = HistGradientBoostingClassifier(\n",
    "            learning_rate=hp_x[j],random_state=42)\n",
    "        clf = fit_model2(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "        score = clf.score(X_train,y_train)\n",
    "\n",
    "        cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "                scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "        print(\"train score= %f\"%score)\n",
    "        print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "        print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "        print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "        print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "\n",
    "        #print(sigmoid(clf.decision_function(X_train)))\n",
    "        #p_train=clf.predict(X_train)\n",
    "\n",
    "        print(\"y train:\")\n",
    "        print(\"n pos %f\"%np.sum(y_train))\n",
    "        print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "        print(\"y train pred:\")\n",
    "        y_train_pred=clf.predict(X_train)\n",
    "        print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "        print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "        p_train=clf.predict_proba(X_train)\n",
    "        print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "        print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "        #print(p_train)\n",
    "\n",
    "        print(\"y test:\")\n",
    "        p_test=clf.predict_proba(X_test)\n",
    "        print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "        print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "        if holdout:\n",
    "\n",
    "            print(\"holdout metrics:\")\n",
    "            holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "            print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "            hp_y[j][0] = holdout_auc\n",
    "\n",
    "            y_hold_pred = clf.predict(X_hold)\n",
    "            holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout acc= %f\"%holdout_acc)\n",
    "            hp_y[j][1] = holdout_acc\n",
    "\n",
    "            holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout rec= %f\"%holdout_rec)\n",
    "            hp_y[j][2] = holdout_rec\n",
    "\n",
    "            holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout prec= %f\"%holdout_prec)\n",
    "            hp_y[j][3] = holdout_prec\n",
    "\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        #y_test[:,1+i] = p_test[:,1]\n",
    "\n",
    "        df_test_labels[subtask2_labels[i]] = p_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "for k in range(0,len(hp_metrics)):\n",
    "    ax1.plot(np.log10(hp_x),hp_y[:,k],label=hp_metrics[k])\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3_raw = feats_2_X3(df_train_feats,subtask3_feats)\n",
    "X_test3_raw = feats_2_X3(df_test_feats,subtask3_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train3_raw))\n",
    "print(np.shape(X_test3_raw))\n",
    "\n",
    "X_train_imp,X_test = impute(X_train3_raw,X_test3_raw)\n",
    "print(np.shape(X_train_imp))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "#X_train,X_test = standardize(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "\n",
    "\n",
    "holdout_r2s = np.zeros(len(subtask3_labels))\n",
    "\n",
    "for i in range(0,len(subtask3_labels)):\n",
    "#for i in range(0,1):\n",
    "    print(\"i=%d\"%i)\n",
    "    y_train=df_train_labels[subtask3_labels[i]].values\n",
    "    \n",
    "    if holdout:\n",
    "        #make hold out\n",
    "        X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "            X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "        print(np.shape(X_train))\n",
    "        print(np.shape(X_hold))\n",
    "        print(np.sum(y_train))\n",
    "        print(np.sum(y_hold))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        X_train = X_train_imp\n",
    "\n",
    "    reg = fit_model3(X_train,y_train)\n",
    "    \n",
    "    score = reg.score(X_train,y_train)\n",
    "    cv_results = cross_validate(reg,X_train,y_train,cv=5,\n",
    "            scoring=[\"r2\"])\n",
    "    \n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv r2= %f\"%np.mean(cv_results['test_r2']))\n",
    "    \n",
    "    y_train_pred=reg.predict(X_train)\n",
    "    print(np.mean(y_train_pred))\n",
    "    print(np.std(y_train_pred))\n",
    "    \n",
    "    y_test=reg.predict(X_test)\n",
    "    print(np.mean(y_test))\n",
    "    print(np.std(y_test))\n",
    "    \n",
    "    if holdout:\n",
    "        print(\"holdout metrics:\")\n",
    "        holdout_r2 = r2_score(y_hold,reg.predict(X_hold))\n",
    "        print(\"holdout roc auc= %f\"%holdout_r2)\n",
    "        holdout_r2s[i] = holdout_r2\n",
    "        #hp_y[j][0] = holdout_auc\n",
    "    \n",
    "    df_test_labels[subtask3_labels[i]] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels.to_csv('prediction_1904_8.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
