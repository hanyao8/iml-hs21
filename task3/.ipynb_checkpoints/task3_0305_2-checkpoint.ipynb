{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_auc_score, recall_score, \\\n",
    "    accuracy_score, precision_score, r2_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_3PLEX=True\n",
    "USE_1PLEX_POS=True\n",
    "USE_2PLEX_POS=True\n",
    "USE_3PLEX_POS=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"data/sample.csv\")\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#df_labels_cols = list(df_train_labels)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DKWL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCHN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KDQP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNWI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NKRM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111995</th>\n",
       "      <td>GSME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111996</th>\n",
       "      <td>DLPT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111997</th>\n",
       "      <td>SGHC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111998</th>\n",
       "      <td>KIGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111999</th>\n",
       "      <td>PGPT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sequence  Active\n",
       "0          DKWL       0\n",
       "1          FCHN       0\n",
       "2          KDQP       0\n",
       "3          FNWI       0\n",
       "4          NKRM       0\n",
       "...         ...     ...\n",
       "111995     GSME       0\n",
       "111996     DLPT       0\n",
       "111997     SGHC       0\n",
       "111998     KIGT       0\n",
       "111999     PGPT       0\n",
       "\n",
       "[112000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1\n",
       "0      0\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "...   ..\n",
       "47994  0\n",
       "47995  1\n",
       "47996  0\n",
       "47997  1\n",
       "47998  0\n",
       "\n",
       "[47999 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HWFK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MWPW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTLG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHYY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>NRWM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>MMMK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>AFNM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>CRYI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>MKFC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sequence\n",
       "0         HWFK\n",
       "1         MWPW\n",
       "2         ALDV\n",
       "3         NTLG\n",
       "4         LHYY\n",
       "...        ...\n",
       "47995     NRWM\n",
       "47996     MMMK\n",
       "47997     AFNM\n",
       "47998     CRYI\n",
       "47999     MKFC\n",
       "\n",
       "[48000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_feats_dict(df_train):\n",
    "    filtered = df_train[df_train['Active']==1]\n",
    "    fv = filtered['Sequence'].values\n",
    "    \n",
    "\n",
    "    fv_1plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,4):\n",
    "            fv_1plex_list.append(fv[i][j:j+1])\n",
    "    feats1 = list(set(fv_1plex_list))\n",
    "    print(len(feats1))\n",
    "        \n",
    "        \n",
    "    fv_2plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,3):\n",
    "            fv_2plex_list.append(fv[i][j:j+2])\n",
    "    feats2 = list(set(fv_2plex_list))\n",
    "    print(len(feats2))\n",
    "\n",
    "    feats_dict = {'1plex':feats1,\n",
    "                '2plex':feats2}\n",
    "\n",
    "    if USE_3PLEX:\n",
    "        fv_3plex_list = []\n",
    "        for i in range(len(fv)):\n",
    "            for j in range(0,2):\n",
    "                fv_3plex_list.append(fv[i][j:j+3])\n",
    "        feats3 = list(set(fv_3plex_list))\n",
    "        print(len(feats3))\n",
    "\n",
    "        feats_dict['3plex']=feats3\n",
    "    \n",
    "    if USE_1PLEX_POS:\n",
    "        feats_dict['1plex_pos0']=feats1\n",
    "        feats_dict['1plex_pos1']=feats1\n",
    "        feats_dict['1plex_pos2']=feats1\n",
    "        feats_dict['1plex_pos3']=feats1\n",
    "        \n",
    "    if USE_2PLEX_POS:\n",
    "        feats_dict['2plex_pos0']=feats2\n",
    "        feats_dict['2plex_pos1']=feats2\n",
    "        feats_dict['2plex_pos2']=feats2\n",
    "\n",
    "    if USE_3PLEX_POS:\n",
    "        feats_dict['3plex_pos0']=feats3\n",
    "        feats_dict['3plex_pos1']=feats3\n",
    "        \n",
    "    return(feats_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_occ(df,feats_dict):\n",
    "    \n",
    "    fv = df['Sequence'].values\n",
    "    \n",
    "    occ = {}\n",
    "    \n",
    "    fv_1plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,4):\n",
    "            fv_1plex_list.append(fv[i][j:j+1])\n",
    "    #1-plex\n",
    "    for i in range(len(feats_dict['1plex'])):\n",
    "        feat = feats_dict['1plex'][i]\n",
    "        count = fv_1plex_list.count(feat)\n",
    "        occ[feat] = count\n",
    "        print(\"%s: %d\"%(feat,count))\n",
    "        \n",
    "        \n",
    "    fv_2plex_list = []\n",
    "    for i in range(len(fv)):\n",
    "        for j in range(0,3):\n",
    "            fv_2plex_list.append(fv[i][j:j+2])\n",
    "    #2-plex\n",
    "    for i in range(len(feats_dict['2plex'])):\n",
    "        feat = feats_dict['2plex'][i]\n",
    "        count = fv_2plex_list.count(feat)\n",
    "        occ[feat] = count\n",
    "        print(\"%s: %d\"%(feat,count))\n",
    "\n",
    "        \n",
    "    if USE_3PLEX:\n",
    "        fv_3plex_list = []\n",
    "        for i in range(len(fv)):\n",
    "            for j in range(0,2):\n",
    "                fv_3plex_list.append(fv[i][j:j+3])\n",
    "        #3-plex\n",
    "        for i in range(len(feats_dict['3plex'])):\n",
    "            feat = feats_dict['3plex'][i]\n",
    "            count = fv_3plex_list.count(feat)\n",
    "            occ[feat] = count\n",
    "            print(\"%s: %d\"%(feat,count))\n",
    "            \n",
    "    \n",
    "    \n",
    "    return(occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_X(df,feats_dict):\n",
    "    n = df.shape[0]\n",
    "    d = 0\n",
    "    for feat_type in list(feats_dict):\n",
    "        d+=len(feats_dict[feat_type])\n",
    "    X = np.zeros((n,d))\n",
    "    print(np.shape(X))\n",
    "    \n",
    "    seqs = df[\"Sequence\"].values\n",
    "    i=0\n",
    "    for feat_type in list(feats_dict):\n",
    "        if 'plex_pos' in feat_type:\n",
    "            pos = int(feat_type[-1])\n",
    "            plex = int(feat_type[0])\n",
    "            for j in range(len(feats_dict[feat_type])):\n",
    "                \n",
    "                for k in range(len(seqs)):\n",
    "                    if feats_dict[feat_type][j] == seqs[k][pos:pos+plex]:\n",
    "                        X[k][i] = 1\n",
    "                        \n",
    "                if i%100==0:\n",
    "                    print(i)\n",
    "                i+=1\n",
    "\n",
    "        #elif\n",
    "        \n",
    "        else:\n",
    "            for j in range(len(feats_dict[feat_type])):\n",
    "                for k in range(len(seqs)):\n",
    "                    if feats_dict[feat_type][j] in seqs[k]:\n",
    "                        X[k][i] = 1\n",
    "\n",
    "                if i%100==0:\n",
    "                    print(i)\n",
    "                i+=1\n",
    "\n",
    "    return(X)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "389\n",
      "2354\n",
      "V: 985\n",
      "G: 2309\n",
      "Q: 385\n",
      "K: 335\n",
      "E: 298\n",
      "M: 1162\n",
      "T: 675\n",
      "A: 1836\n",
      "R: 388\n",
      "W: 851\n",
      "P: 99\n",
      "D: 253\n",
      "S: 620\n",
      "L: 1309\n",
      "F: 1201\n",
      "H: 496\n",
      "C: 1673\n",
      "N: 363\n",
      "Y: 815\n",
      "I: 799\n",
      "DW: 2\n",
      "IY: 37\n",
      "RA: 58\n",
      "TR: 8\n",
      "HD: 17\n",
      "QA: 32\n",
      "YV: 40\n",
      "YE: 13\n",
      "NR: 4\n",
      "EH: 13\n",
      "SH: 12\n",
      "VI: 22\n",
      "II: 23\n",
      "VR: 22\n",
      "IS: 30\n",
      "KY: 12\n",
      "AM: 82\n",
      "EV: 17\n",
      "PK: 3\n",
      "LA: 157\n",
      "YA: 69\n",
      "CY: 35\n",
      "GN: 47\n",
      "YG: 244\n",
      "FK: 17\n",
      "EQ: 12\n",
      "QK: 8\n",
      "LQ: 18\n",
      "QE: 6\n",
      "WR: 32\n",
      "CD: 11\n",
      "GG: 43\n",
      "WP: 2\n",
      "SW: 11\n",
      "DE: 3\n",
      "HS: 10\n",
      "VS: 28\n",
      "AE: 7\n",
      "KW: 9\n",
      "LR: 31\n",
      "GH: 22\n",
      "MF: 36\n",
      "HC: 45\n",
      "PA: 6\n",
      "YN: 24\n",
      "CV: 56\n",
      "GR: 2\n",
      "DA: 22\n",
      "YL: 38\n",
      "EG: 25\n",
      "TF: 30\n",
      "DS: 3\n",
      "SD: 2\n",
      "SK: 3\n",
      "NG: 71\n",
      "YY: 32\n",
      "WS: 30\n",
      "SQ: 2\n",
      "HE: 2\n",
      "DL: 27\n",
      "TQ: 8\n",
      "KD: 24\n",
      "HL: 39\n",
      "GQ: 21\n",
      "RY: 21\n",
      "ES: 15\n",
      "AD: 4\n",
      "FV: 90\n",
      "DD: 4\n",
      "FT: 113\n",
      "VC: 78\n",
      "FA: 139\n",
      "YH: 29\n",
      "FM: 26\n",
      "SY: 22\n",
      "PW: 3\n",
      "FF: 32\n",
      "RF: 41\n",
      "KM: 24\n",
      "VK: 20\n",
      "RK: 4\n",
      "VQ: 16\n",
      "GT: 93\n",
      "NM: 27\n",
      "QQ: 13\n",
      "KT: 2\n",
      "SL: 36\n",
      "TY: 11\n",
      "ER: 10\n",
      "GI: 58\n",
      "TV: 7\n",
      "SP: 1\n",
      "PD: 3\n",
      "SC: 42\n",
      "RL: 40\n",
      "YR: 28\n",
      "GE: 2\n",
      "LD: 18\n",
      "NF: 28\n",
      "KV: 8\n",
      "NI: 3\n",
      "WC: 86\n",
      "GV: 118\n",
      "TT: 6\n",
      "HA: 46\n",
      "HR: 9\n",
      "GF: 132\n",
      "KH: 8\n",
      "ML: 27\n",
      "AL: 72\n",
      "QW: 13\n",
      "WH: 33\n",
      "ME: 8\n",
      "CC: 166\n",
      "VY: 36\n",
      "TE: 2\n",
      "VM: 42\n",
      "SV: 9\n",
      "MC: 78\n",
      "HW: 15\n",
      "RG: 68\n",
      "DG: 25\n",
      "KG: 58\n",
      "WE: 12\n",
      "QD: 27\n",
      "PE: 3\n",
      "GW: 33\n",
      "ED: 12\n",
      "NN: 3\n",
      "RM: 26\n",
      "MI: 40\n",
      "PG: 8\n",
      "IN: 28\n",
      "FE: 13\n",
      "MR: 29\n",
      "WW: 39\n",
      "QY: 19\n",
      "TS: 11\n",
      "NS: 8\n",
      "TM: 10\n",
      "KN: 6\n",
      "LI: 30\n",
      "MQ: 23\n",
      "QG: 47\n",
      "IQ: 17\n",
      "KE: 2\n",
      "CM: 61\n",
      "LG: 223\n",
      "VF: 51\n",
      "DM: 18\n",
      "QS: 15\n",
      "SR: 7\n",
      "HK: 8\n",
      "TP: 1\n",
      "MP: 3\n",
      "IV: 26\n",
      "DQ: 3\n",
      "HM: 32\n",
      "CK: 13\n",
      "QI: 13\n",
      "WY: 47\n",
      "TG: 43\n",
      "CR: 16\n",
      "EL: 21\n",
      "PN: 2\n",
      "AN: 9\n",
      "RV: 12\n",
      "MN: 29\n",
      "VH: 23\n",
      "FD: 11\n",
      "RI: 10\n",
      "PF: 7\n",
      "SN: 4\n",
      "PT: 1\n",
      "MA: 147\n",
      "MD: 16\n",
      "CS: 59\n",
      "SE: 1\n",
      "SA: 88\n",
      "GK: 5\n",
      "AP: 2\n",
      "HV: 17\n",
      "EE: 5\n",
      "HY: 20\n",
      "RN: 8\n",
      "NL: 36\n",
      "GA: 104\n",
      "QP: 1\n",
      "AQ: 10\n",
      "HI: 16\n",
      "LH: 34\n",
      "VT: 15\n",
      "KF: 30\n",
      "IM: 41\n",
      "EA: 24\n",
      "CH: 23\n",
      "IH: 28\n",
      "AC: 126\n",
      "PS: 1\n",
      "MY: 22\n",
      "EY: 13\n",
      "TK: 7\n",
      "IG: 87\n",
      "WD: 23\n",
      "AH: 16\n",
      "AS: 66\n",
      "RR: 11\n",
      "HF: 43\n",
      "DH: 3\n",
      "TD: 3\n",
      "HQ: 7\n",
      "IE: 11\n",
      "WG: 119\n",
      "DR: 2\n",
      "TC: 32\n",
      "ND: 7\n",
      "TN: 11\n",
      "MW: 27\n",
      "KC: 41\n",
      "NC: 48\n",
      "AG: 160\n",
      "YT: 19\n",
      "HN: 14\n",
      "AW: 12\n",
      "RH: 8\n",
      "YP: 1\n",
      "IK: 22\n",
      "AV: 16\n",
      "GY: 16\n",
      "EW: 13\n",
      "KI: 8\n",
      "DK: 2\n",
      "LK: 25\n",
      "VP: 7\n",
      "LV: 62\n",
      "RQ: 2\n",
      "WT: 17\n",
      "DF: 19\n",
      "AR: 10\n",
      "LN: 29\n",
      "EM: 11\n",
      "ID: 20\n",
      "CA: 253\n",
      "PQ: 5\n",
      "PL: 6\n",
      "RE: 1\n",
      "AT: 26\n",
      "PH: 5\n",
      "WK: 29\n",
      "FW: 33\n",
      "FG: 308\n",
      "LY: 28\n",
      "LS: 41\n",
      "KS: 14\n",
      "AA: 207\n",
      "CW: 17\n",
      "SF: 51\n",
      "KA: 28\n",
      "IR: 27\n",
      "MH: 26\n",
      "MG: 165\n",
      "IC: 78\n",
      "QF: 28\n",
      "LE: 11\n",
      "HG: 120\n",
      "PY: 5\n",
      "QN: 10\n",
      "YK: 21\n",
      "DY: 10\n",
      "YD: 10\n",
      "AY: 29\n",
      "VL: 49\n",
      "CI: 42\n",
      "TH: 12\n",
      "WI: 36\n",
      "EN: 13\n",
      "QV: 15\n",
      "WV: 49\n",
      "GL: 154\n",
      "PM: 3\n",
      "VE: 11\n",
      "ET: 7\n",
      "KR: 8\n",
      "CE: 4\n",
      "ST: 1\n",
      "VN: 24\n",
      "HT: 4\n",
      "EK: 11\n",
      "WF: 57\n",
      "NW: 7\n",
      "KQ: 5\n",
      "EC: 35\n",
      "SI: 5\n",
      "NY: 10\n",
      "FN: 24\n",
      "NT: 1\n",
      "FI: 27\n",
      "RW: 12\n",
      "SM: 24\n",
      "LC: 113\n",
      "GC: 181\n",
      "NH: 5\n",
      "IL: 52\n",
      "TI: 7\n",
      "CT: 34\n",
      "GD: 1\n",
      "IT: 14\n",
      "QH: 17\n",
      "GS: 95\n",
      "CQ: 8\n",
      "VW: 31\n",
      "AI: 26\n",
      "MS: 48\n",
      "LM: 25\n",
      "QT: 4\n",
      "GP: 2\n",
      "HH: 13\n",
      "QL: 28\n",
      "RT: 3\n",
      "FP: 5\n",
      "PC: 13\n",
      "PP: 2\n",
      "TA: 25\n",
      "IP: 5\n",
      "VD: 20\n",
      "LF: 47\n",
      "CF: 49\n",
      "WL: 59\n",
      "VG: 130\n",
      "PV: 1\n",
      "YC: 73\n",
      "CL: 38\n",
      "WN: 25\n",
      "IW: 28\n",
      "LL: 47\n",
      "QC: 36\n",
      "MT: 47\n",
      "YI: 26\n",
      "WA: 68\n",
      "VV: 26\n",
      "YS: 22\n",
      "KL: 39\n",
      "EI: 12\n",
      "LW: 26\n",
      "NV: 5\n",
      "WQ: 21\n",
      "LT: 144\n",
      "GM: 201\n",
      "VA: 65\n",
      "NA: 53\n",
      "RS: 9\n",
      "YW: 30\n",
      "QM: 23\n",
      "FL: 34\n",
      "AF: 48\n",
      "RC: 54\n",
      "QR: 13\n",
      "IA: 67\n",
      "EP: 1\n",
      "IF: 59\n",
      "CN: 18\n",
      "MV: 42\n",
      "SS: 6\n",
      "TW: 12\n",
      "YF: 34\n",
      "KK: 6\n",
      "FC: 92\n",
      "NK: 2\n",
      "FS: 24\n",
      "WM: 36\n",
      "CG: 260\n",
      "FR: 22\n",
      "PI: 2\n",
      "MM: 27\n",
      "CP: 1\n",
      "AK: 11\n",
      "YQ: 18\n",
      "FH: 25\n",
      "DC: 34\n",
      "TL: 20\n",
      "LP: 17\n",
      "SG: 73\n",
      "EF: 28\n",
      "MK: 21\n",
      "FQ: 10\n",
      "FY: 30\n",
      "PR: 1\n",
      "NQ: 1\n",
      "YM: 32\n",
      "KAA: 5\n",
      "VEG: 2\n",
      "GLC: 1\n",
      "DMA: 4\n",
      "HWM: 1\n",
      "FLC: 4\n",
      "HHF: 1\n",
      "CHA: 4\n",
      "CNA: 5\n",
      "VMM: 1\n",
      "VTC: 2\n",
      "TCY: 1\n",
      "QGV: 5\n",
      "YQF: 1\n",
      "AAC: 6\n",
      "ANA: 2\n",
      "VAL: 8\n",
      "TIG: 2\n",
      "VQS: 1\n",
      "PYE: 1\n",
      "IWL: 2\n",
      "CWG: 4\n",
      "YTG: 4\n",
      "RNA: 2\n",
      "QWF: 1\n",
      "WRR: 1\n",
      "HMS: 1\n",
      "WGK: 1\n",
      "FAF: 4\n",
      "TCF: 1\n",
      "LFA: 7\n",
      "FYG: 14\n",
      "ECV: 1\n",
      "FCC: 13\n",
      "RRL: 1\n",
      "NMV: 1\n",
      "IAM: 11\n",
      "CPA: 1\n",
      "RMV: 1\n",
      "VGY: 1\n",
      "FTL: 2\n",
      "CWL: 3\n",
      "QAY: 1\n",
      "NIG: 1\n",
      "CGL: 11\n",
      "QIC: 3\n",
      "MDS: 1\n",
      "ISG: 5\n",
      "EWG: 4\n",
      "IIF: 1\n",
      "ILA: 10\n",
      "DHC: 1\n",
      "VMG: 12\n",
      "FGG: 4\n",
      "IHV: 1\n",
      "YTL: 1\n",
      "ALC: 5\n",
      "LAC: 6\n",
      "FTC: 1\n",
      "YCG: 16\n",
      "WMT: 5\n",
      "QRL: 3\n",
      "QIL: 3\n",
      "QSF: 2\n",
      "LAS: 1\n",
      "VKD: 1\n",
      "RCY: 1\n",
      "FEF: 3\n",
      "SGN: 1\n",
      "YSF: 5\n",
      "HHC: 1\n",
      "ENA: 1\n",
      "EQD: 2\n",
      "RSC: 1\n",
      "YCI: 3\n",
      "LQC: 4\n",
      "YKA: 2\n",
      "VHA: 6\n",
      "DAS: 3\n",
      "GAG: 3\n",
      "GKD: 1\n",
      "CLV: 2\n",
      "TIA: 1\n",
      "QWG: 6\n",
      "HHA: 1\n",
      "NNA: 1\n",
      "QGF: 2\n",
      "QGL: 5\n",
      "RHC: 1\n",
      "RCL: 2\n",
      "PAA: 5\n",
      "HYA: 3\n",
      "HYL: 1\n",
      "WQD: 2\n",
      "HND: 2\n",
      "TRF: 1\n",
      "APC: 1\n",
      "WCV: 4\n",
      "ACV: 3\n",
      "ALG: 9\n",
      "FCL: 2\n",
      "YAT: 2\n",
      "EMA: 3\n",
      "WFV: 7\n",
      "WTF: 5\n",
      "AKC: 1\n",
      "WCL: 6\n",
      "HTF: 1\n",
      "WYF: 3\n",
      "END: 1\n",
      "KMC: 3\n",
      "YWM: 3\n",
      "CTL: 1\n",
      "NGC: 10\n",
      "CTF: 3\n",
      "PFG: 2\n",
      "HCF: 2\n",
      "WSY: 1\n",
      "MHS: 1\n",
      "LKC: 3\n",
      "IMS: 3\n",
      "ANG: 2\n",
      "HRA: 2\n",
      "VIA: 4\n",
      "LHL: 4\n",
      "CLT: 6\n",
      "LCV: 1\n",
      "ESF: 2\n",
      "FQF: 2\n",
      "WSF: 7\n",
      "WMF: 3\n",
      "DFC: 1\n",
      "AFA: 6\n",
      "MQM: 2\n",
      "WCS: 5\n",
      "VRF: 3\n",
      "WKD: 1\n",
      "ARC: 2\n",
      "NCM: 5\n",
      "RMG: 7\n",
      "QNF: 1\n",
      "HHL: 1\n",
      "RHG: 6\n",
      "CVS: 1\n",
      "CGM: 13\n",
      "KAS: 2\n",
      "NAT: 2\n",
      "ASC: 1\n",
      "VWF: 3\n",
      "FSL: 4\n",
      "MKS: 1\n",
      "YWV: 1\n",
      "QPC: 1\n",
      "QAS: 1\n",
      "CKD: 1\n",
      "CNS: 1\n",
      "SAG: 8\n",
      "IIL: 2\n",
      "RGM: 13\n",
      "VGE: 1\n",
      "FFF: 1\n",
      "VKL: 2\n",
      "HAG: 11\n",
      "NLV: 3\n",
      "LMG: 7\n",
      "AMV: 1\n",
      "VMA: 12\n",
      "ICS: 6\n",
      "VVY: 1\n",
      "WHM: 4\n",
      "FRF: 3\n",
      "LVF: 4\n",
      "CDC: 1\n",
      "RFS: 1\n",
      "QYV: 1\n",
      "VYG: 18\n",
      "EQA: 1\n",
      "VRC: 1\n",
      "WIA: 3\n",
      "YTC: 2\n",
      "VEC: 2\n",
      "FTF: 2\n",
      "YWW: 1\n",
      "EFV: 3\n",
      "WWG: 7\n",
      "SHA: 1\n",
      "EMG: 4\n",
      "MEL: 2\n",
      "VGV: 7\n",
      "LTL: 4\n",
      "NHC: 1\n",
      "YIY: 1\n",
      "VCL: 3\n",
      "YNG: 6\n",
      "TLH: 1\n",
      "VAC: 10\n",
      "MFA: 6\n",
      "ERV: 1\n",
      "IQM: 2\n",
      "AEL: 1\n",
      "WVC: 6\n",
      "VVC: 3\n",
      "IVF: 2\n",
      "WGA: 6\n",
      "EKL: 2\n",
      "GFF: 1\n",
      "KKD: 1\n",
      "CLM: 1\n",
      "ASA: 3\n",
      "RNL: 1\n",
      "SDC: 2\n",
      "FAT: 1\n",
      "RFT: 9\n",
      "QIG: 2\n",
      "QSM: 1\n",
      "QRF: 1\n",
      "EQF: 2\n",
      "QTG: 1\n",
      "WEC: 2\n",
      "LHF: 4\n",
      "HVC: 2\n",
      "MNF: 3\n",
      "FHY: 1\n",
      "MQD: 1\n",
      "CDA: 2\n",
      "QHL: 1\n",
      "LIC: 5\n",
      "KHG: 6\n",
      "IRC: 4\n",
      "MRN: 1\n",
      "AMM: 2\n",
      "LIR: 1\n",
      "VDF: 2\n",
      "IPL: 1\n",
      "HGY: 1\n",
      "KNA: 2\n",
      "LMC: 4\n",
      "WIC: 6\n",
      "YSG: 5\n",
      "FVF: 4\n",
      "DKG: 1\n",
      "FCT: 1\n",
      "YGI: 13\n",
      "SRF: 1\n",
      "VGM: 12\n",
      "QQA: 1\n",
      "FQM: 1\n",
      "ATC: 2\n",
      "MLF: 1\n",
      "LKM: 3\n",
      "HNG: 3\n",
      "NLC: 4\n",
      "LTF: 2\n",
      "HNA: 4\n",
      "AGG: 2\n",
      "CVC: 2\n",
      "HRL: 1\n",
      "WCY: 2\n",
      "VDL: 3\n",
      "DEG: 1\n",
      "HWC: 2\n",
      "IGC: 16\n",
      "VFC: 6\n",
      "VNA: 5\n",
      "CHG: 7\n",
      "FFC: 4\n",
      "HFV: 6\n",
      "LEF: 2\n",
      "WIR: 1\n",
      "VQC: 1\n",
      "MAM: 3\n",
      "CFS: 1\n",
      "RSA: 6\n",
      "RWF: 1\n",
      "PHQ: 1\n",
      "WEM: 2\n",
      "RCT: 4\n",
      "TTG: 4\n",
      "ISY: 1\n",
      "MYM: 2\n",
      "MFT: 3\n",
      "NLA: 6\n",
      "KAY: 1\n",
      "FCA: 12\n",
      "CLA: 8\n",
      "LFL: 3\n",
      "EPL: 1\n",
      "PMH: 1\n",
      "AMG: 9\n",
      "FWF: 2\n",
      "LLL: 4\n",
      "AGT: 8\n",
      "CYA: 7\n",
      "NKC: 1\n",
      "ANF: 1\n",
      "YLT: 5\n",
      "IMT: 1\n",
      "CDM: 1\n",
      "QYL: 1\n",
      "MRF: 1\n",
      "CQY: 1\n",
      "YMT: 2\n",
      "VAT: 2\n",
      "YSL: 3\n",
      "FVC: 5\n",
      "LDG: 5\n",
      "YNC: 2\n",
      "CYL: 1\n",
      "RKD: 1\n",
      "VTS: 1\n",
      "KIL: 1\n",
      "CKL: 2\n",
      "MVL: 3\n",
      "EGV: 1\n",
      "YYF: 2\n",
      "EVG: 4\n",
      "LKF: 4\n",
      "VKC: 1\n",
      "GSV: 1\n",
      "WMC: 3\n",
      "ESL: 2\n",
      "YDA: 1\n",
      "TVG: 2\n",
      "RCF: 1\n",
      "DGT: 3\n",
      "AQF: 1\n",
      "WGT: 5\n",
      "ISA: 12\n",
      "HLG: 11\n",
      "ECC: 6\n",
      "LCF: 3\n",
      "LWG: 5\n",
      "QGG: 1\n",
      "FMF: 1\n",
      "EKD: 1\n",
      "IKY: 1\n",
      "LFF: 3\n",
      "TVC: 2\n",
      "PWQ: 1\n",
      "MRL: 4\n",
      "LSY: 2\n",
      "KGA: 6\n",
      "KMI: 1\n",
      "CSG: 5\n",
      "CGG: 1\n",
      "WSA: 3\n",
      "FRL: 3\n",
      "GMG: 1\n",
      "HVL: 3\n",
      "RGW: 1\n",
      "GQN: 1\n",
      "WRA: 3\n",
      "RTC: 1\n",
      "AGL: 6\n",
      "ECY: 1\n",
      "FYV: 1\n",
      "AWQ: 1\n",
      "ENC: 4\n",
      "LGC: 3\n",
      "INF: 3\n",
      "LQG: 6\n",
      "LCL: 3\n",
      "AYL: 3\n",
      "CSC: 1\n",
      "WKY: 1\n",
      "KFT: 7\n",
      "STC: 1\n",
      "FMV: 1\n",
      "KAC: 8\n",
      "MGT: 4\n",
      "TGN: 2\n",
      "LTC: 2\n",
      "YFA: 6\n",
      "YTF: 2\n",
      "MPC: 1\n",
      "DAA: 8\n",
      "KMG: 11\n",
      "QCI: 1\n",
      "CIG: 5\n",
      "FAA: 9\n",
      "AVA: 1\n",
      "KVC: 3\n",
      "ITC: 1\n",
      "MGS: 3\n",
      "SRL: 1\n",
      "YRM: 4\n",
      "IKG: 7\n",
      "IGN: 3\n",
      "WIL: 5\n",
      "IQG: 6\n",
      "NGI: 1\n",
      "VFV: 4\n",
      "HMV: 1\n",
      "VVV: 1\n",
      "VRM: 1\n",
      "VAI: 1\n",
      "QEC: 2\n",
      "YKF: 3\n",
      "GHN: 1\n",
      "VLC: 7\n",
      "RIY: 1\n",
      "YQD: 3\n",
      "YYL: 3\n",
      "CAM: 1\n",
      "WDC: 6\n",
      "CVF: 2\n",
      "MMC: 2\n",
      "MQS: 1\n",
      "QMF: 1\n",
      "YVA: 6\n",
      "RCV: 3\n",
      "WQF: 1\n",
      "GHK: 1\n",
      "MHD: 1\n",
      "RLP: 1\n",
      "QRM: 1\n",
      "SGI: 4\n",
      "KFG: 14\n",
      "ICL: 2\n",
      "TPC: 1\n",
      "LKA: 2\n",
      "LRL: 6\n",
      "EDC: 2\n",
      "KCG: 10\n",
      "IAC: 7\n",
      "FWW: 1\n",
      "VYT: 4\n",
      "CLF: 1\n",
      "HQC: 1\n",
      "IIV: 1\n",
      "HFA: 8\n",
      "MYC: 5\n",
      "IKD: 1\n",
      "VGN: 1\n",
      "ELL: 1\n",
      "GAC: 1\n",
      "RWV: 1\n",
      "GAA: 4\n",
      "FKC: 3\n",
      "VIL: 3\n",
      "MHF: 2\n",
      "RNC: 2\n",
      "MHL: 3\n",
      "GGS: 1\n",
      "HCI: 1\n",
      "ELG: 7\n",
      "MNA: 3\n",
      "PDH: 1\n",
      "SWL: 1\n",
      "MHG: 6\n",
      "FDL: 2\n",
      "QMA: 8\n",
      "FSC: 2\n",
      "TVF: 1\n",
      "KAG: 7\n",
      "WMI: 1\n",
      "RMI: 1\n",
      "WNM: 4\n",
      "INS: 1\n",
      "WSC: 3\n",
      "DLV: 1\n",
      "YEG: 3\n",
      "TAA: 11\n",
      "HLP: 1\n",
      "CSL: 1\n",
      "TVA: 1\n",
      "FCG: 19\n",
      "FNM: 3\n",
      "EYL: 2\n",
      "EEC: 2\n",
      "DGS: 5\n",
      "MRM: 3\n",
      "VGC: 14\n",
      "FRA: 4\n",
      "HIL: 2\n",
      "WDR: 1\n",
      "VPG: 2\n",
      "QCM: 1\n",
      "VSC: 2\n",
      "NAC: 8\n",
      "YWC: 7\n",
      "THQ: 1\n",
      "IWM: 1\n",
      "MWF: 3\n",
      "ISL: 4\n",
      "KFC: 1\n",
      "CFL: 1\n",
      "LLA: 7\n",
      "NGA: 5\n",
      "DFG: 10\n",
      "RIL: 1\n",
      "WYA: 5\n",
      "MNS: 1\n",
      "AHA: 2\n",
      "VCM: 6\n",
      "FLF: 2\n",
      "CNY: 1\n",
      "WEL: 3\n",
      "RAC: 9\n",
      "VGS: 6\n",
      "VCC: 14\n",
      "CCA: 15\n",
      "YKL: 3\n",
      "MGF: 1\n",
      "AGM: 15\n",
      "LQA: 1\n",
      "VKA: 3\n",
      "RKC: 1\n",
      "KSC: 1\n",
      "TKD: 1\n",
      "KWL: 1\n",
      "ELA: 4\n",
      "MKL: 3\n",
      "PGA: 2\n",
      "FGS: 6\n",
      "TKC: 3\n",
      "ACT: 2\n",
      "QTC: 1\n",
      "FMG: 13\n",
      "YGF: 14\n",
      "CGC: 11\n",
      "ECG: 10\n",
      "EVY: 1\n",
      "AFC: 6\n",
      "FKM: 1\n",
      "FEG: 3\n",
      "WLT: 7\n",
      "LGS: 3\n",
      "AHG: 3\n",
      "EAV: 1\n",
      "FAL: 3\n",
      "AVM: 1\n",
      "ESC: 2\n",
      "SRC: 2\n",
      "DMG: 9\n",
      "LKG: 5\n",
      "FMC: 2\n",
      "YVG: 16\n",
      "CIL: 3\n",
      "EGT: 1\n",
      "PYN: 1\n",
      "EQK: 1\n",
      "FQD: 1\n",
      "EDD: 1\n",
      "RWY: 1\n",
      "HSG: 2\n",
      "TGC: 11\n",
      "SQC: 1\n",
      "WWC: 7\n",
      "NKD: 1\n",
      "VLP: 2\n",
      "YHD: 4\n",
      "VHS: 1\n",
      "FLM: 2\n",
      "HTA: 1\n",
      "SAC: 4\n",
      "WFP: 1\n",
      "ASL: 1\n",
      "MSA: 5\n",
      "ERC: 2\n",
      "IEY: 1\n",
      "QEF: 1\n",
      "GAF: 1\n",
      "MYA: 3\n",
      "MEF: 1\n",
      "LLH: 1\n",
      "SAF: 1\n",
      "WKG: 3\n",
      "QCA: 11\n",
      "DYH: 1\n",
      "LNY: 1\n",
      "WTL: 4\n",
      "NHG: 4\n",
      "VDA: 3\n",
      "QCG: 10\n",
      "FGC: 12\n",
      "HFL: 1\n",
      "WTG: 3\n",
      "YCM: 6\n",
      "EVA: 2\n",
      "MCF: 3\n",
      "SFC: 7\n",
      "GRF: 2\n",
      "LKL: 5\n",
      "CFM: 1\n",
      "PNQ: 1\n",
      "IGS: 6\n",
      "WNW: 1\n",
      "QNL: 1\n",
      "SQF: 1\n",
      "QMC: 2\n",
      "CAL: 3\n",
      "KRY: 1\n",
      "CFC: 2\n",
      "AIL: 1\n",
      "YNA: 5\n",
      "WCF: 5\n",
      "RGF: 7\n",
      "EQL: 2\n",
      "HGT: 9\n",
      "ERA: 1\n",
      "AIY: 1\n",
      "QWY: 1\n",
      "THG: 9\n",
      "SCC: 10\n",
      "EEG: 2\n",
      "FWA: 4\n",
      "TSL: 1\n",
      "LTM: 1\n",
      "WLS: 2\n",
      "HNF: 1\n",
      "GYF: 1\n",
      "DHD: 1\n",
      "CIM: 2\n",
      "LPC: 2\n",
      "NAL: 3\n",
      "RGN: 1\n",
      "HGL: 13\n",
      "MIL: 3\n",
      "HGM: 14\n",
      "FGA: 7\n",
      "PQI: 1\n",
      "VVM: 2\n",
      "ACC: 7\n",
      "TRG: 3\n",
      "CAS: 2\n",
      "QVY: 2\n",
      "WWW: 2\n",
      "ADC: 2\n",
      "SFS: 1\n",
      "MKG: 7\n",
      "NMA: 9\n",
      "HDG: 1\n",
      "LWL: 3\n",
      "VWA: 6\n",
      "SFV: 6\n",
      "GCG: 3\n",
      "DMC: 1\n",
      "IYM: 1\n",
      "FMT: 1\n",
      "KCM: 3\n",
      "MCN: 1\n",
      "GFA: 2\n",
      "TDF: 1\n",
      "LYA: 5\n",
      "VGA: 9\n",
      "CAY: 1\n",
      "MRA: 4\n",
      "KYL: 1\n",
      "AQA: 1\n",
      "WYG: 18\n",
      "NNC: 2\n",
      "DCI: 1\n",
      "FCS: 2\n",
      "TNA: 1\n",
      "KIF: 1\n",
      "LAL: 3\n",
      "CFG: 20\n",
      "LRM: 4\n",
      "WFG: 17\n",
      "ELT: 4\n",
      "YMC: 3\n",
      "LWA: 4\n",
      "FNL: 2\n",
      "CAT: 1\n",
      "SGS: 5\n",
      "TEG: 2\n",
      "EIF: 1\n",
      "ATG: 1\n",
      "VAA: 16\n",
      "KAT: 1\n",
      "AHV: 1\n",
      "AYY: 1\n",
      "IWF: 1\n",
      "YLC: 7\n",
      "LAF: 4\n",
      "HLF: 1\n",
      "YCC: 12\n",
      "MNY: 1\n",
      "CRC: 2\n",
      "HKA: 1\n",
      "WGN: 8\n",
      "IAL: 7\n",
      "LFG: 19\n",
      "WGY: 5\n",
      "QGA: 6\n",
      "SGC: 11\n",
      "PFD: 1\n",
      "WCG: 23\n",
      "MFV: 1\n",
      "HMI: 1\n",
      "LEL: 2\n",
      "YAI: 3\n",
      "LIF: 3\n",
      "LDY: 1\n",
      "PPE: 1\n",
      "WDA: 1\n",
      "EWV: 1\n",
      "IQY: 1\n",
      "ARF: 1\n",
      "WVY: 3\n",
      "NGT: 7\n",
      "VYL: 1\n",
      "DGC: 3\n",
      "EYV: 1\n",
      "YAY: 1\n",
      "PED: 2\n",
      "VYA: 9\n",
      "SGL: 9\n",
      "TVL: 1\n",
      "ADL: 1\n",
      "YGN: 11\n",
      "IDF: 1\n",
      "YKD: 2\n",
      "VGI: 4\n",
      "CCL: 2\n",
      "WCA: 14\n",
      "QGM: 10\n",
      "MKF: 2\n",
      "RMC: 4\n",
      "GYH: 1\n",
      "RGG: 2\n",
      "EIL: 2\n",
      "VWM: 2\n",
      "FSG: 8\n",
      "WWL: 6\n",
      "HCA: 11\n",
      "WDG: 1\n",
      "KSY: 1\n",
      "CFV: 5\n",
      "IYV: 2\n",
      "GQQ: 1\n",
      "AGC: 6\n",
      "VIC: 5\n",
      "AWG: 2\n",
      "NCA: 13\n",
      "AQL: 1\n",
      "LLT: 7\n",
      "GKF: 1\n",
      "RSG: 2\n",
      "LTG: 3\n",
      "WNL: 6\n",
      "VLV: 4\n",
      "IYA: 6\n",
      "SFP: 1\n",
      "LFY: 1\n",
      "LAG: 8\n",
      "AIM: 2\n",
      "QQG: 2\n",
      "DLA: 6\n",
      "YCL: 4\n",
      "FPG: 1\n",
      "GGA: 1\n",
      "ENG: 3\n",
      "WLL: 5\n",
      "DEQ: 1\n",
      "HCS: 2\n",
      "LSM: 5\n",
      "LGV: 1\n",
      "SLG: 11\n",
      "YIC: 4\n",
      "FLT: 3\n",
      "MTL: 1\n",
      "AFY: 1\n",
      "NGL: 12\n",
      "ILT: 8\n",
      "ASG: 3\n",
      "CIA: 2\n",
      "KGT: 7\n",
      "MRG: 7\n",
      "FVY: 1\n",
      "FKD: 1\n",
      "YEL: 3\n",
      "SNA: 2\n",
      "RLG: 13\n",
      "VSV: 1\n",
      "LGF: 2\n",
      "HLV: 1\n",
      "QAC: 3\n",
      "FWC: 5\n",
      "SIA: 1\n",
      "QGT: 2\n",
      "HGK: 1\n",
      "HNC: 2\n",
      "AHD: 1\n",
      "IHN: 1\n",
      "VQM: 2\n",
      "MQG: 4\n",
      "RYC: 2\n",
      "NAM: 4\n",
      "ISC: 3\n",
      "QWC: 2\n",
      "LSA: 3\n",
      "AQM: 1\n",
      "FLA: 8\n",
      "AAG: 9\n",
      "WHC: 4\n",
      "HLT: 11\n",
      "MKD: 1\n",
      "WIS: 1\n",
      "HSA: 5\n",
      "HWF: 1\n",
      "GNF: 2\n",
      "KWG: 4\n",
      "PQQ: 1\n",
      "SWC: 2\n",
      "IAT: 3\n",
      "VLY: 1\n",
      "LCY: 2\n",
      "SLC: 6\n",
      "LSG: 8\n",
      "HLC: 4\n",
      "WVG: 14\n",
      "HQL: 1\n",
      "SIC: 1\n",
      "SGV: 5\n",
      "PIQ: 1\n",
      "KKC: 1\n",
      "FCF: 2\n",
      "MVG: 3\n",
      "RGA: 4\n",
      "RVL: 1\n",
      "CGV: 8\n",
      "QRA: 1\n",
      "GCC: 2\n",
      "QVF: 2\n",
      "IMF: 1\n",
      "DWG: 2\n",
      "WGQ: 6\n",
      "WAS: 6\n",
      "VGF: 11\n",
      "HYC: 3\n",
      "YSC: 3\n",
      "EVL: 3\n",
      "IAV: 1\n",
      "TMA: 4\n",
      "HGF: 13\n",
      "IAF: 3\n",
      "QLC: 4\n",
      "QLV: 2\n",
      "WWF: 4\n",
      "ALA: 8\n",
      "RRA: 1\n",
      "NCS: 4\n",
      "ISV: 1\n",
      "AIA: 1\n",
      "MHN: 1\n",
      "FDD: 1\n",
      "MLG: 6\n",
      "EML: 3\n",
      "VCG: 18\n",
      "YIM: 3\n",
      "CGI: 3\n",
      "ICF: 2\n",
      "IPF: 1\n",
      "HSF: 1\n",
      "MSY: 2\n",
      "MAG: 8\n",
      "FTG: 7\n",
      "VTA: 4\n",
      "CIC: 2\n",
      "GTF: 1\n",
      "AMI: 1\n",
      "AAF: 2\n",
      "CMV: 1\n",
      "YDD: 1\n",
      "LLV: 1\n",
      "IKF: 1\n",
      "KCS: 2\n",
      "WIM: 5\n",
      "TSF: 1\n",
      "WGV: 9\n",
      "MVF: 4\n",
      "EEL: 1\n",
      "EDM: 1\n",
      "YCY: 1\n",
      "CKG: 3\n",
      "WRG: 5\n",
      "EGA: 3\n",
      "YGQ: 9\n",
      "IHM: 1\n",
      "LTA: 3\n",
      "DQQ: 1\n",
      "CMA: 9\n",
      "VAV: 1\n",
      "ECL: 2\n",
      "LSL: 3\n",
      "CMG: 3\n",
      "AFM: 1\n",
      "RFA: 6\n",
      "QVC: 3\n",
      "EQG: 3\n",
      "MMG: 9\n",
      "FVL: 2\n",
      "LLF: 3\n",
      "LNM: 4\n",
      "INA: 7\n",
      "MPL: 1\n",
      "WWA: 2\n",
      "WMG: 11\n",
      "WCI: 4\n",
      "KFV: 2\n",
      "WGF: 14\n",
      "LIL: 4\n",
      "ERG: 3\n",
      "TQG: 4\n",
      "TMG: 5\n",
      "NCC: 7\n",
      "IHS: 1\n",
      "TQC: 1\n",
      "VQY: 1\n",
      "VEA: 4\n",
      "IFM: 1\n",
      "AKG: 3\n",
      "GVF: 1\n",
      "MCC: 5\n",
      "FEC: 1\n",
      "CNL: 3\n",
      "NWY: 2\n",
      "RVY: 1\n",
      "AMT: 1\n",
      "CHV: 1\n",
      "ETF: 1\n",
      "VWY: 1\n",
      "MMM: 2\n",
      "MVC: 7\n",
      "ECF: 2\n",
      "QGC: 13\n",
      "VQA: 4\n",
      "MGC: 8\n",
      "AVL: 2\n",
      "MIY: 1\n",
      "MIC: 6\n",
      "YQA: 3\n",
      "HAS: 4\n",
      "KMA: 5\n",
      "TNG: 5\n",
      "VMV: 1\n",
      "LLM: 2\n",
      "KKG: 4\n",
      "FYY: 1\n",
      "FIY: 1\n",
      "HIM: 2\n",
      "LGG: 2\n",
      "QKC: 1\n",
      "LRY: 2\n",
      "HIF: 3\n",
      "FDA: 2\n",
      "WRL: 3\n",
      "PKH: 1\n",
      "HAF: 2\n",
      "AFV: 6\n",
      "YRL: 4\n",
      "HVM: 1\n",
      "MGV: 4\n",
      "VLT: 8\n",
      "NMT: 3\n",
      "ICT: 7\n",
      "VDY: 1\n",
      "IGY: 1\n",
      "HGG: 5\n",
      "FHD: 1\n",
      "IAI: 1\n",
      "ITA: 5\n",
      "NSC: 1\n",
      "IGM: 11\n",
      "TQQ: 1\n",
      "MNM: 4\n",
      "DMT: 1\n",
      "SYC: 2\n",
      "QAF: 2\n",
      "RKG: 1\n",
      "DMI: 1\n",
      "CMF: 2\n",
      "INV: 1\n",
      "VTY: 1\n",
      "FGM: 12\n",
      "AEQ: 1\n",
      "WAL: 10\n",
      "KFA: 6\n",
      "LWY: 2\n",
      "QQL: 2\n",
      "WCM: 8\n",
      "YHL: 3\n",
      "KRA: 1\n",
      "IFG: 24\n",
      "HGC: 9\n",
      "QLL: 1\n",
      "FIC: 4\n",
      "CQM: 2\n",
      "SLA: 9\n",
      "SCA: 10\n",
      "EAM: 2\n",
      "IDM: 2\n",
      "IIM: 2\n",
      "LCG: 18\n",
      "QSL: 2\n",
      "GND: 1\n",
      "FWL: 5\n",
      "NGV: 4\n",
      "VDG: 6\n",
      "RAS: 6\n",
      "VSA: 9\n",
      "IWY: 2\n",
      "VAM: 6\n",
      "YFV: 2\n",
      "FNG: 8\n",
      "VCV: 4\n",
      "YVS: 1\n",
      "MTG: 2\n",
      "AHY: 1\n",
      "VRY: 1\n",
      "PGN: 1\n",
      "NLG: 13\n",
      "YRS: 1\n",
      "KDC: 2\n",
      "EDF: 1\n",
      "YMA: 8\n",
      "YMG: 10\n",
      "MWG: 7\n",
      "TAF: 1\n",
      "LEC: 1\n",
      "ANC: 1\n",
      "VFL: 1\n",
      "HYM: 1\n",
      "FML: 2\n",
      "ILV: 4\n",
      "AIC: 4\n",
      "EQC: 1\n",
      "YWL: 4\n",
      "EKM: 1\n",
      "WGH: 2\n",
      "DFA: 4\n",
      "TRL: 1\n",
      "GMA: 2\n",
      "MNL: 3\n",
      "SFG: 20\n",
      "NAA: 12\n",
      "QCF: 2\n",
      "QYC: 3\n",
      "NYG: 9\n",
      "TFC: 3\n",
      "REC: 1\n",
      "LGA: 4\n",
      "QDY: 1\n",
      "HKM: 1\n",
      "TWL: 1\n",
      "DCV: 1\n",
      "AFF: 1\n",
      "VEL: 1\n",
      "AEK: 1\n",
      "CAF: 3\n",
      "YAV: 3\n",
      "FDC: 2\n",
      "YVC: 5\n",
      "KMS: 1\n",
      "IYL: 1\n",
      "MTM: 1\n",
      "AEF: 2\n",
      "FKL: 3\n",
      "LSF: 3\n",
      "MVA: 5\n",
      "IFP: 1\n",
      "MDL: 4\n",
      "GQH: 1\n",
      "FVM: 5\n",
      "YGV: 11\n",
      "SWG: 5\n",
      "RIA: 1\n",
      "KMT: 3\n",
      "MAS: 3\n",
      "ETC: 1\n",
      "VAF: 2\n",
      "NGM: 12\n",
      "YAG: 11\n",
      "FHF: 2\n",
      "WEA: 1\n",
      "NAS: 5\n",
      "QAM: 2\n",
      "LCA: 13\n",
      "LIS: 2\n",
      "HIG: 6\n",
      "WFC: 9\n",
      "PDK: 1\n",
      "WWM: 6\n",
      "CYF: 2\n",
      "MAF: 3\n",
      "SYG: 18\n",
      "VQL: 1\n",
      "VCS: 6\n",
      "CSF: 3\n",
      "HLA: 9\n",
      "TCG: 10\n",
      "KCA: 9\n",
      "GHG: 1\n",
      "QFG: 15\n",
      "NMG: 9\n",
      "RLV: 3\n",
      "FYF: 1\n",
      "YGW: 6\n",
      "CFA: 10\n",
      "SMG: 9\n",
      "RCI: 3\n",
      "IWV: 2\n",
      "IDY: 1\n",
      "DSA: 3\n",
      "VGG: 6\n",
      "MCL: 4\n",
      "EKC: 3\n",
      "PHN: 1\n",
      "MFF: 1\n",
      "SGY: 1\n",
      "AWC: 2\n",
      "FAI: 1\n",
      "CRA: 4\n",
      "IQA: 5\n",
      "LWM: 3\n",
      "KRF: 1\n",
      "PYQ: 1\n",
      "LCM: 4\n",
      "RCS: 2\n",
      "WYL: 4\n",
      "LEA: 1\n",
      "FWG: 12\n",
      "INL: 3\n",
      "YQM: 2\n",
      "YMM: 2\n",
      "QSG: 4\n",
      "YYC: 5\n",
      "MCS: 3\n",
      "MTF: 2\n",
      "WMM: 2\n",
      "EVV: 1\n",
      "ACI: 1\n",
      "QYF: 1\n",
      "DCM: 2\n",
      "FIA: 4\n",
      "MEA: 2\n",
      "IHG: 9\n",
      "SMC: 2\n",
      "DLC: 2\n",
      "VNG: 7\n",
      "HVY: 1\n",
      "YWG: 6\n",
      "GVY: 1\n",
      "ETA: 1\n",
      "AYK: 1\n",
      "AKF: 2\n",
      "HQD: 3\n",
      "TFG: 14\n",
      "ICA: 15\n",
      "LNC: 7\n",
      "WFF: 1\n",
      "PWK: 1\n",
      "VPF: 2\n",
      "KHD: 1\n",
      "CDG: 2\n",
      "TGL: 3\n",
      "RFP: 1\n",
      "KGS: 6\n",
      "NMS: 3\n",
      "MAC: 8\n",
      "IYS: 1\n",
      "FNS: 1\n",
      "WNA: 2\n",
      "KAM: 2\n",
      "AQG: 2\n",
      "HGV: 12\n",
      "YAC: 4\n",
      "HGS: 9\n",
      "ESY: 1\n",
      "YGM: 11\n",
      "IMC: 8\n",
      "TRC: 2\n",
      "QFL: 1\n",
      "VRL: 3\n",
      "RWG: 6\n",
      "IEC: 2\n",
      "CHL: 3\n",
      "ICI: 2\n",
      "WSW: 1\n",
      "YGT: 6\n",
      "LVY: 2\n",
      "YWA: 4\n",
      "PAH: 1\n",
      "IIY: 1\n",
      "KYC: 2\n",
      "KCI: 2\n",
      "WFA: 8\n",
      "WFL: 4\n",
      "AGF: 7\n",
      "MFL: 4\n",
      "RVG: 7\n",
      "EDL: 3\n",
      "TLT: 7\n",
      "AHF: 1\n",
      "AAT: 1\n",
      "FGW: 4\n",
      "GWF: 1\n",
      "HNL: 2\n",
      "KQC: 2\n",
      "PPD: 1\n",
      "QHC: 3\n",
      "RAA: 13\n",
      "FAG: 11\n",
      "WNG: 6\n",
      "IFV: 7\n",
      "EAA: 6\n",
      "FGQ: 2\n",
      "YND: 1\n",
      "GHD: 1\n",
      "DRA: 1\n",
      "SAM: 3\n",
      "LSC: 4\n",
      "QID: 1\n",
      "VHM: 1\n",
      "QLT: 7\n",
      "SLT: 8\n",
      "NTC: 1\n",
      "HCV: 3\n",
      "WWV: 4\n",
      "NCV: 3\n",
      "CNG: 4\n",
      "AIG: 3\n",
      "SAL: 3\n",
      "EHG: 4\n",
      "QIF: 3\n",
      "TFV: 3\n",
      "VQG: 4\n",
      "IMI: 1\n",
      "WDL: 4\n",
      "ISF: 2\n",
      "DYG: 8\n",
      "MDG: 2\n",
      "LIA: 5\n",
      "GCA: 5\n",
      "WQL: 5\n",
      "QKG: 2\n",
      "DMV: 1\n",
      "YGK: 1\n",
      "LFT: 3\n",
      "IGL: 10\n",
      "VTL: 1\n",
      "CHM: 2\n",
      "HTL: 1\n",
      "WLM: 3\n",
      "AGA: 4\n",
      "WCC: 12\n",
      "ACF: 3\n",
      "VHF: 1\n",
      "ALS: 1\n",
      "MQC: 4\n",
      "DAG: 3\n",
      "MWA: 6\n",
      "MDY: 1\n",
      "RAM: 4\n",
      "WAR: 1\n",
      "VDM: 2\n",
      "CYY: 1\n",
      "WHG: 11\n",
      "LMM: 2\n",
      "AWA: 1\n",
      "ELC: 5\n",
      "FCV: 1\n",
      "WAA: 8\n",
      "ANL: 1\n",
      "MAY: 1\n",
      "DLG: 10\n",
      "AGN: 2\n",
      "ATF: 1\n",
      "RAI: 1\n",
      "AHC: 2\n",
      "PGH: 1\n",
      "KLV: 3\n",
      "WTA: 1\n",
      "AAQ: 1\n",
      "RMM: 1\n",
      "YLL: 2\n",
      "LKN: 1\n",
      "TLA: 3\n",
      "PVK: 1\n",
      "AQK: 1\n",
      "AFG: 18\n",
      "LQY: 1\n",
      "IVM: 2\n",
      "IQD: 1\n",
      "VHY: 1\n",
      "NSA: 6\n",
      "PFQ: 1\n",
      "ACM: 4\n",
      "KNG: 3\n",
      "MCA: 13\n",
      "YAS: 4\n",
      "TAS: 2\n",
      "QSC: 2\n",
      "LVM: 4\n",
      "YIG: 7\n",
      "PKQ: 1\n",
      "IKS: 1\n",
      "RCG: 11\n",
      "CDL: 2\n",
      "VFT: 7\n",
      "IAA: 15\n",
      "EGC: 8\n",
      "LHC: 6\n",
      "FFL: 2\n",
      "NRG: 1\n",
      "AAM: 4\n",
      "EAL: 2\n",
      "AMS: 1\n",
      "LHA: 4\n",
      "RGL: 9\n",
      "WQC: 6\n",
      "RAL: 3\n",
      "IRV: 1\n",
      "DGV: 1\n",
      "YMV: 1\n",
      "WGC: 12\n",
      "IKL: 3\n",
      "HVG: 9\n",
      "MPA: 1\n",
      "YML: 2\n",
      "YAA: 11\n",
      "QVG: 3\n",
      "ILF: 1\n",
      "ADF: 1\n",
      "CAI: 1\n",
      "CMC: 1\n",
      "YHM: 3\n",
      "IGF: 8\n",
      "IQC: 1\n",
      "HGA: 10\n",
      "HWL: 2\n",
      "PEN: 1\n",
      "SSC: 2\n",
      "LLY: 1\n",
      "CSY: 1\n",
      "SMM: 1\n",
      "YFM: 1\n",
      "DLT: 8\n",
      "CQD: 1\n",
      "QND: 2\n",
      "SGT: 7\n",
      "AAS: 1\n",
      "VWG: 12\n",
      "IGI: 2\n",
      "ALF: 1\n",
      "IVG: 9\n",
      "CRF: 4\n",
      "RTG: 2\n",
      "VWC: 5\n",
      "WNR: 1\n",
      "KQG: 2\n",
      "KLT: 8\n",
      "WKL: 6\n",
      "WAG: 14\n",
      "RLT: 10\n",
      "YSM: 2\n",
      "CHC: 2\n",
      "VSM: 1\n",
      "MMF: 1\n",
      "ACY: 1\n",
      "CIY: 1\n",
      "EIA: 2\n",
      "VCI: 2\n",
      "WQG: 1\n",
      "RVC: 2\n",
      "HWY: 1\n",
      "QKF: 1\n",
      "CEF: 2\n",
      "FMI: 1\n",
      "IDC: 2\n",
      "WSL: 5\n",
      "FVG: 9\n",
      "DCA: 10\n",
      "QLF: 1\n",
      "WAY: 1\n",
      "ESG: 5\n",
      "MDM: 1\n",
      "KHF: 1\n",
      "MNN: 1\n",
      "CSM: 1\n",
      "EWC: 4\n",
      "LQL: 2\n",
      "RAF: 1\n",
      "WNF: 2\n",
      "GYG: 3\n",
      "PKK: 1\n",
      "ICV: 4\n",
      "YIL: 3\n",
      "NGS: 7\n",
      "SGW: 1\n",
      "FNC: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMA: 3\n",
      "TIL: 1\n",
      "SKD: 1\n",
      "YGL: 15\n",
      "LPA: 1\n",
      "HAA: 12\n",
      "NGG: 1\n",
      "MAL: 3\n",
      "HKL: 1\n",
      "WPL: 1\n",
      "RAT: 1\n",
      "WSG: 5\n",
      "DAL: 2\n",
      "SMS: 1\n",
      "VTG: 3\n",
      "IGT: 4\n",
      "IHY: 2\n",
      "LDL: 3\n",
      "LRC: 3\n",
      "LRN: 1\n",
      "FHM: 2\n",
      "WGS: 3\n",
      "IMA: 10\n",
      "SAI: 1\n",
      "QWV: 1\n",
      "WIF: 5\n",
      "FHA: 4\n",
      "IHC: 3\n",
      "VGT: 5\n",
      "PYD: 1\n",
      "QCT: 1\n",
      "FEL: 3\n",
      "MHM: 4\n",
      "IAY: 2\n",
      "EFC: 3\n",
      "VTM: 2\n",
      "TGF: 4\n",
      "VWL: 2\n",
      "MWC: 5\n",
      "KTC: 1\n",
      "GQV: 1\n",
      "YVF: 3\n",
      "MYL: 3\n",
      "HMA: 8\n",
      "FRY: 1\n",
      "VGL: 11\n",
      "KGL: 7\n",
      "LYF: 3\n",
      "IWA: 5\n",
      "NAG: 6\n",
      "YWY: 1\n",
      "IYC: 3\n",
      "GEV: 2\n",
      "IMM: 1\n",
      "TRA: 1\n",
      "FAS: 5\n",
      "TCS: 1\n",
      "QEG: 1\n",
      "HCG: 11\n",
      "KCV: 3\n",
      "ASM: 2\n",
      "ARM: 1\n",
      "CWA: 3\n",
      "YRW: 1\n",
      "SRG: 1\n",
      "FGI: 7\n",
      "MIF: 4\n",
      "CVL: 2\n",
      "CNM: 2\n",
      "IKC: 2\n",
      "MGA: 5\n",
      "HHD: 2\n",
      "EAC: 7\n",
      "IIC: 3\n",
      "KLS: 1\n",
      "FFV: 4\n",
      "HQG: 2\n",
      "MVN: 1\n",
      "MWL: 4\n",
      "PLG: 5\n",
      "QFT: 5\n",
      "PFK: 1\n",
      "NGF: 8\n",
      "YRY: 1\n",
      "RCM: 3\n",
      "WLC: 6\n",
      "IGG: 8\n",
      "CSA: 7\n",
      "CWC: 2\n",
      "TCA: 15\n",
      "SWM: 1\n",
      "CGT: 7\n",
      "HYG: 12\n",
      "GCF: 1\n",
      "AEG: 1\n",
      "CLC: 4\n",
      "MGG: 1\n",
      "WHA: 2\n",
      "MVM: 4\n",
      "SCF: 1\n",
      "IRL: 4\n",
      "MSN: 1\n",
      "YAM: 4\n",
      "SAA: 10\n",
      "TLV: 1\n",
      "FCI: 1\n",
      "NFT: 6\n",
      "HAC: 6\n",
      "MYV: 1\n",
      "LWC: 6\n",
      "YLP: 1\n",
      "ICM: 5\n",
      "VLS: 2\n",
      "CGS: 6\n",
      "LIY: 1\n",
      "IMG: 15\n",
      "VNL: 3\n",
      "DGW: 1\n",
      "IDL: 3\n",
      "HHG: 6\n",
      "FFA: 6\n",
      "MIG: 5\n",
      "LYV: 1\n",
      "FLL: 3\n",
      "RNG: 3\n",
      "WVL: 6\n",
      "YFC: 4\n",
      "QQC: 2\n",
      "ILP: 2\n",
      "LAY: 1\n",
      "SHF: 1\n",
      "RYT: 2\n",
      "QHF: 1\n",
      "VNV: 1\n",
      "YEA: 1\n",
      "YQC: 1\n",
      "QSA: 3\n",
      "WYC: 7\n",
      "QWL: 2\n",
      "SGG: 3\n",
      "FMM: 2\n",
      "FHG: 8\n",
      "YHC: 2\n",
      "TGS: 4\n",
      "AYQ: 1\n",
      "IRG: 8\n",
      "CRY: 1\n",
      "WAT: 1\n",
      "VHG: 9\n",
      "WQA: 1\n",
      "QQD: 4\n",
      "SVA: 1\n",
      "SGA: 4\n",
      "YLA: 5\n",
      "VFA: 10\n",
      "FYM: 1\n",
      "PGK: 1\n",
      "MSF: 5\n",
      "WFM: 5\n",
      "YYM: 3\n",
      "QVM: 2\n",
      "YRF: 3\n",
      "YMI: 1\n",
      "YDM: 2\n",
      "QCS: 2\n",
      "SLV: 1\n",
      "IKA: 6\n",
      "KCT: 2\n",
      "ILL: 3\n",
      "YIA: 5\n",
      "TQA: 1\n",
      "TIF: 1\n",
      "LDM: 3\n",
      "EHC: 2\n",
      "QLA: 4\n",
      "VIF: 2\n",
      "LGT: 1\n",
      "YNM: 3\n",
      "LFC: 7\n",
      "LVG: 6\n",
      "FYC: 5\n",
      "ITS: 1\n",
      "ERF: 2\n",
      "PIK: 1\n",
      "KTG: 1\n",
      "AHQ: 1\n",
      "VFF: 1\n",
      "AWF: 2\n",
      "AWL: 2\n",
      "TKL: 1\n",
      "WSR: 1\n",
      "MIA: 5\n",
      "QTY: 1\n",
      "TFT: 5\n",
      "VNY: 1\n",
      "YQL: 4\n",
      "YCT: 3\n",
      "PRK: 1\n",
      "VVL: 2\n",
      "SNC: 1\n",
      "YGG: 3\n",
      "PMK: 1\n",
      "KGC: 10\n",
      "EYC: 4\n",
      "ARL: 3\n",
      "AYG: 15\n",
      "AWV: 1\n",
      "HCM: 2\n",
      "QFA: 4\n",
      "SMA: 9\n",
      "IES: 1\n",
      "SCG: 14\n",
      "YAF: 4\n",
      "QTF: 1\n",
      "HSC: 2\n",
      "YQG: 4\n",
      "VAS: 5\n",
      "QAG: 7\n",
      "NWG: 3\n",
      "WVF: 4\n",
      "PCQ: 1\n",
      "AQD: 1\n",
      "MSC: 4\n",
      "QCL: 3\n",
      "LLC: 7\n",
      "LYG: 10\n",
      "HMT: 3\n",
      "NQD: 1\n",
      "TNC: 3\n",
      "AAY: 1\n",
      "MQL: 4\n",
      "CQL: 1\n",
      "GLA: 2\n",
      "MKY: 1\n",
      "TQF: 1\n",
      "AYM: 1\n",
      "MRY: 1\n",
      "ITL: 2\n",
      "EIC: 3\n",
      "MKA: 1\n",
      "PSK: 1\n",
      "CAA: 14\n",
      "MHA: 4\n",
      "CKS: 1\n",
      "IHF: 3\n",
      "EIG: 3\n",
      "YDF: 3\n",
      "QRC: 3\n",
      "PHK: 1\n",
      "WHF: 4\n",
      "KDL: 1\n",
      "LIG: 6\n",
      "SIF: 1\n",
      "KWC: 2\n",
      "CDY: 1\n",
      "LRG: 7\n",
      "WRC: 6\n",
      "HKD: 2\n",
      "FAC: 6\n",
      "TDA: 1\n",
      "KRC: 1\n",
      "GGF: 2\n",
      "PQD: 1\n",
      "ING: 8\n",
      "MTA: 2\n",
      "WYM: 5\n",
      "EIV: 1\n",
      "ECA: 12\n",
      "NFV: 2\n",
      "QFC: 3\n",
      "IIG: 6\n",
      "TAM: 1\n",
      "CFT: 8\n",
      "LYL: 3\n",
      "YKC: 2\n",
      "FQL: 1\n",
      "YGA: 6\n",
      "FTM: 1\n",
      "LMT: 1\n",
      "SAS: 2\n",
      "EWL: 2\n",
      "WWI: 1\n",
      "LKD: 1\n",
      "ICY: 2\n",
      "FGN: 9\n",
      "PFH: 1\n",
      "WCT: 2\n",
      "YKM: 3\n",
      "GHF: 1\n",
      "RGS: 7\n",
      "IFL: 1\n",
      "CTG: 2\n",
      "VTF: 1\n",
      "IVA: 8\n",
      "LEG: 3\n",
      "FRM: 3\n",
      "FRC: 1\n",
      "VCY: 2\n",
      "AFT: 9\n",
      "ACG: 13\n",
      "MWV: 1\n",
      "WVM: 6\n",
      "HAM: 4\n",
      "VCF: 3\n",
      "WDF: 5\n",
      "KRL: 1\n",
      "WCR: 1\n",
      "CQA: 1\n",
      "LRF: 4\n",
      "IEF: 1\n",
      "EFT: 3\n",
      "VQF: 2\n",
      "PGC: 2\n",
      "YRA: 5\n",
      "WNC: 3\n",
      "VRA: 7\n",
      "EAG: 5\n",
      "LNS: 1\n",
      "HIC: 2\n",
      "WTC: 3\n",
      "SVF: 1\n",
      "TNF: 1\n",
      "KLL: 1\n",
      "RLH: 1\n",
      "ISM: 2\n",
      "KCC: 8\n",
      "EGS: 1\n",
      "KSL: 1\n",
      "MAA: 8\n",
      "WRY: 2\n",
      "GGV: 2\n",
      "ETL: 1\n",
      "YSA: 3\n",
      "EYG: 6\n",
      "MVY: 3\n",
      "AKL: 3\n",
      "IRA: 8\n",
      "VYF: 1\n",
      "WGM: 15\n",
      "HHM: 1\n",
      "VSF: 3\n",
      "LVA: 3\n",
      "MSL: 4\n",
      "VLG: 11\n",
      "DQH: 1\n",
      "SVG: 5\n",
      "KCY: 1\n",
      "AML: 1\n",
      "FGH: 3\n",
      "WAF: 4\n",
      "AVG: 6\n",
      "RIF: 1\n",
      "MEC: 3\n",
      "FDM: 1\n",
      "TLG: 6\n",
      "WSM: 4\n",
      "YSY: 1\n",
      "QEL: 1\n",
      "MDA: 3\n",
      "LLG: 14\n",
      "CMT: 2\n",
      "CNF: 1\n",
      "CCC: 7\n",
      "WMS: 2\n",
      "VAG: 13\n",
      "SCS: 2\n",
      "LWF: 3\n",
      "VKM: 2\n",
      "QMI: 1\n",
      "LNG: 4\n",
      "LFV: 2\n",
      "QHG: 6\n",
      "QDL: 1\n",
      "AYA: 4\n",
      "VVA: 5\n",
      "GIF: 3\n",
      "DAM: 3\n",
      "MNC: 7\n",
      "IEG: 4\n",
      "YKS: 1\n",
      "VRS: 1\n",
      "LDA: 2\n",
      "MQY: 1\n",
      "YED: 1\n",
      "PQE: 1\n",
      "YHF: 5\n",
      "MQF: 3\n",
      "LNA: 4\n",
      "QDA: 1\n",
      "DGM: 4\n",
      "IFF: 1\n",
      "ESM: 2\n",
      "AYC: 2\n",
      "RGV: 7\n",
      "VPL: 1\n",
      "ENL: 2\n",
      "IEA: 2\n",
      "YFL: 2\n",
      "SGF: 10\n",
      "ALV: 1\n",
      "DKD: 1\n",
      "QHV: 1\n",
      "LNL: 4\n",
      "SPC: 1\n",
      "FIM: 3\n",
      "FIF: 4\n",
      "FLG: 11\n",
      "CIS: 1\n",
      "QHA: 1\n",
      "VMC: 6\n",
      "HML: 1\n",
      "ARY: 1\n",
      "WKC: 7\n",
      "IWS: 1\n",
      "SYA: 2\n",
      "YNS: 1\n",
      "KGG: 2\n",
      "WHL: 6\n",
      "FKG: 4\n",
      "TGA: 4\n",
      "IGA: 7\n",
      "QKD: 2\n",
      "HEC: 1\n",
      "FDG: 3\n",
      "TSG: 3\n",
      "QYG: 13\n",
      "NRA: 1\n",
      "TFA: 5\n",
      "SNG: 1\n",
      "IDS: 1\n",
      "HVF: 1\n",
      "APQ: 1\n",
      "VFG: 21\n",
      "YDC: 2\n",
      "MKN: 2\n",
      "IAG: 13\n",
      "LDC: 4\n",
      "AHM: 1\n",
      "WPC: 1\n",
      "LCC: 8\n",
      "DCC: 5\n",
      "KGF: 3\n",
      "WRS: 1\n",
      "WKM: 6\n",
      "EGF: 1\n",
      "SIG: 2\n",
      "PLK: 1\n",
      "QCC: 4\n",
      "MLC: 6\n",
      "HGN: 4\n",
      "ECM: 1\n",
      "VLA: 11\n",
      "DCG: 13\n",
      "WKR: 1\n",
      "CLL: 1\n",
      "HKG: 1\n",
      "GGC: 2\n",
      "DGI: 1\n",
      "WYV: 1\n",
      "VKG: 7\n",
      "QHM: 2\n",
      "IFA: 8\n",
      "TYG: 9\n",
      "TWG: 8\n",
      "NVG: 3\n",
      "VAY: 1\n",
      "VHV: 1\n",
      "KLA: 7\n",
      "LHG: 9\n",
      "IDG: 4\n",
      "WGW: 5\n",
      "VFM: 1\n",
      "PMQ: 1\n",
      "WMV: 1\n",
      "EFA: 4\n",
      "MMA: 7\n",
      "YFG: 15\n",
      "RCA: 13\n",
      "IVC: 2\n",
      "EHD: 1\n",
      "YAL: 5\n",
      "MRC: 7\n",
      "QCV: 1\n",
      "CEL: 1\n",
      "LRA: 4\n",
      "WRF: 4\n",
      "PHH: 1\n",
      "IQL: 1\n",
      "WIG: 6\n",
      "KSA: 7\n",
      "ETG: 3\n",
      "RYG: 17\n",
      "LML: 2\n",
      "VSG: 8\n",
      "RCC: 11\n",
      "YTA: 2\n",
      "RVA: 1\n",
      "MGM: 10\n",
      "DQG: 1\n",
      "VSL: 3\n",
      "TAC: 4\n",
      "FKA: 1\n",
      "QDF: 1\n",
      "IFC: 6\n",
      "YFT: 2\n",
      "DFT: 3\n",
      "QLG: 9\n",
      "TKG: 2\n",
      "NFA: 6\n",
      "ATA: 1\n",
      "SHL: 1\n",
      "MFM: 1\n",
      "GLG: 9\n",
      "EKF: 2\n",
      "FVA: 2\n",
      "GFG: 4\n",
      "SWF: 1\n",
      "VKF: 2\n",
      "FFM: 2\n",
      "MIS: 1\n",
      "ESA: 1\n",
      "VEF: 1\n",
      "SAT: 1\n",
      "VGQ: 1\n",
      "VKY: 1\n",
      "YCF: 5\n",
      "CAG: 7\n",
      "QKY: 1\n",
      "AGS: 5\n",
      "GHH: 1\n",
      "KNC: 1\n",
      "SFA: 8\n",
      "IYF: 1\n",
      "CKF: 2\n",
      "MSG: 6\n",
      "EHM: 2\n",
      "YLF: 3\n",
      "YHY: 1\n",
      "FGT: 6\n",
      "QIM: 1\n",
      "QSY: 1\n",
      "DGA: 5\n",
      "YEF: 3\n",
      "QRG: 3\n",
      "EFL: 1\n",
      "FIS: 1\n",
      "AEC: 1\n",
      "MHC: 4\n",
      "SKG: 1\n",
      "HCT: 1\n",
      "PDD: 1\n",
      "FRG: 6\n",
      "IWC: 1\n",
      "DAC: 3\n",
      "MWM: 1\n",
      "VIG: 6\n",
      "SGM: 12\n",
      "EFG: 14\n",
      "TGV: 3\n",
      "YKG: 5\n",
      "QKL: 1\n",
      "AHL: 3\n",
      "WRM: 7\n",
      "TYC: 2\n",
      "CRG: 4\n",
      "AKA: 1\n",
      "TMC: 1\n",
      "WQM: 4\n",
      "GIY: 1\n",
      "GGM: 1\n",
      "YCA: 15\n",
      "KGV: 7\n",
      "CQF: 2\n",
      "RRG: 5\n",
      "AAA: 8\n",
      "HFT: 7\n",
      "QAL: 3\n",
      "MCM: 1\n",
      "ATL: 1\n",
      "YRC: 5\n",
      "WAC: 11\n",
      "INM: 2\n",
      "VHL: 2\n",
      "IFT: 9\n",
      "LTY: 1\n",
      "SWV: 1\n",
      "NSG: 1\n",
      "HIA: 1\n",
      "CGF: 9\n",
      "LGL: 3\n",
      "YGY: 2\n",
      "MRS: 1\n",
      "AGI: 2\n",
      "WGL: 16\n",
      "LIM: 3\n",
      "YLG: 15\n",
      "WIW: 2\n",
      "WFT: 5\n",
      "RIG: 4\n",
      "HGH: 2\n",
      "YGS: 7\n",
      "IYG: 21\n",
      "TNL: 1\n",
      "YGC: 11\n",
      "WHD: 1\n",
      "CWF: 4\n",
      "FGL: 17\n",
      "KEC: 1\n",
      "MLT: 4\n",
      "VNC: 2\n",
      "NWC: 1\n",
      "QHD: 2\n",
      "RFC: 1\n",
      "KGM: 10\n",
      "QGS: 3\n",
      "KWY: 1\n",
      "MTC: 4\n",
      "RRF: 1\n",
      "FEA: 2\n",
      "NCG: 13\n",
      "LEM: 1\n",
      "ACA: 11\n",
      "WTM: 1\n",
      "FWV: 1\n",
      "ENF: 1\n",
      "VPC: 2\n",
      "LVL: 6\n",
      "PTK: 1\n",
      "GWG: 1\n",
      "NMC: 2\n",
      "NFC: 1\n",
      "YHG: 7\n",
      "RWC: 3\n",
      "AVY: 1\n",
      "IPC: 1\n",
      "CVY: 1\n",
      "VMT: 5\n",
      "VLL: 2\n",
      "GYK: 1\n",
      "SCV: 1\n",
      "FGF: 12\n",
      "NCT: 1\n",
      "AIF: 2\n",
      "HAL: 4\n",
      "CCG: 10\n",
      "QAT: 1\n",
      "WYY: 2\n",
      "VVF: 1\n",
      "LAA: 10\n",
      "MSM: 2\n",
      "YEC: 2\n",
      "RMT: 5\n",
      "MLA: 6\n",
      "CVG: 8\n",
      "FKF: 3\n",
      "TSA: 3\n",
      "SRA: 2\n",
      "SHG: 8\n",
      "SEC: 1\n",
      "LVC: 5\n",
      "FYL: 3\n",
      "MNG: 6\n",
      "HFC: 4\n",
      "IGV: 8\n",
      "VLF: 1\n",
      "CCF: 2\n",
      "YIS: 1\n",
      "NFG: 13\n",
      "SCL: 1\n",
      "NAI: 1\n",
      "RGI: 3\n",
      "AGV: 9\n",
      "SFT: 8\n",
      "NGN: 2\n",
      "YTM: 1\n",
      "RLS: 1\n",
      "KVA: 1\n",
      "EMC: 1\n",
      "FGY: 1\n",
      "YCS: 4\n",
      "EHL: 3\n",
      "LFM: 2\n",
      "ICG: 19\n",
      "CYG: 20\n",
      "YHA: 3\n",
      "FNF: 3\n",
      "YVM: 5\n",
      "KSF: 1\n",
      "AAL: 4\n",
      "WKF: 2\n",
      "VNM: 2\n",
      "IPA: 1\n",
      "VMS: 4\n",
      "YMF: 3\n",
      "VKS: 1\n",
      "HGW: 12\n",
      "YPA: 1\n",
      "FVS: 1\n",
      "LCS: 1\n",
      "VNF: 3\n",
      "SSA: 3\n",
      "QMG: 10\n",
      "LAM: 7\n",
      "WML: 4\n",
      "FSA: 1\n",
      "CDF: 2\n",
      "FAM: 4\n",
      "FIL: 3\n",
      "NCI: 2\n",
      "KRG: 3\n",
      "TWC: 3\n",
      "CVA: 4\n",
      "DCS: 2\n",
      "SVC: 1\n",
      "QED: 1\n",
      "WQY: 1\n",
      "HRG: 2\n",
      "TSC: 3\n",
      "QQF: 2\n",
      "YYA: 5\n",
      "ASF: 3\n",
      "RMS: 2\n",
      "NWL: 1\n",
      "CLG: 10\n",
      "CIF: 3\n",
      "LMF: 2\n",
      "KEG: 1\n",
      "KYG: 9\n",
      "CHF: 4\n",
      "NLP: 2\n",
      "PGV: 1\n",
      "IVL: 3\n",
      "HRF: 1\n",
      "WLP: 2\n",
      "RKL: 1\n",
      "VYM: 1\n",
      "IML: 1\n",
      "YFF: 2\n",
      "PCA: 8\n",
      "FLV: 1\n",
      "AMA: 7\n",
      "FQA: 2\n",
      "PFA: 1\n",
      "TIC: 2\n",
      "FEM: 1\n",
      "CAC: 4\n",
      "MQA: 2\n",
      "WIY: 2\n",
      "WAI: 2\n",
      "PNK: 1\n",
      "NGW: 1\n",
      "FKS: 1\n",
      "WDM: 5\n",
      "RGT: 6\n",
      "WKA: 2\n",
      "QNG: 2\n",
      "NIC: 2\n",
      "KCL: 1\n",
      "EAF: 1\n",
      "TGM: 8\n",
      "EVC: 4\n",
      "YVL: 2\n",
      "HTG: 1\n",
      "KIC: 3\n",
      "KAL: 2\n",
      "YYG: 14\n",
      "LSS: 1\n",
      "DYQ: 1\n",
      "MFG: 15\n",
      "QAA: 12\n",
      "TLC: 2\n",
      "YGP: 1\n",
      "HGI: 6\n",
      "CGA: 5\n",
      "WGG: 2\n",
      "DFV: 1\n",
      "ERL: 1\n",
      "PCK: 1\n",
      "RIC: 2\n",
      "MGL: 6\n",
      "IFS: 1\n",
      "TTC: 2\n",
      "WVA: 3\n",
      "YNL: 4\n",
      "YHS: 1\n",
      "AWM: 1\n",
      "VCT: 4\n",
      "QNC: 2\n",
      "FHC: 4\n",
      "KLC: 5\n",
      "KSG: 3\n",
      "VRG: 5\n",
      "ITG: 5\n",
      "HWA: 2\n",
      "NLT: 7\n",
      "SLS: 1\n",
      "IGP: 1\n",
      "QNA: 2\n",
      "FTA: 1\n",
      "EHA: 1\n",
      "QRY: 1\n",
      "FWY: 1\n",
      "SHC: 1\n",
      "LPG: 1\n",
      "WLV: 4\n",
      "GLT: 1\n",
      "HMC: 7\n",
      "KVG: 4\n",
      "RQG: 2\n",
      "FCM: 6\n",
      "ARA: 2\n",
      "RLC: 3\n",
      "FSF: 4\n",
      "WGI: 8\n",
      "DEH: 1\n",
      "QMV: 1\n",
      "AVF: 2\n",
      "KWF: 1\n",
      "SKC: 1\n",
      "FYA: 4\n",
      "VIM: 2\n",
      "VEY: 1\n",
      "HAT: 3\n",
      "SMT: 2\n",
      "ICC: 14\n",
      "DGF: 2\n",
      "MDC: 4\n",
      "SSL: 1\n",
      "ALL: 1\n",
      "WAM: 10\n",
      "LEY: 1\n",
      "THF: 1\n",
      "ANM: 2\n",
      "ILG: 18\n",
      "PQN: 1\n",
      "AMC: 4\n",
      "INC: 3\n",
      "CNC: 1\n",
      "LQF: 1\n",
      "TCC: 4\n",
      "MCG: 14\n",
      "VML: 1\n",
      "LHN: 1\n",
      "FAY: 1\n",
      "SCM: 2\n",
      "PWH: 1\n",
      "RFG: 19\n",
      "TAG: 6\n",
      "WLG: 13\n",
      "PCG: 3\n",
      "CVM: 2\n",
      "RLA: 8\n",
      "LYC: 4\n",
      "FNA: 4\n",
      "HKC: 2\n",
      "FIG: 7\n",
      "LKS: 1\n",
      "CYM: 2\n",
      "NLS: 1\n",
      "GSF: 2\n",
      "HRC: 3\n",
      "YCV: 4\n",
      "IGE: 1\n",
      "EGL: 1\n",
      "CRS: 1\n",
      "QDC: 1\n",
      "QVL: 2\n",
      "CKM: 2\n",
      "HED: 1\n",
      "VDC: 2\n",
      "NYH: 1\n",
      "NVC: 2\n",
      "IHL: 3\n",
      "ALT: 9\n",
      "LYM: 2\n",
      "FWM: 2\n",
      "YDG: 1\n",
      "LNW: 1\n",
      "IIA: 7\n",
      "TGT: 4\n",
      "YWF: 3\n",
      "EKG: 2\n",
      "RHL: 1\n",
      "EGM: 9\n",
      "LMS: 1\n",
      "EWM: 2\n",
      "FGV: 11\n",
      "ILC: 3\n",
      "MYG: 8\n",
      "ILS: 3\n",
      "WLA: 12\n",
      "VDS: 1\n",
      "CYC: 2\n",
      "IDA: 5\n",
      "HFG: 17\n",
      "LMA: 6\n",
      "DMS: 1\n",
      "MQN: 1\n",
      "FRS: 1\n",
      "WMA: 4\n",
      "FQG: 3\n",
      "IAS: 4\n",
      "YGH: 9\n",
      "CMS: 1\n",
      "VYV: 2\n",
      "RAG: 9\n",
      "VVG: 11\n",
      "DHG: 1\n",
      "HWG: 6\n",
      "RRC: 3\n",
      "HLS: 1\n",
      "RMA: 5\n",
      "IRF: 2\n",
      "WLF: 5\n",
      "MKC: 3\n",
      "IYT: 1\n",
      "WEF: 4\n",
      "KIG: 3\n",
      "KQD: 1\n",
      "HCC: 12\n",
      "YNF: 2\n",
      "MFC: 5\n",
      "VCA: 16\n",
      "CKA: 2\n",
      "AYF: 1\n",
      "YIF: 2\n",
      "CWM: 1\n",
      "FHL: 3\n",
      "KLG: 12\n",
      "KLP: 2\n",
      "TDC: 1\n",
      "IHA: 4\n",
      "WVR: 1\n",
      "AKM: 1\n",
      "ENM: 1\n",
      "VHC: 1\n",
      "IPG: 1\n",
      "LNF: 3\n",
      "FFG: 13\n",
      "LQM: 3\n",
      "DRG: 1\n",
      "PHE: 1\n",
      "FSY: 1\n",
      "AQC: 2\n",
      "PYH: 1\n",
      "FGD: 1\n",
      "WHR: 1\n",
      "RGC: 8\n",
      "MLL: 4\n",
      "CEA: 1\n",
      "RFV: 4\n",
      "VSS: 1\n",
      "LHM: 3\n",
      "THM: 1\n",
      "YRG: 4\n",
      "LGM: 9\n",
      "MIM: 5\n",
      "IWG: 13\n",
      "HMG: 10\n",
      "MVS: 1\n",
      "NRC: 2\n"
     ]
    }
   ],
   "source": [
    "feats_dict = gen_feats_dict(df_train)\n",
    "occ1 = gen_occ(df_train[df_train['Active']==1],feats_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 8718)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "(48000, 8718)\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n"
     ]
    }
   ],
   "source": [
    "X_train_raw = gen_X(df_train,feats_dict)\n",
    "X_test_raw = gen_X(df_test,feats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 8718)\n",
      "(112000,)\n",
      "(48000, 8718)\n",
      "(8718,)\n",
      "(8718,)\n",
      "(112000, 1527)\n",
      "(112000,)\n",
      "(48000, 1527)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "holdout=False\n",
    "feat_sel1=False\n",
    "feat_sel2=True\n",
    "\n",
    "if holdout:\n",
    "    #make hold out\n",
    "    X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "        X_train_raw,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "    print(np.shape(X_train))\n",
    "    print(np.shape(X_hold))\n",
    "    print(np.sum(y_train))\n",
    "    print(np.sum(y_hold))\n",
    "    print(\"\\n\")\n",
    "else:\n",
    "    X_train = X_train_raw.copy()\n",
    "    \n",
    "X_test = X_test_raw.copy()\n",
    "    \n",
    "y_train = df_train['Active'].values\n",
    "n = float(np.shape(y_train)[0])    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "if feat_sel1:\n",
    "    lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X_train, y_train)\n",
    "    model = SelectFromModel(lsvc, prefit=True)\n",
    "    X_train = model.transform(X_train)\n",
    "    X_test = model.transform(X_test)\n",
    "    \n",
    "    \n",
    "if feat_sel2:\n",
    "    #feature selection by conditional probability threshold\n",
    "    a = np.sum(X_train,axis=0)\n",
    "    b = np.sum(np.transpose(X_train)*y_train,axis=1)\n",
    "    print(np.shape(a))\n",
    "    print(np.shape(b))\n",
    "    c = b/a\n",
    "    d = np.argwhere(c>0.2).flatten()\n",
    "    \n",
    "    X_train = X_train[:,d]\n",
    "    X_test = X_test[:,d]\n",
    "    \n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   36,   39, ..., 8707, 8712, 8715])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = X_train[:,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112000, 2823)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1plex',\n",
       " '2plex',\n",
       " '3plex',\n",
       " '1plex_pos0',\n",
       " '1plex_pos1',\n",
       " '1plex_pos2',\n",
       " '1plex_pos3',\n",
       " '2plex_pos0',\n",
       " '2plex_pos1',\n",
       " '2plex_pos2',\n",
       " '3plex_pos0',\n",
       " '3plex_pos1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score= 0.982634\n",
      "cv roc auc= 0.967249\n",
      "cv acc= 0.976732\n",
      "cv rec= 0.570136\n",
      "cv prec= 0.751200\n",
      "y train:\n",
      "n pos 4213.000000\n",
      "frac pos 0.037616\n",
      "y train pred:\n",
      "n pos 3364.000000\n",
      "frac pos 0.030036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hp_x = np.array([0.56])\n",
    "hp_metrics = [\n",
    "           'test_accuracy',\n",
    "           'test_recall',\n",
    "           'test_precision'\n",
    "          ]\n",
    "hp_y = np.zeros((hp_x.shape[0],len(hp_metrics)))\n",
    "\n",
    "for j in range(0,hp_x.shape[0]):\n",
    "\n",
    "    \"\"\"\n",
    "    clf_init = GaussianNB()\n",
    "    \n",
    "    clf_init = LinearSVC(\n",
    "        penalty='l1',\n",
    "        C=hp_x[j],\n",
    "        dual=False,\n",
    "        random_state=42,tol=1e-5)\n",
    "        \n",
    "    clf_init = LinearSVC(\n",
    "        C=hp_x[j],\n",
    "        class_weight='balanced',\n",
    "        random_state=42,tol=1e-5)\n",
    "        \n",
    "    clf_init = LinearSVC(\n",
    "        C=0.56,\n",
    "        class_weight={0:0.52,1:13.3*hp_x[j]},\n",
    "        random_state=42,tol=1e-5)\n",
    "    #tuning class weights didn't do too much\n",
    "        \n",
    "    HistGradientBoostingClassifier(random_state=42)\n",
    "    clf_init = HistGradientBoostingClassifier(verbose=10,random_state=42)\n",
    "    #too slow\n",
    "    \n",
    "    clf_init = BernoulliNB(class_prior=[1-hp_x[j],hp_x[j]])\n",
    "    #performance not as good\n",
    "    \"\"\"\n",
    "    clf_init = LinearSVC(\n",
    "        C=hp_x[j],\n",
    "        random_state=42,tol=1e-5)\n",
    "    \n",
    "    clf = clf_init.fit(X_train,y_train)\n",
    "    score = clf.score(X_train,y_train)\n",
    "\n",
    "    cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "            scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "    print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "    hp_y[j][0] = np.mean(cv_results['test_accuracy'])\n",
    "    \n",
    "    print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "    hp_y[j][1] = np.mean(cv_results['test_recall'])\n",
    "    \n",
    "    print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "    hp_y[j][2] = np.mean(cv_results['test_precision'])\n",
    "\n",
    "    #print(sigmoid(clf.decision_function(X_train)))\n",
    "    #p_train=clf.predict(X_train)\n",
    "\n",
    "    print(\"y train:\")\n",
    "    print(\"n pos %f\"%np.sum(y_train))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "    print(\"y train pred:\")\n",
    "    y_train_pred=clf.predict(X_train)\n",
    "    print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "    #p_train=clf.predict_proba(X_train)\n",
    "    #print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "    #print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "    #print(p_train)\n",
    "\n",
    "    #print(\"y test:\")\n",
    "    #p_test=clf.predict_proba(X_test)\n",
    "    #print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "    #print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "    if holdout:\n",
    "        #print(\"holdout metrics:\")\n",
    "        #holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "        #print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "        #holdout_aucs[i] = holdout_auc\n",
    "\n",
    "        y_hold_pred = clf.predict(X_hold)\n",
    "        holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout acc= %f\"%holdout_acc)\n",
    "        holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout rec= %f\"%holdout_rec)\n",
    "        holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout prec= %f\"%holdout_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000, 1527)\n",
      "(112000,)\n",
      "(48000, 1527)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3786ebbd5ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prob sum 0 %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prob sum 1 %f\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "p_train=clf.predict_proba(X_train)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n/(2*np.bincount(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y test pred:\n",
      "n pos 1660.000000\n",
      "frac pos 0.014821\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"y test pred:\")\n",
    "y_test_pred=clf.predict(X_test)\n",
    "print(\"n pos %f\"%np.sum(y_test_pred))\n",
    "print(\"frac pos %f\"%(np.sum(y_test_pred)/n) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_str = \"\"\n",
    "for i in range(len(y_test_pred)):\n",
    "    result_str+=str(y_test_pred[i])\n",
    "    result_str+=\"\\n\"\n",
    "\n",
    "submission = open(\"sub.csv\",\"w\")\n",
    "submission.write(result_str)\n",
    "submission.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56]\n",
      "[[0.98302679 0.72893044 0.80215195]]\n"
     ]
    }
   ],
   "source": [
    "#L2 experiment result, with 8718 feats\n",
    "\n",
    "print(hp_x)\n",
    "print(hp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "for k in range(0,len(hp_metrics)):\n",
    "    ax1.plot(np.log10(hp_x),hp_y[:,k],label=hp_metrics[k])\n",
    "    \n",
    "f1 = 2*hp_y[:,1]*hp_y[:,2]/(hp_y[:,1]+hp_y[:,2])\n",
    "ax1.plot(np.log10(hp_x),f1,label=\"f1\")\n",
    "    \n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76379035])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf_init = HistGradientBoostingClassifier(random_state=42)\n",
    "clf = fit_model1(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "score = clf.score(X_train,y_train)\n",
    "\n",
    "cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "        scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "print(\"train score= %f\"%score)\n",
    "print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "\n",
    "#print(sigmoid(clf.decision_function(X_train)))\n",
    "#p_train=clf.predict(X_train)\n",
    "\n",
    "print(\"y train:\")\n",
    "print(\"n pos %f\"%np.sum(y_train))\n",
    "print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "print(\"y train pred:\")\n",
    "y_train_pred=clf.predict(X_train)\n",
    "print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "p_train=clf.predict_proba(X_train)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "#print(p_train)\n",
    "\n",
    "print(\"y test:\")\n",
    "p_test=clf.predict_proba(X_test)\n",
    "print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "if holdout:\n",
    "    print(\"holdout metrics:\")\n",
    "    holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "    print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "    holdout_aucs[i] = holdout_auc\n",
    "\n",
    "    y_hold_pred = clf.predict(X_hold)\n",
    "    holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout acc= %f\"%holdout_acc)\n",
    "    holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout rec= %f\"%holdout_rec)\n",
    "    holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "    print(\"holdout prec= %f\"%holdout_prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = df_train[df_train['Active']==1]\n",
    "asv = active['Sequence'].values\n",
    "asv_str = ''.join(list(asv))\n",
    "asv_1plex = asv_str\n",
    "\n",
    "chars = ''.join(set(asv_str))\n",
    "feats1 = chars\n",
    "\n",
    "occ = {}\n",
    "\n",
    "#1-plex\n",
    "for i in range(len(chars)):\n",
    "    count = asv_str.count(chars[i])\n",
    "    occ[chars[i]] = count\n",
    "    print(\"%s: %d\"%(chars[i],count))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_2plex_list = []\n",
    "for i in range(len(asv)):\n",
    "    for j in range(0,3):\n",
    "        asv_2plex_list.append(asv[i][j:j+2])\n",
    "\n",
    "feats2 = list(set(asv_2plex_list))\n",
    "print(len(feats2))\n",
    "\n",
    "occ = {}\n",
    "#2-plex\n",
    "for i in range(len(feats2)):\n",
    "    count = asv_2plex_list.count(feats2[i])\n",
    "    occ[feats2[i]] = count\n",
    "    print(\"%s: %d\"%(feats2[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_3plex_list = []\n",
    "for i in range(len(asv)):\n",
    "    for j in range(0,2):\n",
    "        asv_3plex_list.append(asv[i][j:j+3])\n",
    "\n",
    "feats3 = list(set(asv_3plex_list))\n",
    "print(len(feats3))\n",
    "\n",
    "occ = {}\n",
    "#3-plex\n",
    "for i in range(len(feats3)):\n",
    "    count = asv_3plex_list.count(feats3[i])\n",
    "    occ[feats3[i]] = count\n",
    "    print(\"%s: %d\"%(feats3[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(asv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asv_2plex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2 = list(set(asv_2plex_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = df_train[df_train['Active']!=2]\n",
    "asv = active['Sequence'].values\n",
    "asv_str = ''.join(list(asv))\n",
    "chars = ''.join(set(asv_str))\n",
    "occ = {}\n",
    "for i in range(len(chars)):\n",
    "    count = asv_str.count(chars[i])\n",
    "    occ[chars[i]] = count\n",
    "    print(\"%s: %d\"%(chars[i],count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train,X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return(X_train,X_test)\n",
    "    \n",
    "\n",
    "def impute(X_train,X_test):\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imp_mean.fit(X_train)\n",
    "    \n",
    "    X_train = imp_mean.transform(X_train)\n",
    "    X_test = imp_mean.transform(X_test)\n",
    "\n",
    "    #print(X_train_imp)\n",
    "    return(X_train,X_test)\n",
    "\n",
    "def forest_fi(X_train,y_train,X_test):\n",
    "\n",
    "    forest = ExtraTreesClassifier(n_estimators=20,\n",
    "                                  random_state=0)\n",
    "\n",
    "    forest.fit(X_train,y_train)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    X_train = X_train[:,indices[:50]]\n",
    "    X_test = X_test[:,indices[:50]]\n",
    "    return(X_train,X_test)\n",
    "\n",
    "\n",
    "def nystroem(X_train,X_test):\n",
    "    gamma=1.0\n",
    "    n_components=100\n",
    "    print(\"nystroem gamma=%f\"%(gamma))\n",
    "    print(\"nystroem q=%d\"%(n_components))\n",
    "    feature_map_nystroem = Nystroem(gamma=gamma,\n",
    "                                    random_state=42,\n",
    "                                    n_components=n_components)\n",
    "    feature_map_nystroem.fit(X_train)\n",
    "    Q_train = feature_map_nystroem.transform(X_train)\n",
    "    sqrt_k_inv_train = np.linalg.inv(feature_map_nystroem.normalization_)\n",
    "    B_train = np.dot(Q_train,sqrt_k_inv_train)\n",
    "    K_train = np.dot(B_train,np.transpose(B_train))\n",
    "\n",
    "    Q_test = feature_map_nystroem.transform(X_test)\n",
    "    sqrt_k_inv_test = np.linalg.inv(feature_map_nystroem.normalization_)\n",
    "    B_test = np.dot(Q_test,sqrt_k_inv_test)\n",
    "    K_test = np.dot(B_test,np.transpose(B_train))\n",
    "    return(K_train,K_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return(1/(1+np.exp(-x)))\n",
    "\n",
    "def fit_model1_1(X_train,y_train):\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
    "                                     max_depth=3, random_state=42).fit(X_train,y_train)\n",
    "    #clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "    #                                 max_depth=5, random_state=42).fit(X_train_imp,y_train)\n",
    "\n",
    "    return(clf)\n",
    "\n",
    "def fit_model1_2(X_train,y_train):\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=10,\n",
    "                  class_weight=\"balanced\",\n",
    "                  decision_function_shape='ovo').fit(X_train,y_train)\n",
    "    return(clf)\n",
    "\n",
    "def fit_model1(X_train,y_train,clf_init,sw_dict={}):\n",
    "    n = np.shape(y_train)[0]\n",
    "    w0 = n/(n-np.sum(y_train))\n",
    "    w1 = n/np.sum(y_train)\n",
    "    \n",
    "    sample_weight = np.zeros(len(y_train))\n",
    "    if not(sw_dict):\n",
    "        print(\"using default sample weights\")\n",
    "        sample_weight[y_train == 0] = w0\n",
    "        sample_weight[y_train == 1] = w1\n",
    "    else:\n",
    "        print(\"using custom sample weights\")\n",
    "        sample_weight[y_train == 0] = sw_dict[0]\n",
    "        sample_weight[y_train == 1] = sw_dict[1]\n",
    "    \n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = clf_init\n",
    "    #clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0, \n",
    "    #                                 max_depth=3, random_state=42)\n",
    "    clf.fit(X_train,y_train,sample_weight=sample_weight)\n",
    "    #clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, \n",
    "    #                                 max_depth=5, random_state=42).fit(X_train_imp,y_train)\n",
    "\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2_1(X_train,y_train,hps):\n",
    "    C = hps[\"C\"]\n",
    "    #class_weight={1:16.5}\n",
    "    class_weight={1:hps[\"w1\"]}\n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=hps[\"C\"],\n",
    "                  kernel=\"rbf\",\n",
    "                  gamma=hps[\"gamma\"],\n",
    "                  class_weight=class_weight,\n",
    "                  decision_function_shape='ovo',\n",
    "                  verbose=True).fit(X_train,y_train)\n",
    "    print(\"C: %f\"%hps[\"C\"])\n",
    "    print(\"gamma: %f\"%hps[\"gamma\"])\n",
    "    print(\"Computed class weight: %s\"%(str(clf.class_weight_)))\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2_2(K_train,y_train):\n",
    "    C = 1.0\n",
    "    class_weight={1:17.5}\n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    \n",
    "    clf = svm.SVC(C=C,\n",
    "                  kernel=\"precomputed\",\n",
    "                  class_weight=\"balanced\",\n",
    "                  decision_function_shape='ovo',\n",
    "                  verbose=True).fit(K_train,y_train)\n",
    "    print(\"C: %f\"%C)\n",
    "    print(\"Computed class weight: %s\"%(str(clf.class_weight_)))\n",
    "    return(clf)\n",
    "\n",
    "def fit_model2(X_train,y_train,clf_init,sw_dict={}):\n",
    "    n = np.shape(y_train)[0]\n",
    "    w0 = n/(n-np.sum(y_train))\n",
    "    w1 = n/np.sum(y_train)\n",
    "    \n",
    "    sample_weight = np.zeros(len(y_train))\n",
    "    if not(sw_dict):\n",
    "        print(\"using default sample weights\")\n",
    "        sample_weight[y_train == 0] = w0\n",
    "        sample_weight[y_train == 1] = w1\n",
    "    else:\n",
    "        print(\"using custom sample weights\")\n",
    "        sample_weight[y_train == 0] = sw_dict[0]\n",
    "        sample_weight[y_train == 1] = sw_dict[1]\n",
    "    \n",
    "    print(\"Shape and sum of y_train\")\n",
    "    print(np.shape(y_train))\n",
    "    print(np.sum(y_train))\n",
    "    clf = clf_init\n",
    "    clf.fit(X_train,y_train,sample_weight=sample_weight)\n",
    "    return(clf)\n",
    "\n",
    "def fit_model3(X_train,y_train):\n",
    "    #print(np.shape(y_train))\n",
    "    #print(np.sum(y_train))\n",
    "    reg = HistGradientBoostingRegressor(random_state=42).fit(X_train,y_train)\n",
    "    #reg = GradientBoostingRegressor(random_state=42).fit(X_train,y_train)\n",
    "    return(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pids = pd.unique(df_test_feats['pid'])\n",
    "\n",
    "df_test_labels = pd.DataFrame(columns=df_labels_cols)\n",
    "df_test_labels['pid'] = test_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_raw = feats_2_X1(df_train_feats,active_feats)\n",
    "X_test1_raw = feats_2_X1(df_test_feats,active_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train1_raw))\n",
    "print(np.shape(X_test1_raw))\n",
    "X_train_imp,X_test = impute(X_train1_raw,X_test1_raw)\n",
    "print(np.shape(X_train_imp))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "holdout_aucs = np.zeros(len(subtask1_labels))\n",
    "\n",
    "for i in range(0,len(subtask1_labels)):\n",
    "#for i in range(0,1):\n",
    "    print(\"i=%d\"%i)\n",
    "    y_train=df_train_labels[subtask1_labels[i]].values\n",
    "    n = float(np.shape(y_train)[0])\n",
    "\n",
    "    if holdout:\n",
    "        #make hold out\n",
    "        X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "            X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "        print(np.shape(X_train))\n",
    "        print(np.shape(X_hold))\n",
    "        print(np.sum(y_train))\n",
    "        print(np.sum(y_hold))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        X_train = X_train_imp\n",
    "\n",
    "    #sample weight\n",
    "    use_custom_sw = True\n",
    "    if use_custom_sw:\n",
    "        #sample weight\n",
    "        n = float(np.shape(y_train)[0])\n",
    "        w1_boost = 0.17\n",
    "\n",
    "        w0 = n/(n-np.sum(y_train))\n",
    "        w1 = (n/np.sum(y_train))*w1_boost\n",
    "        geo_mean = np.sqrt(w0*w1)\n",
    "        w0 /= geo_mean\n",
    "        w1 /= geo_mean\n",
    "    else:\n",
    "        w0=1.0\n",
    "        w1=1.0\n",
    "    \n",
    "    clf_init = HistGradientBoostingClassifier(random_state=42)\n",
    "    clf = fit_model1(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "    score = clf.score(X_train,y_train)\n",
    "    \n",
    "    cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "            scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "    \n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "    print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "    print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "    print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "    \n",
    "    #print(sigmoid(clf.decision_function(X_train)))\n",
    "    #p_train=clf.predict(X_train)\n",
    "    \n",
    "    print(\"y train:\")\n",
    "    print(\"n pos %f\"%np.sum(y_train))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "    \n",
    "    print(\"y train pred:\")\n",
    "    y_train_pred=clf.predict(X_train)\n",
    "    print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "    print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "    \n",
    "    p_train=clf.predict_proba(X_train)\n",
    "    print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "    print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "    \n",
    "    #print(p_train)\n",
    "    \n",
    "    print(\"y test:\")\n",
    "    p_test=clf.predict_proba(X_test)\n",
    "    print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "    print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "    \n",
    "    if holdout:\n",
    "        print(\"holdout metrics:\")\n",
    "        holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "        print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "        holdout_aucs[i] = holdout_auc\n",
    "\n",
    "        y_hold_pred = clf.predict(X_hold)\n",
    "        holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout acc= %f\"%holdout_acc)\n",
    "        holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout rec= %f\"%holdout_rec)\n",
    "        holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "        print(\"holdout prec= %f\"%holdout_prec)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    #y_test[:,1+i] = p_test[:,1]\n",
    "    \n",
    "    df_test_labels[subtask1_labels[i]] = p_test[:,1]\n",
    "    \n",
    "print(\"Hold out aucs and mean\")\n",
    "print(holdout_aucs)\n",
    "print(np.mean(holdout_aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_raw = feats_2_X2(df_train_feats,active_feats)\n",
    "X_test2_raw = feats_2_X2(df_test_feats,active_feats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(X_train2_raw))\n",
    "print(np.shape(X_test2_raw))\n",
    "\n",
    "X_train_imp,X_test = impute(X_train2_raw,X_test2_raw)\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "#X_train,X_test = standardize(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "\n",
    "#X_train,X_test = nystroem(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "hp_x = np.array([0.05])\n",
    "hp_metrics = ['hold_roc_auc',\n",
    "           'hold_accuracy',\n",
    "           'hold_recall',\n",
    "           'hold_precision'\n",
    "          ]\n",
    "hp_y = np.zeros((hp_x.shape[0],len(hp_metrics)))\n",
    "\n",
    "for j in range(0,hp_x.shape[0]):\n",
    "    for i in range(0,len(subtask2_labels)):\n",
    "    #for i in range(0,1):\n",
    "        print(\"i=%d\"%i)\n",
    "        y_train=df_train_labels[subtask2_labels[i]].values\n",
    "        n = float(np.shape(y_train)[0])\n",
    "\n",
    "        if holdout:\n",
    "            #make hold out\n",
    "            X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "                X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "            print(np.shape(X_train))\n",
    "            print(np.shape(X_hold))\n",
    "            print(np.sum(y_train))\n",
    "            print(np.sum(y_hold))\n",
    "            print(\"\\n\")\n",
    "        else:\n",
    "            X_train = X_train_imp\n",
    "\n",
    "        #sample weight\n",
    "        use_custom_sw = True\n",
    "        if use_custom_sw:\n",
    "            #sample weight\n",
    "            n = float(np.shape(y_train)[0])\n",
    "            w1_boost = 0.17\n",
    "\n",
    "            w0 = n/(n-np.sum(y_train))\n",
    "            w1 = (n/np.sum(y_train))*w1_boost\n",
    "            geo_mean = np.sqrt(w0*w1)\n",
    "            w0 /= geo_mean\n",
    "            w1 /= geo_mean\n",
    "        else:\n",
    "            w0=1.0\n",
    "            w1=1.0\n",
    "            \n",
    "        print(\"class weights: %f,%f\"%(w0,w1))\n",
    "\n",
    "        clf_init = HistGradientBoostingClassifier(\n",
    "            learning_rate=hp_x[j],random_state=42)\n",
    "        clf = fit_model2(X_train,y_train,clf_init,sw_dict={0:w0,1:w1})\n",
    "        score = clf.score(X_train,y_train)\n",
    "\n",
    "        cv_results = cross_validate(clf,X_train,y_train,cv=5,\n",
    "                scoring=[\"roc_auc\",\"accuracy\",\"recall\",\"precision\"])\n",
    "\n",
    "        print(\"train score= %f\"%score)\n",
    "        print(\"cv roc auc= %f\"%np.mean(cv_results['test_roc_auc']))\n",
    "        print(\"cv acc= %f\"%np.mean(cv_results['test_accuracy']))\n",
    "        print(\"cv rec= %f\"%np.mean(cv_results['test_recall']))\n",
    "        print(\"cv prec= %f\"%np.mean(cv_results['test_precision']))\n",
    "\n",
    "        #print(sigmoid(clf.decision_function(X_train)))\n",
    "        #p_train=clf.predict(X_train)\n",
    "\n",
    "        print(\"y train:\")\n",
    "        print(\"n pos %f\"%np.sum(y_train))\n",
    "        print(\"frac pos %f\"%(np.sum(y_train)/n))\n",
    "\n",
    "        print(\"y train pred:\")\n",
    "        y_train_pred=clf.predict(X_train)\n",
    "        print(\"n pos %f\"%np.sum(y_train_pred))\n",
    "        print(\"frac pos %f\"%(np.sum(y_train_pred)/n) ) \n",
    "\n",
    "        p_train=clf.predict_proba(X_train)\n",
    "        print(\"prob sum 0 %f\"%np.sum(p_train[:,0]))\n",
    "        print(\"prob sum 1 %f\"%np.sum(p_train[:,1]))\n",
    "\n",
    "        #print(p_train)\n",
    "\n",
    "        print(\"y test:\")\n",
    "        p_test=clf.predict_proba(X_test)\n",
    "        print(\"prob sum 0 %f\"%np.sum(p_test[:,0]))\n",
    "        print(\"prob sum 1 %f\"%np.sum(p_test[:,1]))\n",
    "\n",
    "        if holdout:\n",
    "\n",
    "            print(\"holdout metrics:\")\n",
    "            holdout_auc = roc_auc_score(y_hold,clf.predict_proba(X_hold)[:,1])\n",
    "            print(\"holdout roc auc= %f\"%holdout_auc)\n",
    "            hp_y[j][0] = holdout_auc\n",
    "\n",
    "            y_hold_pred = clf.predict(X_hold)\n",
    "            holdout_acc = accuracy_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout acc= %f\"%holdout_acc)\n",
    "            hp_y[j][1] = holdout_acc\n",
    "\n",
    "            holdout_rec = recall_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout rec= %f\"%holdout_rec)\n",
    "            hp_y[j][2] = holdout_rec\n",
    "\n",
    "            holdout_prec = precision_score(y_hold,y_hold_pred)\n",
    "            print(\"holdout prec= %f\"%holdout_prec)\n",
    "            hp_y[j][3] = holdout_prec\n",
    "\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        #y_test[:,1+i] = p_test[:,1]\n",
    "\n",
    "        df_test_labels[subtask2_labels[i]] = p_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "for k in range(0,len(hp_metrics)):\n",
    "    ax1.plot(np.log10(hp_x),hp_y[:,k],label=hp_metrics[k])\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3_raw = feats_2_X3(df_train_feats,subtask3_feats)\n",
    "X_test3_raw = feats_2_X3(df_test_feats,subtask3_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train3_raw))\n",
    "print(np.shape(X_test3_raw))\n",
    "\n",
    "X_train_imp,X_test = impute(X_train3_raw,X_test3_raw)\n",
    "print(np.shape(X_train_imp))\n",
    "print(np.shape(X_test))\n",
    "\n",
    "#X_train,X_test = standardize(X_train,X_test)\n",
    "#print(np.shape(X_train))\n",
    "#print(np.shape(X_test))\n",
    "\n",
    "\n",
    "\n",
    "holdout_r2s = np.zeros(len(subtask3_labels))\n",
    "\n",
    "for i in range(0,len(subtask3_labels)):\n",
    "#for i in range(0,1):\n",
    "    print(\"i=%d\"%i)\n",
    "    y_train=df_train_labels[subtask3_labels[i]].values\n",
    "    \n",
    "    if holdout:\n",
    "        #make hold out\n",
    "        X_train,X_hold,y_train,y_hold = train_test_split(\n",
    "            X_train_imp,y_train,test_size=0.2,random_state=42)\n",
    "\n",
    "        print(np.shape(X_train))\n",
    "        print(np.shape(X_hold))\n",
    "        print(np.sum(y_train))\n",
    "        print(np.sum(y_hold))\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        X_train = X_train_imp\n",
    "\n",
    "    reg = fit_model3(X_train,y_train)\n",
    "    \n",
    "    score = reg.score(X_train,y_train)\n",
    "    cv_results = cross_validate(reg,X_train,y_train,cv=5,\n",
    "            scoring=[\"r2\"])\n",
    "    \n",
    "    print(\"train score= %f\"%score)\n",
    "    print(\"cv r2= %f\"%np.mean(cv_results['test_r2']))\n",
    "    \n",
    "    y_train_pred=reg.predict(X_train)\n",
    "    print(np.mean(y_train_pred))\n",
    "    print(np.std(y_train_pred))\n",
    "    \n",
    "    y_test=reg.predict(X_test)\n",
    "    print(np.mean(y_test))\n",
    "    print(np.std(y_test))\n",
    "    \n",
    "    if holdout:\n",
    "        print(\"holdout metrics:\")\n",
    "        holdout_r2 = r2_score(y_hold,reg.predict(X_hold))\n",
    "        print(\"holdout roc auc= %f\"%holdout_r2)\n",
    "        holdout_r2s[i] = holdout_r2\n",
    "        #hp_y[j][0] = holdout_auc\n",
    "    \n",
    "    df_test_labels[subtask3_labels[i]] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_labels.to_csv('prediction_1904_8.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
